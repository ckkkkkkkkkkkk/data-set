package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . Weight ; import org . apache . lucene . search . Searcher ; public abstract class SpanQuery extends Query { public abstract Spans getSpans ( IndexReader reader ) throws IOException ; public abstract String getField ( ) ; public abstract Collection getTerms ( ) ; protected Weight createWeight ( Searcher searcher ) throws IOException { return new SpanWeight ( this , searcher ) ; } } 	0	['5', '2', '5', '17', '7', '10', '12', '6', '4', '2', '14', '0', '0', '0.75', '0.466666667', '1', '1', '1.8', '1', '0.8', '0']
package org . apache . lucene . analysis . standard ; public interface CharStream { char readChar ( ) throws java . io . IOException ; int getColumn ( ) ; int getLine ( ) ; int getEndColumn ( ) ; int getEndLine ( ) ; int getBeginColumn ( ) ; int getBeginLine ( ) ; void backup ( int amount ) ; char BeginToken ( ) throws java . io . IOException ; String GetImage ( ) ; char [ ] GetSuffix ( int len ) ; void Done ( ) ; } 	0	['12', '1', '0', '3', '12', '66', '3', '0', '12', '2', '12', '0', '0', '0', '0.583333333', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . analysis . standard ; import java . io . * ; public final class FastCharStream implements CharStream { char [ ] buffer = null ; int bufferLength = 0 ; int bufferPosition = 0 ; int tokenStart = 0 ; int bufferStart = 0 ; Reader input ; public FastCharStream ( Reader r ) { input = r ; } public final char readChar ( ) throws IOException { if ( bufferPosition >= bufferLength ) refill ( ) ; return buffer [ bufferPosition ++ ] ; } private final void refill ( ) throws IOException { int newPosition = bufferLength - tokenStart ; if ( tokenStart == 0 ) { if ( buffer == null ) { buffer = new char [ 2048 ] ; } else if ( bufferLength == buffer . length ) { char [ ] newBuffer = new char [ buffer . length * 2 ] ; System . arraycopy ( buffer , 0 , newBuffer , 0 , bufferLength ) ; buffer = newBuffer ; } } else { System . arraycopy ( buffer , tokenStart , buffer , 0 , newPosition ) ; } bufferLength = newPosition ; bufferPosition = newPosition ; bufferStart += tokenStart ; tokenStart = 0 ; int charsRead = input . read ( buffer , newPosition , buffer . length - newPosition ) ; if ( charsRead == - 1 ) throw new IOException ( "read past eof" ) ; else bufferLength += charsRead ; } public final char BeginToken ( ) throws IOException { tokenStart = bufferPosition ; return readChar ( ) ; } public final void backup ( int amount ) { bufferPosition -= amount ; } public final String GetImage ( ) { return new String ( buffer , tokenStart , bufferPosition - tokenStart ) ; } public final char [ ] GetSuffix ( int len ) { char [ ] value = new char [ len ] ; System . arraycopy ( buffer , bufferPosition - len , value , 0 , len ) ; return value ; } public final void Done ( ) { try { input . close ( ) ; } catch ( IOException e ) { System . err . println ( "Caught: " + e + "; ignoring." ) ; } } public final int getColumn ( ) { return bufferStart + bufferPosition ; } public final int getLine ( ) { return 1 ; } public final int getEndColumn ( ) { return bufferStart + bufferPosition ; } public final int getEndLine ( ) { return 1 ; } public final int getBeginColumn ( ) { return bufferStart + tokenStart ; } public final int getBeginLine ( ) { return 1 ; } } 	0	['14', '1', '0', '2', '25', '3', '1', '1', '13', '0.602564103', '237', '0', '0', '0', '0.404761905', '0', '0', '15.5', '1', '0.9286', '0']
package org . apache . lucene . document ; public class LoadFirstFieldSelector implements FieldSelector { public FieldSelectorResult accept ( String fieldName ) { return FieldSelectorResult . LOAD_AND_BREAK ; } } 	0	['2', '1', '0', '2', '3', '1', '0', '2', '2', '2', '7', '0', '0', '0', '0.75', '0', '0', '2.5', '1', '0.5', '0']
package org . apache . lucene . index ; import java . io . IOException ; import java . util . Arrays ; import org . apache . lucene . store . IndexInput ; class DefaultSkipListReader extends MultiLevelSkipListReader { private boolean currentFieldStoresPayloads ; private long freqPointer [ ] ; private long proxPointer [ ] ; private int payloadLength [ ] ; private long lastFreqPointer ; private long lastProxPointer ; private int lastPayloadLength ; DefaultSkipListReader ( IndexInput skipStream , int maxSkipLevels , int skipInterval ) { super ( skipStream , maxSkipLevels , skipInterval ) ; freqPointer = new long [ maxSkipLevels ] ; proxPointer = new long [ maxSkipLevels ] ; payloadLength = new int [ maxSkipLevels ] ; } void init ( long skipPointer , long freqBasePointer , long proxBasePointer , int df , boolean storesPayloads ) { super . init ( skipPointer , df ) ; this . currentFieldStoresPayloads = storesPayloads ; lastFreqPointer = freqBasePointer ; lastProxPointer = proxBasePointer ; Arrays . fill ( freqPointer , freqBasePointer ) ; Arrays . fill ( proxPointer , proxBasePointer ) ; Arrays . fill ( payloadLength , 0 ) ; } long getFreqPointer ( ) { return lastFreqPointer ; } long getProxPointer ( ) { return lastProxPointer ; } int getPayloadLength ( ) { return lastPayloadLength ; } protected void seekChild ( int level ) throws IOException { super . seekChild ( level ) ; freqPointer [ level ] = lastFreqPointer ; proxPointer [ level ] = lastProxPointer ; payloadLength [ level ] = lastPayloadLength ; } protected void setLastSkipData ( int level ) { super . setLastSkipData ( level ) ; lastFreqPointer = freqPointer [ level ] ; lastProxPointer = proxPointer [ level ] ; lastPayloadLength = payloadLength [ level ] ; } protected int readSkipData ( int level , IndexInput skipStream ) throws IOException { int delta ; if ( currentFieldStoresPayloads ) { delta = skipStream . readVInt ( ) ; if ( ( delta & 1 ) != 0 ) { payloadLength [ level ] = skipStream . readVInt ( ) ; } delta >>>= 1 ; } else { delta = skipStream . readVInt ( ) ; } freqPointer [ level ] += skipStream . readVInt ( ) ; proxPointer [ level ] += skipStream . readVInt ( ) ; return delta ; } } 	0	['8', '2', '0', '3', '15', '0', '1', '2', '0', '0.571428571', '158', '1', '0', '0.5625', '0.425', '1', '3', '17.875', '1', '0.875', '0']
package org . apache . lucene . search ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . FieldSelector ; import org . apache . lucene . index . CorruptIndexException ; import org . apache . lucene . index . Term ; import java . io . IOException ; import java . util . HashMap ; import java . util . HashSet ; import java . util . Map ; import java . util . Set ; public class MultiSearcher extends Searcher { private static class CachedDfSource extends Searcher { private Map dfMap ; private int maxDoc ; public CachedDfSource ( Map dfMap , int maxDoc , Similarity similarity ) { this . dfMap = dfMap ; this . maxDoc = maxDoc ; setSimilarity ( similarity ) ; } public int docFreq ( Term term ) { int df ; try { df = ( ( Integer ) dfMap . get ( term ) ) . intValue ( ) ; } catch ( NullPointerException e ) { throw new IllegalArgumentException ( "df for term " + term . text ( ) + " not available" ) ; } return df ; } public int [ ] docFreqs ( Term [ ] terms ) { int [ ] result = new int [ terms . length ] ; for ( int i = 0 ; i < terms . length ; i ++ ) { result [ i ] = docFreq ( terms [ i ] ) ; } return result ; } public int maxDoc ( ) { return maxDoc ; } public Query rewrite ( Query query ) { return query ; } public void close ( ) { throw new UnsupportedOperationException ( ) ; } public Document doc ( int i ) { throw new UnsupportedOperationException ( ) ; } public Document doc ( int i , FieldSelector fieldSelector ) { throw new UnsupportedOperationException ( ) ; } public Explanation explain ( Weight weight , int doc ) { throw new UnsupportedOperationException ( ) ; } public void search ( Weight weight , Filter filter , HitCollector results ) { throw new UnsupportedOperationException ( ) ; } public TopDocs search ( Weight weight , Filter filter , int n ) { throw new UnsupportedOperationException ( ) ; } public TopFieldDocs search ( Weight weight , Filter filter , int n , Sort sort ) { throw new UnsupportedOperationException ( ) ; } } private Searchable [ ] searchables ; private int [ ] starts ; private int maxDoc = 0 ; public MultiSearcher ( Searchable [ ] searchables ) throws IOException { this . searchables = searchables ; starts = new int [ searchables . length + 1 ] ; for ( int i = 0 ; i < searchables . length ; i ++ ) { starts [ i ] = maxDoc ; maxDoc += searchables [ i ] . maxDoc ( ) ; } starts [ searchables . length ] = maxDoc ; } public Searchable [ ] getSearchables ( ) { return searchables ; } protected int [ ] getStarts ( ) { return starts ; } public void close ( ) throws IOException { for ( int i = 0 ; i < searchables . length ; i ++ ) searchables [ i ] . close ( ) ; } public int docFreq ( Term term ) throws IOException { int docFreq = 0 ; for ( int i = 0 ; i < searchables . length ; i ++ ) docFreq += searchables [ i ] . docFreq ( term ) ; return docFreq ; } public Document doc ( int n ) throws CorruptIndexException , IOException { int i = subSearcher ( n ) ; return searchables [ i ] . doc ( n - starts [ i ] ) ; } public Document doc ( int n , FieldSelector fieldSelector ) throws CorruptIndexException , IOException { int i = subSearcher ( n ) ; return searchables [ i ] . doc ( n - starts [ i ] , fieldSelector ) ; } public int subSearcher ( int n ) { int lo = 0 ; int hi = searchables . length - 1 ; while ( hi >= lo ) { int mid = ( lo + hi ) > > 1 ; int midValue = starts [ mid ] ; if ( n < midValue ) hi = mid - 1 ; else if ( n > midValue ) lo = mid + 1 ; else { while ( mid + 1 < searchables . length && starts [ mid + 1 ] == midValue ) { mid ++ ; } return mid ; } } return hi ; } public int subDoc ( int n ) { return n - starts [ subSearcher ( n ) ] ; } public int maxDoc ( ) throws IOException { return maxDoc ; } public TopDocs search ( Weight weight , Filter filter , int nDocs ) throws IOException { HitQueue hq = new HitQueue ( nDocs ) ; int totalHits = 0 ; for ( int i = 0 ; i < searchables . length ; i ++ ) { TopDocs docs = searchables [ i ] . search ( weight , filter , nDocs ) ; totalHits += docs . totalHits ; ScoreDoc [ ] scoreDocs = docs . scoreDocs ; for ( int j = 0 ; j < scoreDocs . length ; j ++ ) { ScoreDoc scoreDoc = scoreDocs [ j ] ; scoreDoc . doc += starts [ i ] ; if ( ! hq . insert ( scoreDoc ) ) break ; } } ScoreDoc [ ] scoreDocs = new ScoreDoc [ hq . size ( ) ] ; for ( int i = hq . size ( ) - 1 ; i >= 0 ; i -- ) scoreDocs [ i ] = ( ScoreDoc ) hq . pop ( ) ; float maxScore = ( totalHits == 0 ) ? Float . NEGATIVE_INFINITY : scoreDocs [ 0 ] . score ; return new TopDocs ( totalHits , scoreDocs , maxScore ) ; } public TopFieldDocs search ( Weight weight , Filter filter , int n , Sort sort ) throws IOException { FieldDocSortedHitQueue hq = null ; int totalHits = 0 ; float maxScore = Float . NEGATIVE_INFINITY ; for ( int i = 0 ; i < searchables . length ; i ++ ) { TopFieldDocs docs = searchables [ i ] . search ( weight , filter , n , sort ) ; if ( hq == null ) hq = new FieldDocSortedHitQueue ( docs . fields , n ) ; totalHits += docs . totalHits ; maxScore = Math . max ( maxScore , docs . getMaxScore ( ) ) ; ScoreDoc [ ] scoreDocs = docs . scoreDocs ; for ( int j = 0 ; j < scoreDocs . length ; j ++ ) { ScoreDoc scoreDoc = scoreDocs [ j ] ; scoreDoc . doc += starts [ i ] ; if ( ! hq . insert ( scoreDoc ) ) break ; } } ScoreDoc [ ] scoreDocs = new ScoreDoc [ hq . size ( ) ] ; for ( int i = hq . size ( ) - 1 ; i >= 0 ; i -- ) scoreDocs [ i ] = ( ScoreDoc ) hq . pop ( ) ; return new TopFieldDocs ( totalHits , scoreDocs , hq . getFields ( ) , maxScore ) ; } public void search ( Weight weight , Filter filter , final HitCollector results ) throws IOException { for ( int i = 0 ; i < searchables . length ; i ++ ) { final int start = starts [ i ] ; searchables [ i ] . search ( weight , filter , new HitCollector ( ) { public void collect ( int doc , float score ) { results . collect ( doc + start , score ) ; } } ) ; } } public Query rewrite ( Query original ) throws IOException { Query [ ] queries = new Query [ searchables . length ] ; for ( int i = 0 ; i < searchables . length ; i ++ ) { queries [ i ] = searchables [ i ] . rewrite ( original ) ; } return queries [ 0 ] . combine ( queries ) ; } public Explanation explain ( Weight weight , int doc ) throws IOException { int i = subSearcher ( doc ) ; return searchables [ i ] . explain ( weight , doc - starts [ i ] ) ; } protected Weight createWeight ( Query original ) throws IOException { Query rewrittenQuery = rewrite ( original ) ; Set terms = new HashSet ( ) ; rewrittenQuery . extractTerms ( terms ) ; Term [ ] allTermsArray = new Term [ terms . size ( ) ] ; terms . toArray ( allTermsArray ) ; int [ ] aggregatedDfs = new int [ terms . size ( ) ] ; for ( int i = 0 ; i < searchables . length ; i ++ ) { int [ ] dfs = searchables [ i ] . docFreqs ( allTermsArray ) ; for ( int j = 0 ; j < aggregatedDfs . length ; j ++ ) { aggregatedDfs [ j ] += dfs [ j ] ; } } HashMap dfMap = new HashMap ( ) ; for ( int i = 0 ; i < allTermsArray . length ; i ++ ) { dfMap . put ( allTermsArray [ i ] , new Integer ( aggregatedDfs [ i ] ) ) ; } int numDocs = maxDoc ( ) ; CachedDfSource cacheSim = new CachedDfSource ( dfMap , numDocs , getSimilarity ( ) ) ; return rewrittenQuery . weight ( cacheSim ) ; } } 	0	['16', '2', '1', '22', '53', '0', '2', '21', '14', '0.466666667', '577', '1', '1', '0.594594595', '0.23125', '1', '5', '34.875', '6', '1.25', '0']
package org . apache . lucene . analysis ; import java . io . BufferedReader ; import java . io . File ; import java . io . FileReader ; import java . io . IOException ; import java . io . Reader ; import java . util . HashMap ; import java . util . HashSet ; public class WordlistLoader { public static HashSet getWordSet ( File wordfile ) throws IOException { HashSet result = new HashSet ( ) ; FileReader reader = null ; try { reader = new FileReader ( wordfile ) ; result = getWordSet ( reader ) ; } finally { if ( reader != null ) reader . close ( ) ; } return result ; } public static HashSet getWordSet ( Reader reader ) throws IOException { HashSet result = new HashSet ( ) ; BufferedReader br = null ; try { if ( reader instanceof BufferedReader ) { br = ( BufferedReader ) reader ; } else { br = new BufferedReader ( reader ) ; } String word = null ; while ( ( word = br . readLine ( ) ) != null ) { result . add ( word . trim ( ) ) ; } } finally { if ( br != null ) br . close ( ) ; } return result ; } public static HashMap getStemDict ( File wordstemfile ) throws IOException { if ( wordstemfile == null ) throw new NullPointerException ( "wordstemfile may not be null" ) ; HashMap result = new HashMap ( ) ; BufferedReader br = null ; FileReader fr = null ; try { fr = new FileReader ( wordstemfile ) ; br = new BufferedReader ( fr ) ; String line ; while ( ( line = br . readLine ( ) ) != null ) { String [ ] wordstem = line . split ( "\t" , 2 ) ; result . put ( wordstem [ 0 ] , wordstem [ 1 ] ) ; } } finally { if ( fr != null ) fr . close ( ) ; if ( br != null ) br . close ( ) ; } return result ; } } 	0	['4', '1', '0', '2', '17', '6', '2', '0', '4', '2', '147', '0', '0', '0', '0.333333333', '0', '0', '35.75', '1', '0.75', '0']
package org . apache . lucene . search . spans ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermPositions ; import java . io . IOException ; public class TermSpans implements Spans { protected TermPositions positions ; protected Term term ; protected int doc ; protected int freq ; protected int count ; protected int position ; public TermSpans ( TermPositions positions , Term term ) throws IOException { this . positions = positions ; this . term = term ; doc = - 1 ; } public boolean next ( ) throws IOException { if ( count == freq ) { if ( ! positions . next ( ) ) { doc = Integer . MAX_VALUE ; return false ; } doc = positions . doc ( ) ; freq = positions . freq ( ) ; count = 0 ; } position = positions . nextPosition ( ) ; count ++ ; return true ; } public boolean skipTo ( int target ) throws IOException { if ( doc >= target ) { return true ; } if ( ! positions . skipTo ( target ) ) { doc = Integer . MAX_VALUE ; return false ; } doc = positions . doc ( ) ; freq = positions . freq ( ) ; count = 0 ; position = positions . nextPosition ( ) ; count ++ ; return true ; } public int doc ( ) { return doc ; } public int start ( ) { return position ; } public int end ( ) { return position + 1 ; } public String toString ( ) { return "spans(" + term . toString ( ) + ")@" + ( doc == - 1 ? "START" : ( doc == Integer . MAX_VALUE ) ? "END" : doc + "-" + position ) ; } public TermPositions getPositions ( ) { return positions ; } } 	0	['8', '1', '0', '6', '19', '0', '3', '3', '8', '0.666666667', '160', '1', '2', '0', '0.34375', '0', '0', '18.25', '3', '1.125', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . List ; import java . util . ArrayList ; import java . util . Iterator ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . util . ToStringUtils ; public class SpanNearQuery extends SpanQuery { private List clauses ; private int slop ; private boolean inOrder ; private String field ; public SpanNearQuery ( SpanQuery [ ] clauses , int slop , boolean inOrder ) { this . clauses = new ArrayList ( clauses . length ) ; for ( int i = 0 ; i < clauses . length ; i ++ ) { SpanQuery clause = clauses [ i ] ; if ( i == 0 ) { field = clause . getField ( ) ; } else if ( ! clause . getField ( ) . equals ( field ) ) { throw new IllegalArgumentException ( "Clauses must have same field." ) ; } this . clauses . add ( clause ) ; } this . slop = slop ; this . inOrder = inOrder ; } public SpanQuery [ ] getClauses ( ) { return ( SpanQuery [ ] ) clauses . toArray ( new SpanQuery [ clauses . size ( ) ] ) ; } public int getSlop ( ) { return slop ; } public boolean isInOrder ( ) { return inOrder ; } public String getField ( ) { return field ; } public Collection getTerms ( ) { Collection terms = new ArrayList ( ) ; Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { SpanQuery clause = ( SpanQuery ) i . next ( ) ; terms . addAll ( clause . getTerms ( ) ) ; } return terms ; } public void extractTerms ( Set terms ) { Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { SpanQuery clause = ( SpanQuery ) i . next ( ) ; clause . extractTerms ( terms ) ; } } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "spanNear([" ) ; Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { SpanQuery clause = ( SpanQuery ) i . next ( ) ; buffer . append ( clause . toString ( field ) ) ; if ( i . hasNext ( ) ) { buffer . append ( ", " ) ; } } buffer . append ( "], " ) ; buffer . append ( slop ) ; buffer . append ( ", " ) ; buffer . append ( inOrder ) ; buffer . append ( ")" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public Spans getSpans ( final IndexReader reader ) throws IOException { if ( clauses . size ( ) == 0 ) return new SpanOrQuery ( getClauses ( ) ) . getSpans ( reader ) ; if ( clauses . size ( ) == 1 ) return ( ( SpanQuery ) clauses . get ( 0 ) ) . getSpans ( reader ) ; return inOrder ? ( Spans ) new NearSpansOrdered ( this , reader ) : ( Spans ) new NearSpansUnordered ( this , reader ) ; } public Query rewrite ( IndexReader reader ) throws IOException { SpanNearQuery clone = null ; for ( int i = 0 ; i < clauses . size ( ) ; i ++ ) { SpanQuery c = ( SpanQuery ) clauses . get ( i ) ; SpanQuery query = ( SpanQuery ) c . rewrite ( reader ) ; if ( query != c ) { if ( clone == null ) clone = ( SpanNearQuery ) this . clone ( ) ; clone . clauses . set ( i , query ) ; } } if ( clone != null ) { return clone ; } else { return this ; } } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof SpanNearQuery ) ) return false ; final SpanNearQuery spanNearQuery = ( SpanNearQuery ) o ; if ( inOrder != spanNearQuery . inOrder ) return false ; if ( slop != spanNearQuery . slop ) return false ; if ( ! clauses . equals ( spanNearQuery . clauses ) ) return false ; return getBoost ( ) == spanNearQuery . getBoost ( ) ; } public int hashCode ( ) { int result ; result = clauses . hashCode ( ) ; result ^= ( result << 14 ) | ( result > > > 19 ) ; result += Float . floatToRawIntBits ( getBoost ( ) ) ; result += slop ; result ^= ( inOrder ? 0x99AFD3BD : 0 ) ; return result ; } } 	0	['12', '3', '0', '8', '47', '0', '2', '8', '12', '0.590909091', '353', '1', '0', '0.592592593', '0.208333333', '2', '2', '28.08333333', '7', '1.75', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . * ; final class PhrasePositions { int doc ; int position ; int count ; int offset ; TermPositions tp ; PhrasePositions next ; boolean repeats ; PhrasePositions ( TermPositions t , int o ) { tp = t ; offset = o ; } final boolean next ( ) throws IOException { if ( ! tp . next ( ) ) { tp . close ( ) ; doc = Integer . MAX_VALUE ; return false ; } doc = tp . doc ( ) ; position = 0 ; return true ; } final boolean skipTo ( int target ) throws IOException { if ( ! tp . skipTo ( target ) ) { tp . close ( ) ; doc = Integer . MAX_VALUE ; return false ; } doc = tp . doc ( ) ; position = 0 ; return true ; } final void firstPosition ( ) throws IOException { count = tp . freq ( ) ; nextPosition ( ) ; } final boolean nextPosition ( ) throws IOException { if ( count -- > 0 ) { position = tp . nextPosition ( ) - offset ; return true ; } else return false ; } } 	0	['5', '1', '0', '6', '12', '0', '5', '1', '0', '0.678571429', '95', '0', '2', '0', '0.533333333', '0', '0', '16.6', '1', '0.8', '0']
package org . apache . lucene . document ; import java . io . Serializable ; public interface FieldSelector extends Serializable { FieldSelectorResult accept ( String fieldName ) ; } 	0	['1', '1', '0', '18', '1', '0', '17', '1', '1', '2', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search . function ; public class FieldScoreQuery extends ValueSourceQuery { public static class Type { public static final Type BYTE = new Type ( "byte" ) ; public static final Type SHORT = new Type ( "short" ) ; public static final Type INT = new Type ( "int" ) ; public static final Type FLOAT = new Type ( "float" ) ; private String typeName ; private Type ( String name ) { this . typeName = name ; } public String toString ( ) { return getClass ( ) . getName ( ) + "::" + typeName ; } } public FieldScoreQuery ( String field , Type type ) { super ( getValueSource ( field , type ) ) ; } private static ValueSource getValueSource ( String field , Type type ) { if ( type == Type . BYTE ) { return new ByteFieldSource ( field ) ; } if ( type == Type . SHORT ) { return new ShortFieldSource ( field ) ; } if ( type == Type . INT ) { return new IntFieldSource ( field ) ; } if ( type == Type . FLOAT ) { return new FloatFieldSource ( field ) ; } throw new IllegalArgumentException ( type + " is not a known Field Score Query Type!" ) ; } } 	0	['2', '3', '0', '7', '12', '1', '0', '7', '1', '2', '52', '0', '0', '0.947368421', '0.833333333', '0', '0', '25', '5', '2.5', '0']
package org . apache . lucene . search ; import java . io . IOException ; import java . util . HashSet ; import java . util . Iterator ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; public abstract class Query implements java . io . Serializable , Cloneable { private float boost = 1.0f ; public void setBoost ( float b ) { boost = b ; } public float getBoost ( ) { return boost ; } public abstract String toString ( String field ) ; public String toString ( ) { return toString ( "" ) ; } protected Weight createWeight ( Searcher searcher ) throws IOException { throw new UnsupportedOperationException ( ) ; } public Weight weight ( Searcher searcher ) throws IOException { Query query = searcher . rewrite ( this ) ; Weight weight = query . createWeight ( searcher ) ; float sum = weight . sumOfSquaredWeights ( ) ; float norm = getSimilarity ( searcher ) . queryNorm ( sum ) ; weight . normalize ( norm ) ; return weight ; } public Query rewrite ( IndexReader reader ) throws IOException { return this ; } public Query combine ( Query [ ] queries ) { HashSet uniques = new HashSet ( ) ; for ( int i = 0 ; i < queries . length ; i ++ ) { Query query = queries [ i ] ; BooleanClause [ ] clauses = null ; boolean splittable = ( query instanceof BooleanQuery ) ; if ( splittable ) { BooleanQuery bq = ( BooleanQuery ) query ; splittable = bq . isCoordDisabled ( ) ; clauses = bq . getClauses ( ) ; for ( int j = 0 ; splittable && j < clauses . length ; j ++ ) { splittable = ( clauses [ j ] . getOccur ( ) == BooleanClause . Occur . SHOULD ) ; } } if ( splittable ) { for ( int j = 0 ; j < clauses . length ; j ++ ) { uniques . add ( clauses [ j ] . getQuery ( ) ) ; } } else { uniques . add ( query ) ; } } if ( uniques . size ( ) == 1 ) { return ( Query ) uniques . iterator ( ) . next ( ) ; } Iterator it = uniques . iterator ( ) ; BooleanQuery result = new BooleanQuery ( true ) ; while ( it . hasNext ( ) ) result . add ( ( Query ) it . next ( ) , BooleanClause . Occur . SHOULD ) ; return result ; } public void extractTerms ( Set terms ) { throw new UnsupportedOperationException ( ) ; } public static Query mergeBooleanQueries ( Query [ ] queries ) { HashSet allClauses = new HashSet ( ) ; for ( int i = 0 ; i < queries . length ; i ++ ) { BooleanClause [ ] clauses = ( ( BooleanQuery ) queries [ i ] ) . getClauses ( ) ; for ( int j = 0 ; j < clauses . length ; j ++ ) { allClauses . add ( clauses [ j ] ) ; } } boolean coordDisabled = queries . length == 0 ? false : ( ( BooleanQuery ) queries [ 0 ] ) . isCoordDisabled ( ) ; BooleanQuery result = new BooleanQuery ( coordDisabled ) ; Iterator i = allClauses . iterator ( ) ; while ( i . hasNext ( ) ) { result . add ( ( BooleanClause ) i . next ( ) ) ; } return result ; } public Similarity getSimilarity ( Searcher searcher ) { return searcher . getSimilarity ( ) ; } public Object clone ( ) { try { return ( Query ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeException ( "Clone not supported: " + e . getMessage ( ) ) ; } } } 	0	['13', '1', '15', '51', '39', '72', '48', '7', '12', '0.833333333', '249', '1', '0', '0', '0.230769231', '0', '0', '18.07692308', '9', '1.8462', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public final class SimpleAnalyzer extends Analyzer { public TokenStream tokenStream ( String fieldName , Reader reader ) { return new LowerCaseTokenizer ( reader ) ; } } 	0	['2', '2', '0', '4', '4', '1', '1', '3', '2', '2', '10', '0', '0', '0.666666667', '0.666666667', '0', '0', '4', '1', '0.5', '0']
package org . apache . lucene . index ; final class TermInfo { int docFreq = 0 ; long freqPointer = 0 ; long proxPointer = 0 ; int skipOffset ; TermInfo ( ) { } TermInfo ( int df , long fp , long pp ) { docFreq = df ; freqPointer = fp ; proxPointer = pp ; } TermInfo ( TermInfo ti ) { docFreq = ti . docFreq ; freqPointer = ti . freqPointer ; proxPointer = ti . proxPointer ; skipOffset = ti . skipOffset ; } final void set ( int docFreq , long freqPointer , long proxPointer , int skipOffset ) { this . docFreq = docFreq ; this . freqPointer = freqPointer ; this . proxPointer = proxPointer ; this . skipOffset = skipOffset ; } final void set ( TermInfo ti ) { docFreq = ti . docFreq ; freqPointer = ti . freqPointer ; proxPointer = ti . proxPointer ; skipOffset = ti . skipOffset ; } } 	0	['5', '1', '0', '8', '6', '0', '8', '0', '0', '0.125', '100', '0', '0', '0', '0.55', '0', '0', '18.2', '1', '0.4', '0']
package org . apache . lucene . index ; import java . io . IOException ; public class CorruptIndexException extends IOException { public CorruptIndexException ( String message ) { super ( message ) ; } } 	0	['1', '4', '0', '28', '2', '0', '28', '0', '1', '2', '5', '0', '0', '1', '1', '0', '0', '4', '0', '0', '0']
package org . apache . lucene . index ; import java . io . IOException ; import org . apache . lucene . util . PriorityQueue ; final class SegmentMergeQueue extends PriorityQueue { SegmentMergeQueue ( int size ) { initialize ( size ) ; } protected final boolean lessThan ( Object a , Object b ) { SegmentMergeInfo stiA = ( SegmentMergeInfo ) a ; SegmentMergeInfo stiB = ( SegmentMergeInfo ) b ; int comparison = stiA . term . compareTo ( stiB . term ) ; if ( comparison == 0 ) return stiA . base < stiB . base ; else return comparison < 0 ; } final void close ( ) throws IOException { while ( top ( ) != null ) ( ( SegmentMergeInfo ) pop ( ) ) . close ( ) ; } } 	0	['3', '2', '0', '5', '9', '3', '2', '3', '0', '2', '47', '0', '0', '0.846153846', '0.555555556', '1', '3', '14.66666667', '4', '1.6667', '0']
package org . apache . lucene . search ; import java . util . List ; import java . util . Iterator ; import java . io . IOException ; import org . apache . lucene . util . ScorerDocQueue ; class DisjunctionSumScorer extends Scorer { private final int nrScorers ; protected final List subScorers ; private final int minimumNrMatchers ; private ScorerDocQueue scorerDocQueue = null ; private int queueSize = - 1 ; private int currentDoc = - 1 ; protected int nrMatchers = - 1 ; private float currentScore = Float . NaN ; public DisjunctionSumScorer ( List subScorers , int minimumNrMatchers ) { super ( null ) ; nrScorers = subScorers . size ( ) ; if ( minimumNrMatchers <= 0 ) { throw new IllegalArgumentException ( "Minimum nr of matchers must be positive" ) ; } if ( nrScorers <= 1 ) { throw new IllegalArgumentException ( "There must be at least 2 subScorers" ) ; } this . minimumNrMatchers = minimumNrMatchers ; this . subScorers = subScorers ; } public DisjunctionSumScorer ( List subScorers ) { this ( subScorers , 1 ) ; } private void initScorerDocQueue ( ) throws IOException { Iterator si = subScorers . iterator ( ) ; scorerDocQueue = new ScorerDocQueue ( nrScorers ) ; queueSize = 0 ; while ( si . hasNext ( ) ) { Scorer se = ( Scorer ) si . next ( ) ; if ( se . next ( ) ) { if ( scorerDocQueue . insert ( se ) ) { queueSize ++ ; } } } } public void score ( HitCollector hc ) throws IOException { while ( next ( ) ) { hc . collect ( currentDoc , currentScore ) ; } } protected boolean score ( HitCollector hc , int max ) throws IOException { while ( currentDoc < max ) { hc . collect ( currentDoc , currentScore ) ; if ( ! next ( ) ) { return false ; } } return true ; } public boolean next ( ) throws IOException { if ( scorerDocQueue == null ) { initScorerDocQueue ( ) ; } return ( scorerDocQueue . size ( ) >= minimumNrMatchers ) && advanceAfterCurrent ( ) ; } protected boolean advanceAfterCurrent ( ) throws IOException { do { currentDoc = scorerDocQueue . topDoc ( ) ; currentScore = scorerDocQueue . topScore ( ) ; nrMatchers = 1 ; do { if ( ! scorerDocQueue . topNextAndAdjustElsePop ( ) ) { if ( -- queueSize == 0 ) { break ; } } if ( scorerDocQueue . topDoc ( ) != currentDoc ) { break ; } currentScore += scorerDocQueue . topScore ( ) ; nrMatchers ++ ; } while ( true ) ; if ( nrMatchers >= minimumNrMatchers ) { return true ; } else if ( queueSize < minimumNrMatchers ) { return false ; } } while ( true ) ; } public float score ( ) throws IOException { return currentScore ; } public int doc ( ) { return currentDoc ; } public int nrMatchers ( ) { return nrMatchers ; } public boolean skipTo ( int target ) throws IOException { if ( scorerDocQueue == null ) { initScorerDocQueue ( ) ; } if ( queueSize < minimumNrMatchers ) { return false ; } if ( target <= currentDoc ) { return true ; } do { if ( scorerDocQueue . topDoc ( ) >= target ) { return advanceAfterCurrent ( ) ; } else if ( ! scorerDocQueue . topSkipToAndAdjustElsePop ( target ) ) { if ( -- queueSize < minimumNrMatchers ) { return false ; } } } while ( true ) ; } public Explanation explain ( int doc ) throws IOException { Explanation res = new Explanation ( ) ; Iterator ssi = subScorers . iterator ( ) ; float sumScore = 0.0f ; int nrMatches = 0 ; while ( ssi . hasNext ( ) ) { Explanation es = ( ( Scorer ) ssi . next ( ) ) . explain ( doc ) ; if ( es . getValue ( ) > 0.0f ) { sumScore += es . getValue ( ) ; nrMatches ++ ; } res . addDetail ( es ) ; } if ( nrMatchers >= minimumNrMatchers ) { res . setValue ( sumScore ) ; res . setDescription ( "sum over at least " + minimumNrMatchers + " of " + subScorers . size ( ) + ":" ) ; } else { res . setValue ( 0.0f ) ; res . setDescription ( nrMatches + " match(es) but at least " + minimumNrMatchers + " of " + subScorers . size ( ) + " needed" ) ; } return res ; } } 	0	['12', '2', '1', '7', '37', '0', '2', '5', '9', '0.454545455', '357', '1', '1', '0.444444444', '0.416666667', '1', '3', '28.08333333', '1', '0.8333', '0']
package org . apache . lucene . index ; import java . io . IOException ; import org . apache . lucene . store . IndexInput ; final class TermBuffer implements Cloneable { private static final char [ ] NO_CHARS = new char [ 0 ] ; private String field ; private char [ ] text = NO_CHARS ; private int textLength ; private Term term ; public final int compareTo ( TermBuffer other ) { if ( field == other . field ) return compareChars ( text , textLength , other . text , other . textLength ) ; else return field . compareTo ( other . field ) ; } private static final int compareChars ( char [ ] v1 , int len1 , char [ ] v2 , int len2 ) { int end = Math . min ( len1 , len2 ) ; for ( int k = 0 ; k < end ; k ++ ) { char c1 = v1 [ k ] ; char c2 = v2 [ k ] ; if ( c1 != c2 ) { return c1 - c2 ; } } return len1 - len2 ; } private final void setTextLength ( int newLength ) { if ( text . length < newLength ) { char [ ] newText = new char [ newLength ] ; System . arraycopy ( text , 0 , newText , 0 , textLength ) ; text = newText ; } textLength = newLength ; } public final void read ( IndexInput input , FieldInfos fieldInfos ) throws IOException { this . term = null ; int start = input . readVInt ( ) ; int length = input . readVInt ( ) ; int totalLength = start + length ; setTextLength ( totalLength ) ; input . readChars ( this . text , start , length ) ; this . field = fieldInfos . fieldName ( input . readVInt ( ) ) ; } public final void set ( Term term ) { if ( term == null ) { reset ( ) ; return ; } setTextLength ( term . text ( ) . length ( ) ) ; term . text ( ) . getChars ( 0 , term . text ( ) . length ( ) , text , 0 ) ; this . field = term . field ( ) ; this . term = term ; } public final void set ( TermBuffer other ) { setTextLength ( other . textLength ) ; System . arraycopy ( other . text , 0 , text , 0 , textLength ) ; this . field = other . field ; this . term = other . term ; } public void reset ( ) { this . field = null ; this . textLength = 0 ; this . term = null ; } public Term toTerm ( ) { if ( field == null ) return null ; if ( term == null ) term = new Term ( field , new String ( text , 0 , textLength ) , false ) ; return term ; } protected Object clone ( ) { TermBuffer clone = null ; try { clone = ( TermBuffer ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { } clone . text = new char [ text . length ] ; System . arraycopy ( text , 0 , clone . text , 0 , textLength ) ; return clone ; } } 	0	['11', '1', '0', '4', '25', '0', '1', '3', '6', '0.52', '241', '1', '1', '0', '0.242857143', '0', '0', '20.45454545', '3', '1.4545', '0']
package org . apache . lucene . store ; import java . io . IOException ; public abstract class BufferedIndexOutput extends IndexOutput { static final int BUFFER_SIZE = 16384 ; private final byte [ ] buffer = new byte [ BUFFER_SIZE ] ; private long bufferStart = 0 ; private int bufferPosition = 0 ; public void writeByte ( byte b ) throws IOException { if ( bufferPosition >= BUFFER_SIZE ) flush ( ) ; buffer [ bufferPosition ++ ] = b ; } public void writeBytes ( byte [ ] b , int offset , int length ) throws IOException { int bytesLeft = BUFFER_SIZE - bufferPosition ; if ( bytesLeft >= length ) { System . arraycopy ( b , offset , buffer , bufferPosition , length ) ; bufferPosition += length ; if ( BUFFER_SIZE - bufferPosition == 0 ) flush ( ) ; } else { if ( length > BUFFER_SIZE ) { if ( bufferPosition > 0 ) flush ( ) ; flushBuffer ( b , offset , length ) ; bufferStart += length ; } else { int pos = 0 ; int pieceLength ; while ( pos < length ) { pieceLength = ( length - pos < bytesLeft ) ? length - pos : bytesLeft ; System . arraycopy ( b , pos + offset , buffer , bufferPosition , pieceLength ) ; pos += pieceLength ; bufferPosition += pieceLength ; bytesLeft = BUFFER_SIZE - bufferPosition ; if ( bytesLeft == 0 ) { flush ( ) ; bytesLeft = BUFFER_SIZE ; } } } } } public void flush ( ) throws IOException { flushBuffer ( buffer , bufferPosition ) ; bufferStart += bufferPosition ; bufferPosition = 0 ; } private void flushBuffer ( byte [ ] b , int len ) throws IOException { flushBuffer ( b , 0 , len ) ; } protected abstract void flushBuffer ( byte [ ] b , int offset , int len ) throws IOException ; public void close ( ) throws IOException { flush ( ) ; } public long getFilePointer ( ) { return bufferStart + bufferPosition ; } public void seek ( long pos ) throws IOException { flush ( ) ; bufferStart = pos ; } public abstract long length ( ) throws IOException ; } 	0	['10', '2', '1', '2', '12', '17', '1', '1', '8', '0.555555556', '185', '0.75', '0', '0.608695652', '0.36', '1', '3', '17.1', '1', '0.9', '0']
package org . apache . lucene . index ; public class TermVectorOffsetInfo { public static final TermVectorOffsetInfo [ ] EMPTY_OFFSET_INFO = new TermVectorOffsetInfo [ 0 ] ; private int startOffset ; private int endOffset ; public TermVectorOffsetInfo ( ) { } public TermVectorOffsetInfo ( int startOffset , int endOffset ) { this . endOffset = endOffset ; this . startOffset = startOffset ; } public int getEndOffset ( ) { return endOffset ; } public void setEndOffset ( int endOffset ) { this . endOffset = endOffset ; } public int getStartOffset ( ) { return startOffset ; } public void setStartOffset ( int startOffset ) { this . startOffset = startOffset ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof TermVectorOffsetInfo ) ) return false ; final TermVectorOffsetInfo termVectorOffsetInfo = ( TermVectorOffsetInfo ) o ; if ( endOffset != termVectorOffsetInfo . endOffset ) return false ; if ( startOffset != termVectorOffsetInfo . startOffset ) return false ; return true ; } public int hashCode ( ) { int result ; result = startOffset ; result = 29 * result + endOffset ; return result ; } } 	0	['9', '1', '0', '7', '10', '2', '7', '0', '8', '0.666666667', '83', '0.666666667', '1', '0', '0.5', '1', '1', '7.888888889', '5', '1.1111', '0']
package org . apache . lucene . index ; import java . io . IOException ; import org . apache . lucene . store . IndexOutput ; import org . apache . lucene . store . RAMOutputStream ; abstract class MultiLevelSkipListWriter { private int numberOfSkipLevels ; private int skipInterval ; private RAMOutputStream [ ] skipBuffer ; protected MultiLevelSkipListWriter ( int skipInterval , int maxSkipLevels , int df ) { this . skipInterval = skipInterval ; numberOfSkipLevels = df == 0 ? 0 : ( int ) Math . floor ( Math . log ( df ) / Math . log ( skipInterval ) ) ; if ( numberOfSkipLevels > maxSkipLevels ) { numberOfSkipLevels = maxSkipLevels ; } } protected void init ( ) { skipBuffer = new RAMOutputStream [ numberOfSkipLevels ] ; for ( int i = 0 ; i < numberOfSkipLevels ; i ++ ) { skipBuffer [ i ] = new RAMOutputStream ( ) ; } } protected void resetSkip ( ) { if ( skipBuffer == null ) { init ( ) ; } else { for ( int i = 0 ; i < skipBuffer . length ; i ++ ) { skipBuffer [ i ] . reset ( ) ; } } } protected abstract void writeSkipData ( int level , IndexOutput skipBuffer ) throws IOException ; void bufferSkip ( int df ) throws IOException { int numLevels ; for ( numLevels = 0 ; ( df % skipInterval ) == 0 && numLevels < numberOfSkipLevels ; df /= skipInterval ) { numLevels ++ ; } long childPointer = 0 ; for ( int level = 0 ; level < numLevels ; level ++ ) { writeSkipData ( level , skipBuffer [ level ] ) ; long newChildPointer = skipBuffer [ level ] . getFilePointer ( ) ; if ( level != 0 ) { skipBuffer [ level ] . writeVLong ( childPointer ) ; } childPointer = newChildPointer ; } } long writeSkip ( IndexOutput output ) throws IOException { long skipPointer = output . getFilePointer ( ) ; if ( skipBuffer == null || skipBuffer . length == 0 ) return skipPointer ; for ( int level = numberOfSkipLevels - 1 ; level > 0 ; level -- ) { long length = skipBuffer [ level ] . getFilePointer ( ) ; if ( length > 0 ) { output . writeVLong ( length ) ; skipBuffer [ level ] . writeTo ( output ) ; } } skipBuffer [ 0 ] . writeTo ( output ) ; return skipPointer ; } } 	0	['6', '1', '1', '3', '16', '0', '1', '2', '0', '0.466666667', '178', '1', '1', '0', '0.611111111', '0', '0', '28.16666667', '3', '1.3333', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public class LetterTokenizer extends CharTokenizer { public LetterTokenizer ( Reader in ) { super ( in ) ; } protected boolean isTokenChar ( char c ) { return Character . isLetter ( c ) ; } } 	0	['2', '4', '1', '2', '4', '1', '1', '1', '1', '2', '9', '0', '0', '0.875', '0.666666667', '1', '1', '3.5', '1', '0.5', '0']
package org . apache . lucene . search ; import org . apache . lucene . util . Parameter ; public class BooleanClause implements java . io . Serializable { public static final class Occur extends Parameter implements java . io . Serializable { private Occur ( String name ) { super ( name ) ; } public String toString ( ) { if ( this == MUST ) return "+" ; if ( this == MUST_NOT ) return "-" ; return "" ; } public static final Occur MUST = new Occur ( "MUST" ) ; public static final Occur SHOULD = new Occur ( "SHOULD" ) ; public static final Occur MUST_NOT = new Occur ( "MUST_NOT" ) ; } private Query query ; private Occur occur ; public BooleanClause ( Query query , Occur occur ) { this . query = query ; this . occur = occur ; } public Occur getOccur ( ) { return occur ; } public void setOccur ( Occur occur ) { this . occur = occur ; } public Query getQuery ( ) { return query ; } public void setQuery ( Query query ) { this . query = query ; } public boolean isProhibited ( ) { return Occur . MUST_NOT . equals ( occur ) ; } public boolean isRequired ( ) { return Occur . MUST . equals ( occur ) ; } public boolean equals ( Object o ) { if ( ! ( o instanceof BooleanClause ) ) return false ; BooleanClause other = ( BooleanClause ) o ; return this . query . equals ( other . query ) && this . occur . equals ( other . occur ) ; } public int hashCode ( ) { return query . hashCode ( ) ^ ( Occur . MUST . equals ( occur ) ? 1 : 0 ) ^ ( Occur . MUST_NOT . equals ( occur ) ? 2 : 0 ) ; } public String toString ( ) { return occur . toString ( ) + query . toString ( ) ; } } 	0	['10', '1', '0', '6', '18', '0', '5', '2', '10', '0.333333333', '104', '1', '2', '0', '0.375', '1', '1', '9.2', '4', '1.4', '0']
package org . apache . lucene . util ; public class ToStringUtils { public static String boost ( float boost ) { if ( boost != 1.0f ) { return "^" + Float . toString ( boost ) ; } else return "" ; } } 	0	['2', '1', '0', '17', '7', '1', '17', '0', '2', '2', '21', '0', '0', '0', '0.5', '0', '0', '9.5', '2', '1', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import java . io . IOException ; public class WildcardQuery extends MultiTermQuery { private boolean termContainsWildcard ; public WildcardQuery ( Term term ) { super ( term ) ; this . termContainsWildcard = ( term . text ( ) . indexOf ( '*' ) != - 1 ) || ( term . text ( ) . indexOf ( '?' ) != - 1 ) ; } protected FilteredTermEnum getEnum ( IndexReader reader ) throws IOException { return new WildcardTermEnum ( reader , getTerm ( ) ) ; } public boolean equals ( Object o ) { if ( o instanceof WildcardQuery ) return super . equals ( o ) ; return false ; } public Query rewrite ( IndexReader reader ) throws IOException { if ( this . termContainsWildcard ) { return super . rewrite ( reader ) ; } return new TermQuery ( getTerm ( ) ) ; } } 	0	['4', '3', '0', '8', '12', '4', '1', '7', '3', '0.666666667', '55', '1', '0', '0.857142857', '0.5', '1', '1', '12.5', '2', '1', '0']
package org . apache . lucene . document ; import org . apache . lucene . search . PrefixQuery ; import org . apache . lucene . search . RangeQuery ; import java . util . Date ; public class DateField { private DateField ( ) { } private static int DATE_LEN = Long . toString ( 1000L * 365 * 24 * 60 * 60 * 1000 , Character . MAX_RADIX ) . length ( ) ; public static String MIN_DATE_STRING ( ) { return timeToString ( 0 ) ; } public static String MAX_DATE_STRING ( ) { char [ ] buffer = new char [ DATE_LEN ] ; char c = Character . forDigit ( Character . MAX_RADIX - 1 , Character . MAX_RADIX ) ; for ( int i = 0 ; i < DATE_LEN ; i ++ ) buffer [ i ] = c ; return new String ( buffer ) ; } public static String dateToString ( Date date ) { return timeToString ( date . getTime ( ) ) ; } public static String timeToString ( long time ) { if ( time < 0 ) throw new RuntimeException ( "time '" + time + "' is too early, must be >= 0" ) ; String s = Long . toString ( time , Character . MAX_RADIX ) ; if ( s . length ( ) > DATE_LEN ) throw new RuntimeException ( "time '" + time + "' is too late, length of string " + "representation must be <= " + DATE_LEN ) ; if ( s . length ( ) < DATE_LEN ) { StringBuffer sb = new StringBuffer ( s ) ; while ( sb . length ( ) < DATE_LEN ) sb . insert ( 0 , 0 ) ; s = sb . toString ( ) ; } return s ; } public static long stringToTime ( String s ) { return Long . parseLong ( s , Character . MAX_RADIX ) ; } public static Date stringToDate ( String s ) { return new Date ( stringToTime ( s ) ) ; } } 	0	['8', '1', '0', '1', '25', '22', '1', '0', '6', '0.428571429', '126', '1', '0', '0', '0.178571429', '0', '0', '14.625', '5', '1.375', '0']
package org . apache . lucene . document ; import java . io . Serializable ; public final class FieldSelectorResult implements Serializable { public transient static final FieldSelectorResult LOAD = new FieldSelectorResult ( 0 ) ; public transient static final FieldSelectorResult LAZY_LOAD = new FieldSelectorResult ( 1 ) ; public transient static final FieldSelectorResult NO_LOAD = new FieldSelectorResult ( 2 ) ; public transient static final FieldSelectorResult LOAD_AND_BREAK = new FieldSelectorResult ( 3 ) ; public transient static final FieldSelectorResult LOAD_FOR_MERGE = new FieldSelectorResult ( 4 ) ; public transient static final FieldSelectorResult SIZE = new FieldSelectorResult ( 5 ) ; public transient static final FieldSelectorResult SIZE_AND_BREAK = new FieldSelectorResult ( 6 ) ; private int id ; private FieldSelectorResult ( int id ) { this . id = id ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; final FieldSelectorResult that = ( FieldSelectorResult ) o ; if ( id != that . id ) return false ; return true ; } public int hashCode ( ) { return id ; } } 	0	['4', '1', '0', '7', '6', '0', '7', '0', '2', '0.875', '83', '0.125', '7', '0', '0.555555556', '1', '1', '17.75', '5', '1.5', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import java . io . IOException ; import java . io . Serializable ; public interface SortComparatorSource extends Serializable { ScoreDocComparator newComparator ( IndexReader reader , String fieldname ) throws IOException ; } 	0	['1', '1', '0', '6', '1', '0', '4', '2', '1', '2', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search ; import java . io . IOException ; public class ReqOptSumScorer extends Scorer { private Scorer reqScorer ; private Scorer optScorer ; public ReqOptSumScorer ( Scorer reqScorer , Scorer optScorer ) { super ( null ) ; this . reqScorer = reqScorer ; this . optScorer = optScorer ; } private boolean firstTimeOptScorer = true ; public boolean next ( ) throws IOException { return reqScorer . next ( ) ; } public boolean skipTo ( int target ) throws IOException { return reqScorer . skipTo ( target ) ; } public int doc ( ) { return reqScorer . doc ( ) ; } public float score ( ) throws IOException { int curDoc = reqScorer . doc ( ) ; float reqScore = reqScorer . score ( ) ; if ( firstTimeOptScorer ) { firstTimeOptScorer = false ; if ( ! optScorer . skipTo ( curDoc ) ) { optScorer = null ; return reqScore ; } } else if ( optScorer == null ) { return reqScore ; } else if ( ( optScorer . doc ( ) < curDoc ) && ( ! optScorer . skipTo ( curDoc ) ) ) { optScorer = null ; return reqScore ; } return ( optScorer . doc ( ) == curDoc ) ? reqScore + optScorer . score ( ) : reqScore ; } public Explanation explain ( int doc ) throws IOException { Explanation res = new Explanation ( ) ; res . setDescription ( "required, optional" ) ; res . addDetail ( reqScorer . explain ( doc ) ) ; res . addDetail ( optScorer . explain ( doc ) ) ; return res ; } } 	0	['6', '2', '0', '4', '15', '0', '1', '3', '6', '0.466666667', '113', '1', '2', '0.615384615', '0.5', '1', '3', '17.33333333', '1', '0.8333', '0']
package org . apache . lucene . document ; public class NumberTools { private static final int RADIX = 36 ; private static final char NEGATIVE_PREFIX = '-' ; private static final char POSITIVE_PREFIX = '0' ; public static final String MIN_STRING_VALUE = NEGATIVE_PREFIX + "0000000000000" ; public static final String MAX_STRING_VALUE = POSITIVE_PREFIX + "1y2p0ij32e8e7" ; public static final int STR_SIZE = MIN_STRING_VALUE . length ( ) ; public static String longToString ( long l ) { if ( l == Long . MIN_VALUE ) { return MIN_STRING_VALUE ; } StringBuffer buf = new StringBuffer ( STR_SIZE ) ; if ( l < 0 ) { buf . append ( NEGATIVE_PREFIX ) ; l = Long . MAX_VALUE + l + 1 ; } else { buf . append ( POSITIVE_PREFIX ) ; } String num = Long . toString ( l , RADIX ) ; int padLen = STR_SIZE - num . length ( ) - buf . length ( ) ; while ( padLen -- > 0 ) { buf . append ( '0' ) ; } buf . append ( num ) ; return buf . toString ( ) ; } public static long stringToLong ( String str ) { if ( str == null ) { throw new NullPointerException ( "string cannot be null" ) ; } if ( str . length ( ) != STR_SIZE ) { throw new NumberFormatException ( "string is the wrong size" ) ; } if ( str . equals ( MIN_STRING_VALUE ) ) { return Long . MIN_VALUE ; } char prefix = str . charAt ( 0 ) ; long l = Long . parseLong ( str . substring ( 1 ) , RADIX ) ; if ( prefix == POSITIVE_PREFIX ) { } else if ( prefix == NEGATIVE_PREFIX ) { l = l - Long . MAX_VALUE - 1 ; } else { throw new NumberFormatException ( "string does not begin with the correct prefix" ) ; } return l ; } } 	0	['4', '1', '0', '0', '18', '0', '0', '0', '3', '1.166666667', '130', '0.5', '0', '0', '0.333333333', '0', '0', '30', '6', '2.5', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import java . io . IOException ; public final class FuzzyTermEnum extends FilteredTermEnum { private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19 ; private int [ ] [ ] d ; private float similarity ; private boolean endEnum = false ; private Term searchTerm = null ; private final String field ; private final String text ; private final String prefix ; private final float minimumSimilarity ; private final float scale_factor ; private final int [ ] maxDistances = new int [ TYPICAL_LONGEST_WORD_IN_INDEX ] ; public FuzzyTermEnum ( IndexReader reader , Term term ) throws IOException { this ( reader , term , FuzzyQuery . defaultMinSimilarity , FuzzyQuery . defaultPrefixLength ) ; } public FuzzyTermEnum ( IndexReader reader , Term term , float minSimilarity ) throws IOException { this ( reader , term , minSimilarity , FuzzyQuery . defaultPrefixLength ) ; } public FuzzyTermEnum ( IndexReader reader , Term term , final float minSimilarity , final int prefixLength ) throws IOException { super ( ) ; if ( minSimilarity >= 1.0f ) throw new IllegalArgumentException ( "minimumSimilarity cannot be greater than or equal to 1" ) ; else if ( minSimilarity < 0.0f ) throw new IllegalArgumentException ( "minimumSimilarity cannot be less than 0" ) ; if ( prefixLength < 0 ) throw new IllegalArgumentException ( "prefixLength cannot be less than 0" ) ; this . minimumSimilarity = minSimilarity ; this . scale_factor = 1.0f / ( 1.0f - minimumSimilarity ) ; this . searchTerm = term ; this . field = searchTerm . field ( ) ; final int fullSearchTermLength = searchTerm . text ( ) . length ( ) ; final int realPrefixLength = prefixLength > fullSearchTermLength ? fullSearchTermLength : prefixLength ; this . text = searchTerm . text ( ) . substring ( realPrefixLength ) ; this . prefix = searchTerm . text ( ) . substring ( 0 , realPrefixLength ) ; initializeMaxDistances ( ) ; this . d = initDistanceArray ( ) ; setEnum ( reader . terms ( new Term ( searchTerm . field ( ) , prefix ) ) ) ; } protected final boolean termCompare ( Term term ) { if ( field == term . field ( ) && term . text ( ) . startsWith ( prefix ) ) { final String target = term . text ( ) . substring ( prefix . length ( ) ) ; this . similarity = similarity ( target ) ; return ( similarity > minimumSimilarity ) ; } endEnum = true ; return false ; } public final float difference ( ) { return ( float ) ( ( similarity - minimumSimilarity ) * scale_factor ) ; } public final boolean endEnum ( ) { return endEnum ; } private static final int min ( int a , int b , int c ) { final int t = ( a < b ) ? a : b ; return ( t < c ) ? t : c ; } private final int [ ] [ ] initDistanceArray ( ) { return new int [ this . text . length ( ) + 1 ] [ TYPICAL_LONGEST_WORD_IN_INDEX ] ; } private synchronized final float similarity ( final String target ) { final int m = target . length ( ) ; final int n = text . length ( ) ; if ( n == 0 ) { return prefix . length ( ) == 0 ? 0.0f : 1.0f - ( ( float ) m / prefix . length ( ) ) ; } if ( m == 0 ) { return prefix . length ( ) == 0 ? 0.0f : 1.0f - ( ( float ) n / prefix . length ( ) ) ; } final int maxDistance = getMaxDistance ( m ) ; if ( maxDistance < Math . abs ( m - n ) ) { return 0.0f ; } if ( d [ 0 ] . length <= m ) { growDistanceArray ( m ) ; } for ( int i = 0 ; i <= n ; i ++ ) d [ i ] [ 0 ] = i ; for ( int j = 0 ; j <= m ; j ++ ) d [ 0 ] [ j ] = j ; for ( int i = 1 ; i <= n ; i ++ ) { int bestPossibleEditDistance = m ; final char s_i = text . charAt ( i - 1 ) ; for ( int j = 1 ; j <= m ; j ++ ) { if ( s_i != target . charAt ( j - 1 ) ) { d [ i ] [ j ] = min ( d [ i - 1 ] [ j ] , d [ i ] [ j - 1 ] , d [ i - 1 ] [ j - 1 ] ) + 1 ; } else { d [ i ] [ j ] = min ( d [ i - 1 ] [ j ] + 1 , d [ i ] [ j - 1 ] + 1 , d [ i - 1 ] [ j - 1 ] ) ; } bestPossibleEditDistance = Math . min ( bestPossibleEditDistance , d [ i ] [ j ] ) ; } if ( i > maxDistance && bestPossibleEditDistance > maxDistance ) { return 0.0f ; } } return 1.0f - ( ( float ) d [ n ] [ m ] / ( float ) ( prefix . length ( ) + Math . min ( n , m ) ) ) ; } private void growDistanceArray ( int m ) { for ( int i = 0 ; i < d . length ; i ++ ) { d [ i ] = new int [ m + 1 ] ; } } private final int getMaxDistance ( int m ) { return ( m < maxDistances . length ) ? maxDistances [ m ] : calculateMaxDistance ( m ) ; } private void initializeMaxDistances ( ) { for ( int i = 0 ; i < maxDistances . length ; i ++ ) { maxDistances [ i ] = calculateMaxDistance ( i ) ; } } private int calculateMaxDistance ( int m ) { return ( int ) ( ( 1 - minimumSimilarity ) * ( Math . min ( text . length ( ) , m ) + prefix . length ( ) ) ) ; } public void close ( ) throws IOException { super . close ( ) ; } } 	0	['14', '3', '0', '5', '29', '53', '1', '4', '6', '0.692307692', '514', '1', '1', '0.541666667', '0.333333333', '1', '4', '34.92857143', '14', '2.2857', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . util . ToStringUtils ; public class SpanFirstQuery extends SpanQuery { private SpanQuery match ; private int end ; public SpanFirstQuery ( SpanQuery match , int end ) { this . match = match ; this . end = end ; } public SpanQuery getMatch ( ) { return match ; } public int getEnd ( ) { return end ; } public String getField ( ) { return match . getField ( ) ; } public Collection getTerms ( ) { return match . getTerms ( ) ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "spanFirst(" ) ; buffer . append ( match . toString ( field ) ) ; buffer . append ( ", " ) ; buffer . append ( end ) ; buffer . append ( ")" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public void extractTerms ( Set terms ) { match . extractTerms ( terms ) ; } public Spans getSpans ( final IndexReader reader ) throws IOException { return new Spans ( ) { private Spans spans = match . getSpans ( reader ) ; public boolean next ( ) throws IOException { while ( spans . next ( ) ) { if ( end ( ) <= end ) return true ; } return false ; } public boolean skipTo ( int target ) throws IOException { if ( ! spans . skipTo ( target ) ) return false ; if ( spans . end ( ) <= end ) return true ; return next ( ) ; } public int doc ( ) { return spans . doc ( ) ; } public int start ( ) { return spans . start ( ) ; } public int end ( ) { return spans . end ( ) ; } public String toString ( ) { return "spans(" + SpanFirstQuery . this . toString ( ) + ")" ; } } ; } public Query rewrite ( IndexReader reader ) throws IOException { SpanFirstQuery clone = null ; SpanQuery rewritten = ( SpanQuery ) match . rewrite ( reader ) ; if ( rewritten != match ) { clone = ( SpanFirstQuery ) this . clone ( ) ; clone . match = rewritten ; } if ( clone != null ) { return clone ; } else { return this ; } } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof SpanFirstQuery ) ) return false ; SpanFirstQuery other = ( SpanFirstQuery ) o ; return this . end == other . end && this . match . equals ( other . match ) && this . getBoost ( ) == other . getBoost ( ) ; } public int hashCode ( ) { int h = match . hashCode ( ) ; h ^= ( h << 8 ) | ( h > > > 25 ) ; h ^= Float . floatToRawIntBits ( getBoost ( ) ) ^ end ; return h ; } } 	0	['13', '3', '0', '6', '30', '0', '1', '6', '11', '0.416666667', '176', '1', '1', '0.571428571', '0.192307692', '2', '2', '12.38461538', '6', '1.3077', '0']
package org . apache . lucene ; public final class LucenePackage { private LucenePackage ( ) { } public static Package get ( ) { return LucenePackage . class . getPackage ( ) ; } } 	0	['3', '1', '0', '0', '8', '3', '0', '0', '1', '1', '27', '0', '0', '0', '0.333333333', '0', '0', '7.666666667', '2', '1', '0']
package org . apache . lucene . util ; import java . io . ObjectStreamException ; import java . io . Serializable ; import java . io . StreamCorruptedException ; import java . util . HashMap ; import java . util . Map ; public abstract class Parameter implements Serializable { static Map allParameters = new HashMap ( ) ; private String name ; private Parameter ( ) { } protected Parameter ( String name ) { this . name = name ; String key = makeKey ( name ) ; if ( allParameters . containsKey ( key ) ) throw new IllegalArgumentException ( "Parameter name " + key + " already used!" ) ; allParameters . put ( key , this ) ; } private String makeKey ( String name ) { return getClass ( ) + " " + name ; } public String toString ( ) { return name ; } protected Object readResolve ( ) throws ObjectStreamException { Object par = allParameters . get ( makeKey ( name ) ) ; if ( par == null ) throw new StreamCorruptedException ( "Unknown parameter value: " + name ) ; return par ; } } 	0	['6', '1', '5', '5', '18', '5', '5', '0', '1', '0.6', '88', '0.5', '0', '0', '0.7', '0', '0', '13.33333333', '1', '0.5', '0']
package org . apache . lucene . search . spans ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . util . ToStringUtils ; import java . io . IOException ; import java . util . ArrayList ; import java . util . Collection ; import java . util . Set ; public class SpanTermQuery extends SpanQuery { protected Term term ; public SpanTermQuery ( Term term ) { this . term = term ; } public Term getTerm ( ) { return term ; } public String getField ( ) { return term . field ( ) ; } public Collection getTerms ( ) { Collection terms = new ArrayList ( ) ; terms . add ( term ) ; return terms ; } public void extractTerms ( Set terms ) { terms . add ( term ) ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( term . field ( ) . equals ( field ) ) buffer . append ( term . text ( ) ) ; else buffer . append ( term . toString ( ) ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( ! ( o instanceof SpanTermQuery ) ) return false ; SpanTermQuery other = ( SpanTermQuery ) o ; return ( this . getBoost ( ) == other . getBoost ( ) ) && this . term . equals ( other . term ) ; } public int hashCode ( ) { return Float . floatToIntBits ( getBoost ( ) ) ^ term . hashCode ( ) ^ 0xD23FE494 ; } public Spans getSpans ( final IndexReader reader ) throws IOException { return new TermSpans ( reader . termPositions ( term ) , term ) ; } } 	0	['9', '3', '1', '8', '27', '0', '1', '7', '9', '0', '116', '1', '1', '0.666666667', '0.259259259', '2', '2', '11.77777778', '4', '1.3333', '0']
package org . apache . lucene . util ; public abstract class StringHelper { public static final int stringDifference ( String s1 , String s2 ) { int len1 = s1 . length ( ) ; int len2 = s2 . length ( ) ; int len = len1 < len2 ? len1 : len2 ; for ( int i = 0 ; i < len ; i ++ ) { if ( s1 . charAt ( i ) != s2 . charAt ( i ) ) { return i ; } } return len ; } private StringHelper ( ) { } } 	0	['2', '1', '0', '2', '5', '1', '2', '0', '1', '2', '36', '0', '0', '0', '0.5', '0', '0', '17', '4', '2', '0']
package org . apache . lucene . index ; public interface TermPositionVector extends TermFreqVector { public int [ ] getTermPositions ( int index ) ; public TermVectorOffsetInfo [ ] getOffsets ( int index ) ; } 	0	['2', '1', '0', '4', '2', '1', '2', '2', '2', '2', '2', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . util ; import java . io . IOException ; import org . apache . lucene . search . Scorer ; public class ScorerDocQueue { private final HeapedScorerDoc [ ] heap ; private final int maxSize ; private int size ; private class HeapedScorerDoc { Scorer scorer ; int doc ; HeapedScorerDoc ( Scorer s ) { this ( s , s . doc ( ) ) ; } HeapedScorerDoc ( Scorer scorer , int doc ) { this . scorer = scorer ; this . doc = doc ; } void adjust ( ) { doc = scorer . doc ( ) ; } } private HeapedScorerDoc topHSD ; public ScorerDocQueue ( int maxSize ) { size = 0 ; int heapSize = maxSize + 1 ; heap = new HeapedScorerDoc [ heapSize ] ; this . maxSize = maxSize ; topHSD = heap [ 1 ] ; } public final void put ( Scorer scorer ) { size ++ ; heap [ size ] = new HeapedScorerDoc ( scorer ) ; upHeap ( ) ; } public boolean insert ( Scorer scorer ) { if ( size < maxSize ) { put ( scorer ) ; return true ; } else { int docNr = scorer . doc ( ) ; if ( ( size > 0 ) && ( ! ( docNr < topHSD . doc ) ) ) { heap [ 1 ] = new HeapedScorerDoc ( scorer , docNr ) ; downHeap ( ) ; return true ; } else { return false ; } } } public final Scorer top ( ) { return topHSD . scorer ; } public final int topDoc ( ) { return topHSD . doc ; } public final float topScore ( ) throws IOException { return topHSD . scorer . score ( ) ; } public final boolean topNextAndAdjustElsePop ( ) throws IOException { return checkAdjustElsePop ( topHSD . scorer . next ( ) ) ; } public final boolean topSkipToAndAdjustElsePop ( int target ) throws IOException { return checkAdjustElsePop ( topHSD . scorer . skipTo ( target ) ) ; } private boolean checkAdjustElsePop ( boolean cond ) { if ( cond ) { topHSD . doc = topHSD . scorer . doc ( ) ; } else { heap [ 1 ] = heap [ size ] ; heap [ size ] = null ; size -- ; } downHeap ( ) ; return cond ; } public final Scorer pop ( ) { Scorer result = topHSD . scorer ; popNoResult ( ) ; return result ; } private final void popNoResult ( ) { heap [ 1 ] = heap [ size ] ; heap [ size ] = null ; size -- ; downHeap ( ) ; } public final void adjustTop ( ) { topHSD . adjust ( ) ; downHeap ( ) ; } public final int size ( ) { return size ; } public final void clear ( ) { for ( int i = 0 ; i <= size ; i ++ ) { heap [ i ] = null ; } size = 0 ; } private final void upHeap ( ) { int i = size ; HeapedScorerDoc node = heap [ i ] ; int j = i > > > 1 ; while ( ( j > 0 ) && ( node . doc < heap [ j ] . doc ) ) { heap [ i ] = heap [ j ] ; i = j ; j = j > > > 1 ; } heap [ i ] = node ; topHSD = heap [ 1 ] ; } private final void downHeap ( ) { int i = 1 ; HeapedScorerDoc node = heap [ i ] ; int j = i << 1 ; int k = j + 1 ; if ( ( k <= size ) && ( heap [ k ] . doc < heap [ j ] . doc ) ) { j = k ; } while ( ( j <= size ) && ( heap [ j ] . doc < node . doc ) ) { heap [ i ] = heap [ j ] ; i = j ; j = i << 1 ; k = j + 1 ; if ( k <= size && ( heap [ k ] . doc < heap [ j ] . doc ) ) { j = k ; } } heap [ i ] = node ; topHSD = heap [ 1 ] ; } } 	0	['16', '1', '0', '3', '24', '0', '2', '2', '12', '0.383333333', '361', '1', '2', '0', '0.328125', '0', '0', '21.3125', '7', '1.75', '0']
package org . apache . lucene . search ; public class DefaultSimilarity extends Similarity { public float lengthNorm ( String fieldName , int numTerms ) { return ( float ) ( 1.0 / Math . sqrt ( numTerms ) ) ; } public float queryNorm ( float sumOfSquaredWeights ) { return ( float ) ( 1.0 / Math . sqrt ( sumOfSquaredWeights ) ) ; } public float tf ( float freq ) { return ( float ) Math . sqrt ( freq ) ; } public float sloppyFreq ( int distance ) { return 1.0f / ( distance + 1 ) ; } public float idf ( int docFreq , int numDocs ) { return ( float ) ( Math . log ( numDocs / ( double ) ( docFreq + 1 ) ) + 1.0 ) ; } public float coord ( int overlap , int maxOverlap ) { return overlap / ( float ) maxOverlap ; } } 	0	['7', '2', '0', '3', '10', '21', '3', '1', '7', '2', '54', '0', '0', '0.714285714', '0.5', '1', '2', '6.714285714', '1', '0.8571', '0']
package org . apache . lucene . search ; import org . apache . lucene . util . PriorityQueue ; final class PhraseQueue extends PriorityQueue { PhraseQueue ( int size ) { initialize ( size ) ; } protected final boolean lessThan ( Object o1 , Object o2 ) { PhrasePositions pp1 = ( PhrasePositions ) o1 ; PhrasePositions pp2 = ( PhrasePositions ) o2 ; if ( pp1 . doc == pp2 . doc ) if ( pp1 . position == pp2 . position ) return pp1 . offset < pp2 . offset ; else return pp1 . position < pp2 . position ; else return pp1 . doc < pp2 . doc ; } } 	0	['2', '2', '0', '5', '4', '1', '3', '2', '0', '2', '51', '0', '0', '0.916666667', '0.666666667', '1', '3', '24.5', '6', '3', '0']
package org . apache . lucene . store ; public class AlreadyClosedException extends IllegalStateException { public AlreadyClosedException ( String message ) { super ( message ) ; } } 	0	['1', '5', '0', '4', '2', '0', '4', '0', '1', '2', '5', '0', '0', '1', '1', '0', '0', '4', '0', '0', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; public interface Spans { boolean next ( ) throws IOException ; boolean skipTo ( int target ) throws IOException ; int doc ( ) ; int start ( ) ; int end ( ) ; } 	0	['5', '1', '0', '20', '5', '10', '20', '0', '5', '2', '5', '0', '0', '0', '0.6', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . index ; import java . io . IOException ; final class SegmentMergeInfo { Term term ; int base ; TermEnum termEnum ; IndexReader reader ; private TermPositions postings ; private int [ ] docMap ; SegmentMergeInfo ( int b , TermEnum te , IndexReader r ) throws IOException { base = b ; reader = r ; termEnum = te ; term = te . term ( ) ; } int [ ] getDocMap ( ) { if ( docMap == null ) { if ( reader . hasDeletions ( ) ) { int maxDoc = reader . maxDoc ( ) ; docMap = new int [ maxDoc ] ; int j = 0 ; for ( int i = 0 ; i < maxDoc ; i ++ ) { if ( reader . isDeleted ( i ) ) docMap [ i ] = - 1 ; else docMap [ i ] = j ++ ; } } } return docMap ; } TermPositions getPositions ( ) throws IOException { if ( postings == null ) { postings = reader . termPositions ( ) ; } return postings ; } final boolean next ( ) throws IOException { if ( termEnum . next ( ) ) { term = termEnum . term ( ) ; return true ; } else { term = null ; return false ; } } final void close ( ) throws IOException { termEnum . close ( ) ; if ( postings != null ) { postings . close ( ) ; } } } 	0	['5', '1', '0', '7', '14', '0', '3', '4', '0', '0.75', '108', '0.333333333', '4', '0', '0.4', '0', '0', '19.4', '5', '1.6', '0']
package org . apache . lucene . index ; import java . io . IOException ; import org . apache . lucene . util . BitVector ; import org . apache . lucene . store . IndexInput ; class SegmentTermDocs implements TermDocs { protected SegmentReader parent ; protected IndexInput freqStream ; protected int count ; protected int df ; protected BitVector deletedDocs ; int doc = 0 ; int freq ; private int skipInterval ; private int maxSkipLevels ; private DefaultSkipListReader skipListReader ; private long freqBasePointer ; private long proxBasePointer ; private long skipPointer ; private boolean haveSkipped ; protected boolean currentFieldStoresPayloads ; protected SegmentTermDocs ( SegmentReader parent ) { this . parent = parent ; this . freqStream = ( IndexInput ) parent . freqStream . clone ( ) ; this . deletedDocs = parent . deletedDocs ; this . skipInterval = parent . tis . getSkipInterval ( ) ; this . maxSkipLevels = parent . tis . getMaxSkipLevels ( ) ; } public void seek ( Term term ) throws IOException { TermInfo ti = parent . tis . get ( term ) ; seek ( ti , term ) ; } public void seek ( TermEnum termEnum ) throws IOException { TermInfo ti ; Term term ; if ( termEnum instanceof SegmentTermEnum && ( ( SegmentTermEnum ) termEnum ) . fieldInfos == parent . fieldInfos ) { SegmentTermEnum segmentTermEnum = ( ( SegmentTermEnum ) termEnum ) ; term = segmentTermEnum . term ( ) ; ti = segmentTermEnum . termInfo ( ) ; } else { term = termEnum . term ( ) ; ti = parent . tis . get ( term ) ; } seek ( ti , term ) ; } void seek ( TermInfo ti , Term term ) throws IOException { count = 0 ; FieldInfo fi = parent . fieldInfos . fieldInfo ( term . field ) ; currentFieldStoresPayloads = ( fi != null ) ? fi . storePayloads : false ; if ( ti == null ) { df = 0 ; } else { df = ti . docFreq ; doc = 0 ; freqBasePointer = ti . freqPointer ; proxBasePointer = ti . proxPointer ; skipPointer = freqBasePointer + ti . skipOffset ; freqStream . seek ( freqBasePointer ) ; haveSkipped = false ; } } public void close ( ) throws IOException { freqStream . close ( ) ; if ( skipListReader != null ) skipListReader . close ( ) ; } public final int doc ( ) { return doc ; } public final int freq ( ) { return freq ; } protected void skippingDoc ( ) throws IOException { } public boolean next ( ) throws IOException { while ( true ) { if ( count == df ) return false ; int docCode = freqStream . readVInt ( ) ; doc += docCode > > > 1 ; if ( ( docCode & 1 ) != 0 ) freq = 1 ; else freq = freqStream . readVInt ( ) ; count ++ ; if ( deletedDocs == null || ! deletedDocs . get ( doc ) ) break ; skippingDoc ( ) ; } return true ; } public int read ( final int [ ] docs , final int [ ] freqs ) throws IOException { final int length = docs . length ; int i = 0 ; while ( i < length && count < df ) { final int docCode = freqStream . readVInt ( ) ; doc += docCode > > > 1 ; if ( ( docCode & 1 ) != 0 ) freq = 1 ; else freq = freqStream . readVInt ( ) ; count ++ ; if ( deletedDocs == null || ! deletedDocs . get ( doc ) ) { docs [ i ] = doc ; freqs [ i ] = freq ; ++ i ; } } return i ; } protected void skipProx ( long proxPointer , int payloadLength ) throws IOException { } public boolean skipTo ( int target ) throws IOException { if ( df >= skipInterval ) { if ( skipListReader == null ) skipListReader = new DefaultSkipListReader ( ( IndexInput ) freqStream . clone ( ) , maxSkipLevels , skipInterval ) ; if ( ! haveSkipped ) { skipListReader . init ( skipPointer , freqBasePointer , proxBasePointer , df , currentFieldStoresPayloads ) ; haveSkipped = true ; } int newCount = skipListReader . skipTo ( target ) ; if ( newCount > count ) { freqStream . seek ( skipListReader . getFreqPointer ( ) ) ; skipProx ( skipListReader . getProxPointer ( ) , skipListReader . getPayloadLength ( ) ) ; doc = skipListReader . getDoc ( ) ; count = newCount ; } } do { if ( ! next ( ) ) return false ; } while ( target > doc ) ; return true ; } } 	0	['12', '1', '1', '13', '33', '12', '2', '12', '8', '0.690909091', '377', '0.866666667', '4', '0', '0.21875', '0', '0', '29.16666667', '1', '0.9167', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public final class WhitespaceAnalyzer extends Analyzer { public TokenStream tokenStream ( String fieldName , Reader reader ) { return new WhitespaceTokenizer ( reader ) ; } } 	0	['2', '2', '0', '3', '4', '1', '0', '3', '2', '2', '10', '0', '0', '0.666666667', '0.666666667', '0', '0', '4', '1', '0.5', '0']
package org . apache . lucene . analysis . standard ; public class TokenMgrError extends Error { static final int LEXICAL_ERROR = 0 ; static final int STATIC_LEXER_ERROR = 1 ; static final int INVALID_LEXICAL_STATE = 2 ; static final int LOOP_DETECTED = 3 ; int errorCode ; protected static final String addEscapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( "\\b" ) ; continue ; case '\t' : retval . append ( "\\t" ) ; continue ; case '\n' : retval . append ( "\\n" ) ; continue ; case '\f' : retval . append ( "\\f" ) ; continue ; case '\r' : retval . append ( "\\r" ) ; continue ; case '\"' : retval . append ( "\\\"" ) ; continue ; case '\'' : retval . append ( "\\\'" ) ; continue ; case '\\' : retval . append ( "\\\\" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = "0000" + Integer . toString ( ch , 16 ) ; retval . append ( "\\u" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; } protected static String LexicalError ( boolean EOFSeen , int lexState , int errorLine , int errorColumn , String errorAfter , char curChar ) { return ( "Lexical error at line " + errorLine + ", column " + errorColumn + ".  Encountered: " + ( EOFSeen ? "<EOF> " : ( "\"" + addEscapes ( String . valueOf ( curChar ) ) + "\"" ) + " (" + ( int ) curChar + "), " ) + "after : \"" + addEscapes ( errorAfter ) + "\"" ) ; } public String getMessage ( ) { return super . getMessage ( ) ; } public TokenMgrError ( ) { } public TokenMgrError ( String message , int reason ) { super ( message ) ; errorCode = reason ; } public TokenMgrError ( boolean EOFSeen , int lexState , int errorLine , int errorColumn , String errorAfter , char curChar , int reason ) { this ( LexicalError ( EOFSeen , lexState , errorLine , errorColumn , errorAfter , curChar ) , reason ) ; } } 	0	['6', '3', '0', '1', '19', '15', '1', '0', '4', '1.12', '184', '0', '0', '0.8125', '0.5', '1', '1', '28.83333333', '14', '2.8333', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . * ; final class ExactPhraseScorer extends PhraseScorer { ExactPhraseScorer ( Weight weight , TermPositions [ ] tps , int [ ] offsets , Similarity similarity , byte [ ] norms ) { super ( weight , tps , offsets , similarity , norms ) ; } protected final float phraseFreq ( ) throws IOException { pq . clear ( ) ; for ( PhrasePositions pp = first ; pp != null ; pp = pp . next ) { pp . firstPosition ( ) ; pq . put ( pp ) ; } pqToList ( ) ; int freq = 0 ; do { while ( first . position < last . position ) { do { if ( ! first . nextPosition ( ) ) return ( float ) freq ; } while ( first . position < last . position ) ; firstToLast ( ) ; } freq ++ ; } while ( last . nextPosition ( ) ) ; return ( float ) freq ; } } 	0	['2', '3', '0', '8', '9', '1', '2', '6', '0', '2', '64', '0', '0', '0.952380952', '0.583333333', '1', '1', '31', '1', '0.5', '0']
package org . apache . lucene . search ; import java . io . IOException ; public class ReqExclScorer extends Scorer { private Scorer reqScorer , exclScorer ; public ReqExclScorer ( Scorer reqScorer , Scorer exclScorer ) { super ( null ) ; this . reqScorer = reqScorer ; this . exclScorer = exclScorer ; } private boolean firstTime = true ; public boolean next ( ) throws IOException { if ( firstTime ) { if ( ! exclScorer . next ( ) ) { exclScorer = null ; } firstTime = false ; } if ( reqScorer == null ) { return false ; } if ( ! reqScorer . next ( ) ) { reqScorer = null ; return false ; } if ( exclScorer == null ) { return true ; } return toNonExcluded ( ) ; } private boolean toNonExcluded ( ) throws IOException { int exclDoc = exclScorer . doc ( ) ; do { int reqDoc = reqScorer . doc ( ) ; if ( reqDoc < exclDoc ) { return true ; } else if ( reqDoc > exclDoc ) { if ( ! exclScorer . skipTo ( reqDoc ) ) { exclScorer = null ; return true ; } exclDoc = exclScorer . doc ( ) ; if ( exclDoc > reqDoc ) { return true ; } } } while ( reqScorer . next ( ) ) ; reqScorer = null ; return false ; } public int doc ( ) { return reqScorer . doc ( ) ; } public float score ( ) throws IOException { return reqScorer . score ( ) ; } public boolean skipTo ( int target ) throws IOException { if ( firstTime ) { firstTime = false ; if ( ! exclScorer . skipTo ( target ) ) { exclScorer = null ; } } if ( reqScorer == null ) { return false ; } if ( exclScorer == null ) { return reqScorer . skipTo ( target ) ; } if ( ! reqScorer . skipTo ( target ) ) { reqScorer = null ; return false ; } return toNonExcluded ( ) ; } public Explanation explain ( int doc ) throws IOException { Explanation res = new Explanation ( ) ; if ( exclScorer . skipTo ( doc ) && ( exclScorer . doc ( ) == doc ) ) { res . setDescription ( "excluded" ) ; } else { res . setDescription ( "not excluded" ) ; res . addDetail ( reqScorer . explain ( doc ) ) ; } return res ; } } 	0	['7', '2', '0', '4', '16', '0', '1', '3', '6', '0.333333333', '179', '1', '2', '0.571428571', '0.476190476', '1', '3', '24.14285714', '1', '0.8571', '0']
package org . apache . lucene . analysis . standard ; public class ParseException extends java . io . IOException { public ParseException ( Token currentTokenVal , int [ ] [ ] expectedTokenSequencesVal , String [ ] tokenImageVal ) { super ( "" ) ; specialConstructor = true ; currentToken = currentTokenVal ; expectedTokenSequences = expectedTokenSequencesVal ; tokenImage = tokenImageVal ; } public ParseException ( ) { super ( ) ; specialConstructor = false ; } public ParseException ( String message ) { super ( message ) ; specialConstructor = false ; } protected boolean specialConstructor ; public Token currentToken ; public int [ ] [ ] expectedTokenSequences ; public String [ ] tokenImage ; public String getMessage ( ) { if ( ! specialConstructor ) { return super . getMessage ( ) ; } String expected = "" ; int maxSize = 0 ; for ( int i = 0 ; i < expectedTokenSequences . length ; i ++ ) { if ( maxSize < expectedTokenSequences [ i ] . length ) { maxSize = expectedTokenSequences [ i ] . length ; } for ( int j = 0 ; j < expectedTokenSequences [ i ] . length ; j ++ ) { expected += tokenImage [ expectedTokenSequences [ i ] [ j ] ] + " " ; } if ( expectedTokenSequences [ i ] [ expectedTokenSequences [ i ] . length - 1 ] != 0 ) { expected += "..." ; } expected += eol + "    " ; } String retval = "Encountered \"" ; Token tok = currentToken . next ; for ( int i = 0 ; i < maxSize ; i ++ ) { if ( i != 0 ) retval += " " ; if ( tok . kind == 0 ) { retval += tokenImage [ 0 ] ; break ; } retval += add_escapes ( tok . image ) ; tok = tok . next ; } retval += "\" at line " + currentToken . next . beginLine + ", column " + currentToken . next . beginColumn + "." + eol ; if ( expectedTokenSequences . length == 1 ) { retval += "Was expecting:" + eol + "    " ; } else { retval += "Was expecting one of:" + eol + "    " ; } retval += expected ; return retval ; } protected String eol = System . getProperty ( "line.separator" , "\n" ) ; protected String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( "\\b" ) ; continue ; case '\t' : retval . append ( "\\t" ) ; continue ; case '\n' : retval . append ( "\\n" ) ; continue ; case '\f' : retval . append ( "\\f" ) ; continue ; case '\r' : retval . append ( "\\r" ) ; continue ; case '\"' : retval . append ( "\\\"" ) ; continue ; case '\'' : retval . append ( "\\\'" ) ; continue ; case '\\' : retval . append ( "\\\\" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = "0000" + Integer . toString ( ch , 16 ) ; retval . append ( "\\u" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; } } 	0	['5', '4', '0', '2', '18', '0', '1', '1', '4', '0.55', '380', '0.4', '1', '0.866666667', '0.4', '1', '1', '74', '14', '4.8', '0']
package org . apache . lucene . index ; class SegmentTermPositionVector extends SegmentTermVector implements TermPositionVector { protected int [ ] [ ] positions ; protected TermVectorOffsetInfo [ ] [ ] offsets ; public static final int [ ] EMPTY_TERM_POS = new int [ 0 ] ; public SegmentTermPositionVector ( String field , String terms [ ] , int termFreqs [ ] , int [ ] [ ] positions , TermVectorOffsetInfo [ ] [ ] offsets ) { super ( field , terms , termFreqs ) ; this . offsets = offsets ; this . positions = positions ; } public TermVectorOffsetInfo [ ] getOffsets ( int index ) { TermVectorOffsetInfo [ ] result = TermVectorOffsetInfo . EMPTY_OFFSET_INFO ; if ( offsets == null ) return null ; if ( index >= 0 && index < offsets . length ) { result = offsets [ index ] ; } return result ; } public int [ ] getTermPositions ( int index ) { int [ ] result = EMPTY_TERM_POS ; if ( positions == null ) return null ; if ( index >= 0 && index < positions . length ) { result = positions [ index ] ; } return result ; } } 	0	['4', '2', '0', '4', '5', '0', '1', '3', '3', '0.666666667', '65', '0.666666667', '1', '0.777777778', '0.476190476', '0', '0', '14.5', '4', '2', '0']
package org . apache . lucene . search ; import org . apache . lucene . util . PriorityQueue ; final class HitQueue extends PriorityQueue { HitQueue ( int size ) { initialize ( size ) ; } protected final boolean lessThan ( Object a , Object b ) { ScoreDoc hitA = ( ScoreDoc ) a ; ScoreDoc hitB = ( ScoreDoc ) b ; if ( hitA . score == hitB . score ) return hitA . doc > hitB . doc ; else return hitA . score < hitB . score ; } } 	0	['2', '2', '0', '6', '4', '1', '4', '2', '0', '2', '39', '0', '0', '0.916666667', '0.666666667', '1', '3', '18.5', '4', '2', '0']
package org . apache . lucene . search ; import java . io . IOException ; class NonMatchingScorer extends Scorer { public NonMatchingScorer ( ) { super ( null ) ; } public int doc ( ) { throw new UnsupportedOperationException ( ) ; } public boolean next ( ) throws IOException { return false ; } public float score ( ) { throw new UnsupportedOperationException ( ) ; } public boolean skipTo ( int target ) { return false ; } public Explanation explain ( int doc ) { Explanation e = new Explanation ( ) ; e . setDescription ( "No document matches." ) ; return e ; } } 	0	['6', '2', '0', '4', '10', '15', '1', '3', '6', '2', '31', '0', '0', '0.615384615', '0.666666667', '1', '3', '4.166666667', '1', '0.8333', '0']
package org . apache . lucene . index ; import java . io . IOException ; public class StaleReaderException extends IOException { public StaleReaderException ( String message ) { super ( message ) ; } } 	0	['1', '4', '0', '2', '2', '0', '2', '0', '1', '2', '5', '0', '0', '1', '1', '0', '0', '4', '0', '0', '0']
package org . apache . lucene . search . spans ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . search . * ; import java . io . IOException ; import java . util . HashSet ; import java . util . Iterator ; import java . util . Set ; public class SpanWeight implements Weight { protected Similarity similarity ; protected float value ; protected float idf ; protected float queryNorm ; protected float queryWeight ; protected Set terms ; protected SpanQuery query ; public SpanWeight ( SpanQuery query , Searcher searcher ) throws IOException { this . similarity = query . getSimilarity ( searcher ) ; this . query = query ; terms = new HashSet ( ) ; query . extractTerms ( terms ) ; idf = this . query . getSimilarity ( searcher ) . idf ( terms , searcher ) ; } public Query getQuery ( ) { return query ; } public float getValue ( ) { return value ; } public float sumOfSquaredWeights ( ) throws IOException { queryWeight = idf * query . getBoost ( ) ; return queryWeight * queryWeight ; } public void normalize ( float queryNorm ) { this . queryNorm = queryNorm ; queryWeight *= queryNorm ; value = queryWeight * idf ; } public Scorer scorer ( IndexReader reader ) throws IOException { return new SpanScorer ( query . getSpans ( reader ) , this , similarity , reader . norms ( query . getField ( ) ) ) ; } public Explanation explain ( IndexReader reader , int doc ) throws IOException { ComplexExplanation result = new ComplexExplanation ( ) ; result . setDescription ( "weight(" + getQuery ( ) + " in " + doc + "), product of:" ) ; String field = ( ( SpanQuery ) getQuery ( ) ) . getField ( ) ; StringBuffer docFreqs = new StringBuffer ( ) ; Iterator i = terms . iterator ( ) ; while ( i . hasNext ( ) ) { Term term = ( Term ) i . next ( ) ; docFreqs . append ( term . text ( ) ) ; docFreqs . append ( "=" ) ; docFreqs . append ( reader . docFreq ( term ) ) ; if ( i . hasNext ( ) ) { docFreqs . append ( " " ) ; } } Explanation idfExpl = new Explanation ( idf , "idf(" + field + ": " + docFreqs + ")" ) ; Explanation queryExpl = new Explanation ( ) ; queryExpl . setDescription ( "queryWeight(" + getQuery ( ) + "), product of:" ) ; Explanation boostExpl = new Explanation ( getQuery ( ) . getBoost ( ) , "boost" ) ; if ( getQuery ( ) . getBoost ( ) != 1.0f ) queryExpl . addDetail ( boostExpl ) ; queryExpl . addDetail ( idfExpl ) ; Explanation queryNormExpl = new Explanation ( queryNorm , "queryNorm" ) ; queryExpl . addDetail ( queryNormExpl ) ; queryExpl . setValue ( boostExpl . getValue ( ) * idfExpl . getValue ( ) * queryNormExpl . getValue ( ) ) ; result . addDetail ( queryExpl ) ; ComplexExplanation fieldExpl = new ComplexExplanation ( ) ; fieldExpl . setDescription ( "fieldWeight(" + field + ":" + query . toString ( field ) + " in " + doc + "), product of:" ) ; Explanation tfExpl = scorer ( reader ) . explain ( doc ) ; fieldExpl . addDetail ( tfExpl ) ; fieldExpl . addDetail ( idfExpl ) ; Explanation fieldNormExpl = new Explanation ( ) ; byte [ ] fieldNorms = reader . norms ( field ) ; float fieldNorm = fieldNorms != null ? Similarity . decodeNorm ( fieldNorms [ doc ] ) : 0.0f ; fieldNormExpl . setValue ( fieldNorm ) ; fieldNormExpl . setDescription ( "fieldNorm(field=" + field + ", doc=" + doc + ")" ) ; fieldExpl . addDetail ( fieldNormExpl ) ; fieldExpl . setMatch ( Boolean . valueOf ( tfExpl . isMatch ( ) ) ) ; fieldExpl . setValue ( tfExpl . getValue ( ) * idfExpl . getValue ( ) * fieldNormExpl . getValue ( ) ) ; result . addDetail ( fieldExpl ) ; result . setMatch ( fieldExpl . getMatch ( ) ) ; result . setValue ( queryExpl . getValue ( ) * fieldExpl . getValue ( ) ) ; if ( queryExpl . getValue ( ) == 1.0f ) return fieldExpl ; return result ; } } 	0	['7', '1', '1', '13', '46', '0', '2', '12', '7', '0.69047619', '357', '1', '2', '0', '0.30952381', '0', '0', '49', '1', '0.8571', '0']
package org . apache . lucene . index ; import java . io . IOException ; import java . util . Arrays ; import org . apache . lucene . store . IndexOutput ; class DefaultSkipListWriter extends MultiLevelSkipListWriter { private int [ ] lastSkipDoc ; private int [ ] lastSkipPayloadLength ; private long [ ] lastSkipFreqPointer ; private long [ ] lastSkipProxPointer ; private IndexOutput freqOutput ; private IndexOutput proxOutput ; private int curDoc ; private boolean curStorePayloads ; private int curPayloadLength ; private long curFreqPointer ; private long curProxPointer ; DefaultSkipListWriter ( int skipInterval , int numberOfSkipLevels , int docCount , IndexOutput freqOutput , IndexOutput proxOutput ) { super ( skipInterval , numberOfSkipLevels , docCount ) ; this . freqOutput = freqOutput ; this . proxOutput = proxOutput ; lastSkipDoc = new int [ numberOfSkipLevels ] ; lastSkipPayloadLength = new int [ numberOfSkipLevels ] ; lastSkipFreqPointer = new long [ numberOfSkipLevels ] ; lastSkipProxPointer = new long [ numberOfSkipLevels ] ; } void setSkipData ( int doc , boolean storePayloads , int payloadLength ) { this . curDoc = doc ; this . curStorePayloads = storePayloads ; this . curPayloadLength = payloadLength ; this . curFreqPointer = freqOutput . getFilePointer ( ) ; this . curProxPointer = proxOutput . getFilePointer ( ) ; } protected void resetSkip ( ) { super . resetSkip ( ) ; Arrays . fill ( lastSkipDoc , 0 ) ; Arrays . fill ( lastSkipPayloadLength , - 1 ) ; Arrays . fill ( lastSkipFreqPointer , freqOutput . getFilePointer ( ) ) ; Arrays . fill ( lastSkipProxPointer , proxOutput . getFilePointer ( ) ) ; } protected void writeSkipData ( int level , IndexOutput skipBuffer ) throws IOException { if ( curStorePayloads ) { int delta = curDoc - lastSkipDoc [ level ] ; if ( curPayloadLength == lastSkipPayloadLength [ level ] ) { skipBuffer . writeVInt ( delta * 2 ) ; } else { skipBuffer . writeVInt ( delta * 2 + 1 ) ; skipBuffer . writeVInt ( curPayloadLength ) ; lastSkipPayloadLength [ level ] = curPayloadLength ; } } else { skipBuffer . writeVInt ( curDoc - lastSkipDoc [ level ] ) ; } skipBuffer . writeVInt ( ( int ) ( curFreqPointer - lastSkipFreqPointer [ level ] ) ) ; skipBuffer . writeVInt ( ( int ) ( curProxPointer - lastSkipProxPointer [ level ] ) ) ; lastSkipDoc [ level ] = curDoc ; lastSkipFreqPointer [ level ] = curFreqPointer ; lastSkipProxPointer [ level ] = curProxPointer ; } } 	0	['4', '2', '0', '3', '10', '0', '1', '2', '0', '0.484848485', '176', '1', '2', '0.625', '0.625', '1', '1', '40.25', '1', '0.75', '0']
package org . apache . lucene . analysis . standard ; public interface StandardTokenizerConstants { int EOF = 0 ; int ALPHANUM = 1 ; int APOSTROPHE = 2 ; int ACRONYM = 3 ; int COMPANY = 4 ; int EMAIL = 5 ; int HOST = 6 ; int NUM = 7 ; int P = 8 ; int HAS_DIGIT = 9 ; int ALPHA = 10 ; int LETTER = 11 ; int CJ = 12 ; int KOREAN = 13 ; int DIGIT = 14 ; int NOISE = 15 ; int DEFAULT = 0 ; String [ ] tokenImage = { "<EOF>" , "<ALPHANUM>" , "<APOSTROPHE>" , "<ACRONYM>" , "<COMPANY>" , "<EMAIL>" , "<HOST>" , "<NUM>" , "<P>" , "<HAS_DIGIT>" , "<ALPHA>" , "<LETTER>" , "<CJ>" , "<KOREAN>" , "<DIGIT>" , "<NOISE>" , } ; } 	0	['1', '1', '0', '3', '1', '0', '3', '0', '0', '2', '87', '0', '0', '0', '0', '0', '0', '68', '0', '0', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import java . io . IOException ; public abstract class SortComparator implements SortComparatorSource { public ScoreDocComparator newComparator ( final IndexReader reader , final String fieldname ) throws IOException { final String field = fieldname . intern ( ) ; final Comparable [ ] cachedValues = FieldCache . DEFAULT . getCustom ( reader , field , SortComparator . this ) ; return new ScoreDocComparator ( ) { public int compare ( ScoreDoc i , ScoreDoc j ) { return cachedValues [ i . doc ] . compareTo ( cachedValues [ j . doc ] ) ; } public Comparable sortValue ( ScoreDoc i ) { return cachedValues [ i . doc ] ; } public int sortType ( ) { return SortField . CUSTOM ; } } ; } protected abstract Comparable getComparable ( String termtext ) ; } 	0	['3', '1', '0', '7', '7', '3', '4', '5', '2', '2', '21', '0', '0', '0', '0.666666667', '0', '0', '6', '1', '0.6667', '0']
package org . apache . lucene . index ; import java . io . IOException ; public abstract class TermEnum { public abstract boolean next ( ) throws IOException ; public abstract Term term ( ) ; public abstract int docFreq ( ) ; public abstract void close ( ) throws IOException ; public boolean skipTo ( Term target ) throws IOException { do { if ( ! next ( ) ) return false ; } while ( target . compareTo ( term ( ) ) > 0 ) ; return true ; } } 	0	['6', '1', '5', '33', '8', '15', '32', '1', '6', '2', '21', '0', '0', '0', '0.583333333', '0', '0', '2.5', '1', '0.8333', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . TermDocs ; final class TermScorer extends Scorer { private Weight weight ; private TermDocs termDocs ; private byte [ ] norms ; private float weightValue ; private int doc ; private final int [ ] docs = new int [ 32 ] ; private final int [ ] freqs = new int [ 32 ] ; private int pointer ; private int pointerMax ; private static final int SCORE_CACHE_SIZE = 32 ; private float [ ] scoreCache = new float [ SCORE_CACHE_SIZE ] ; TermScorer ( Weight weight , TermDocs td , Similarity similarity , byte [ ] norms ) { super ( similarity ) ; this . weight = weight ; this . termDocs = td ; this . norms = norms ; this . weightValue = weight . getValue ( ) ; for ( int i = 0 ; i < SCORE_CACHE_SIZE ; i ++ ) scoreCache [ i ] = getSimilarity ( ) . tf ( i ) * weightValue ; } public void score ( HitCollector hc ) throws IOException { next ( ) ; score ( hc , Integer . MAX_VALUE ) ; } protected boolean score ( HitCollector c , int end ) throws IOException { Similarity similarity = getSimilarity ( ) ; float [ ] normDecoder = Similarity . getNormDecoder ( ) ; while ( doc < end ) { int f = freqs [ pointer ] ; float score = f < SCORE_CACHE_SIZE ? scoreCache [ f ] : similarity . tf ( f ) * weightValue ; score *= normDecoder [ norms [ doc ] & 0xFF ] ; c . collect ( doc , score ) ; if ( ++ pointer >= pointerMax ) { pointerMax = termDocs . read ( docs , freqs ) ; if ( pointerMax != 0 ) { pointer = 0 ; } else { termDocs . close ( ) ; doc = Integer . MAX_VALUE ; return false ; } } doc = docs [ pointer ] ; } return true ; } public int doc ( ) { return doc ; } public boolean next ( ) throws IOException { pointer ++ ; if ( pointer >= pointerMax ) { pointerMax = termDocs . read ( docs , freqs ) ; if ( pointerMax != 0 ) { pointer = 0 ; } else { termDocs . close ( ) ; doc = Integer . MAX_VALUE ; return false ; } } doc = docs [ pointer ] ; return true ; } public float score ( ) { int f = freqs [ pointer ] ; float raw = f < SCORE_CACHE_SIZE ? scoreCache [ f ] : getSimilarity ( ) . tf ( f ) * weightValue ; return raw * Similarity . decodeNorm ( norms [ doc ] ) ; } public boolean skipTo ( int target ) throws IOException { for ( pointer ++ ; pointer < pointerMax ; pointer ++ ) { if ( docs [ pointer ] >= target ) { doc = docs [ pointer ] ; return true ; } } boolean result = termDocs . skipTo ( target ) ; if ( result ) { pointerMax = 1 ; pointer = 0 ; docs [ pointer ] = doc = termDocs . doc ( ) ; freqs [ pointer ] = termDocs . freq ( ) ; } else { doc = Integer . MAX_VALUE ; } return result ; } public Explanation explain ( int doc ) throws IOException { TermQuery query = ( TermQuery ) weight . getQuery ( ) ; Explanation tfExplanation = new Explanation ( ) ; int tf = 0 ; while ( pointer < pointerMax ) { if ( docs [ pointer ] == doc ) tf = freqs [ pointer ] ; pointer ++ ; } if ( tf == 0 ) { if ( termDocs . skipTo ( doc ) ) { if ( termDocs . doc ( ) == doc ) { tf = termDocs . freq ( ) ; } } } termDocs . close ( ) ; tfExplanation . setValue ( getSimilarity ( ) . tf ( tf ) ) ; tfExplanation . setDescription ( "tf(termFreq(" + query . getTerm ( ) + ")=" + tf + ")" ) ; return tfExplanation ; } public String toString ( ) { return "scorer(" + weight + ")" ; } } 	0	['9', '2', '0', '10', '31', '0', '1', '9', '7', '0.545454545', '409', '1', '2', '0.5', '0.285714286', '1', '3', '43.22222222', '2', '1', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermEnum ; public abstract class FilteredTermEnum extends TermEnum { private Term currentTerm = null ; private TermEnum actualEnum = null ; public FilteredTermEnum ( ) { } protected abstract boolean termCompare ( Term term ) ; public abstract float difference ( ) ; protected abstract boolean endEnum ( ) ; protected void setEnum ( TermEnum actualEnum ) throws IOException { this . actualEnum = actualEnum ; Term term = actualEnum . term ( ) ; if ( term != null && termCompare ( term ) ) currentTerm = term ; else next ( ) ; } public int docFreq ( ) { if ( actualEnum == null ) return - 1 ; return actualEnum . docFreq ( ) ; } public boolean next ( ) throws IOException { if ( actualEnum == null ) return false ; currentTerm = null ; while ( currentTerm == null ) { if ( endEnum ( ) ) return false ; if ( actualEnum . next ( ) ) { Term term = actualEnum . term ( ) ; if ( termCompare ( term ) ) { currentTerm = term ; return true ; } } else return false ; } currentTerm = null ; return false ; } public Term term ( ) { return currentTerm ; } public void close ( ) throws IOException { actualEnum . close ( ) ; currentTerm = null ; actualEnum = null ; } } 	0	['9', '2', '2', '7', '14', '8', '5', '2', '6', '0.5', '103', '1', '2', '0.384615385', '0.407407407', '1', '2', '10.22222222', '2', '1', '0']
package org . apache . lucene . index ; import java . io . IOException ; public interface TermDocs { void seek ( Term term ) throws IOException ; void seek ( TermEnum termEnum ) throws IOException ; int doc ( ) ; int freq ( ) ; boolean next ( ) throws IOException ; int read ( int [ ] docs , int [ ] freqs ) throws IOException ; boolean skipTo ( int target ) throws IOException ; void close ( ) throws IOException ; } 	0	['8', '1', '0', '27', '8', '28', '25', '2', '8', '2', '8', '0', '0', '0', '0.3', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; import java . util . Map ; import java . util . HashMap ; public class PerFieldAnalyzerWrapper extends Analyzer { private Analyzer defaultAnalyzer ; private Map analyzerMap = new HashMap ( ) ; public PerFieldAnalyzerWrapper ( Analyzer defaultAnalyzer ) { this . defaultAnalyzer = defaultAnalyzer ; } public void addAnalyzer ( String fieldName , Analyzer analyzer ) { analyzerMap . put ( fieldName , analyzer ) ; } public TokenStream tokenStream ( String fieldName , Reader reader ) { Analyzer analyzer = ( Analyzer ) analyzerMap . get ( fieldName ) ; if ( analyzer == null ) { analyzer = defaultAnalyzer ; } return analyzer . tokenStream ( fieldName , reader ) ; } public int getPositionIncrementGap ( String fieldName ) { Analyzer analyzer = ( Analyzer ) analyzerMap . get ( fieldName ) ; if ( analyzer == null ) analyzer = defaultAnalyzer ; return analyzer . getPositionIncrementGap ( fieldName ) ; } public String toString ( ) { return "PerFieldAnalyzerWrapper(" + analyzerMap + ", default=" + defaultAnalyzer + ")" ; } } 	0	['5', '2', '0', '2', '15', '0', '0', '2', '5', '0.125', '73', '1', '1', '0.333333333', '0.55', '0', '0', '13.2', '2', '1.2', '0']
package org . apache . lucene . search ; public abstract class HitCollector { public abstract void collect ( int doc , float score ) ; } 	0	['2', '1', '6', '22', '3', '1', '22', '0', '2', '2', '5', '0', '0', '0', '0.666666667', '0', '0', '1.5', '1', '0.5', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public class WhitespaceTokenizer extends CharTokenizer { public WhitespaceTokenizer ( Reader in ) { super ( in ) ; } protected boolean isTokenChar ( char c ) { return ! Character . isWhitespace ( c ) ; } } 	0	['2', '4', '0', '2', '4', '1', '1', '1', '1', '2', '13', '0', '0', '0.875', '0.666666667', '1', '1', '5.5', '2', '1', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . util . ToStringUtils ; public class SpanNotQuery extends SpanQuery { private SpanQuery include ; private SpanQuery exclude ; public SpanNotQuery ( SpanQuery include , SpanQuery exclude ) { this . include = include ; this . exclude = exclude ; if ( ! include . getField ( ) . equals ( exclude . getField ( ) ) ) throw new IllegalArgumentException ( "Clauses must have same field." ) ; } public SpanQuery getInclude ( ) { return include ; } public SpanQuery getExclude ( ) { return exclude ; } public String getField ( ) { return include . getField ( ) ; } public Collection getTerms ( ) { return include . getTerms ( ) ; } public void extractTerms ( Set terms ) { include . extractTerms ( terms ) ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "spanNot(" ) ; buffer . append ( include . toString ( field ) ) ; buffer . append ( ", " ) ; buffer . append ( exclude . toString ( field ) ) ; buffer . append ( ")" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public Spans getSpans ( final IndexReader reader ) throws IOException { return new Spans ( ) { private Spans includeSpans = include . getSpans ( reader ) ; private boolean moreInclude = true ; private Spans excludeSpans = exclude . getSpans ( reader ) ; private boolean moreExclude = excludeSpans . next ( ) ; public boolean next ( ) throws IOException { if ( moreInclude ) moreInclude = includeSpans . next ( ) ; while ( moreInclude && moreExclude ) { if ( includeSpans . doc ( ) > excludeSpans . doc ( ) ) moreExclude = excludeSpans . skipTo ( includeSpans . doc ( ) ) ; while ( moreExclude && includeSpans . doc ( ) == excludeSpans . doc ( ) && excludeSpans . end ( ) <= includeSpans . start ( ) ) { moreExclude = excludeSpans . next ( ) ; } if ( ! moreExclude || includeSpans . doc ( ) != excludeSpans . doc ( ) || includeSpans . end ( ) <= excludeSpans . start ( ) ) break ; moreInclude = includeSpans . next ( ) ; } return moreInclude ; } public boolean skipTo ( int target ) throws IOException { if ( moreInclude ) moreInclude = includeSpans . skipTo ( target ) ; if ( ! moreInclude ) return false ; if ( moreExclude && includeSpans . doc ( ) > excludeSpans . doc ( ) ) moreExclude = excludeSpans . skipTo ( includeSpans . doc ( ) ) ; while ( moreExclude && includeSpans . doc ( ) == excludeSpans . doc ( ) && excludeSpans . end ( ) <= includeSpans . start ( ) ) { moreExclude = excludeSpans . next ( ) ; } if ( ! moreExclude || includeSpans . doc ( ) != excludeSpans . doc ( ) || includeSpans . end ( ) <= excludeSpans . start ( ) ) return true ; return next ( ) ; } public int doc ( ) { return includeSpans . doc ( ) ; } public int start ( ) { return includeSpans . start ( ) ; } public int end ( ) { return includeSpans . end ( ) ; } public String toString ( ) { return "spans(" + SpanNotQuery . this . toString ( ) + ")" ; } } ; } public Query rewrite ( IndexReader reader ) throws IOException { SpanNotQuery clone = null ; SpanQuery rewrittenInclude = ( SpanQuery ) include . rewrite ( reader ) ; if ( rewrittenInclude != include ) { clone = ( SpanNotQuery ) this . clone ( ) ; clone . include = rewrittenInclude ; } SpanQuery rewrittenExclude = ( SpanQuery ) exclude . rewrite ( reader ) ; if ( rewrittenExclude != exclude ) { if ( clone == null ) clone = ( SpanNotQuery ) this . clone ( ) ; clone . exclude = rewrittenExclude ; } if ( clone != null ) { return clone ; } else { return this ; } } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof SpanNotQuery ) ) return false ; SpanNotQuery other = ( SpanNotQuery ) o ; return this . include . equals ( other . include ) && this . exclude . equals ( other . exclude ) && this . getBoost ( ) == other . getBoost ( ) ; } public int hashCode ( ) { int h = include . hashCode ( ) ; h = ( h << 1 ) | ( h > > > 31 ) ; h ^= exclude . hashCode ( ) ; h = ( h << 1 ) | ( h > > > 31 ) ; h ^= Float . floatToRawIntBits ( getBoost ( ) ) ; return h ; } } 	0	['13', '3', '0', '6', '31', '0', '1', '6', '11', '0.375', '218', '1', '2', '0.571428571', '0.208791209', '2', '2', '15.61538462', '6', '1.3077', '0']
package org . apache . lucene . search ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . FieldSelector ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . CorruptIndexException ; import java . io . IOException ; import java . rmi . Naming ; import java . rmi . RMISecurityManager ; import java . rmi . RemoteException ; import java . rmi . server . UnicastRemoteObject ; public class RemoteSearchable extends UnicastRemoteObject implements Searchable { private Searchable local ; public RemoteSearchable ( Searchable local ) throws RemoteException { super ( ) ; this . local = local ; } public void search ( Weight weight , Filter filter , HitCollector results ) throws IOException { local . search ( weight , filter , results ) ; } public void close ( ) throws IOException { local . close ( ) ; } public int docFreq ( Term term ) throws IOException { return local . docFreq ( term ) ; } public int [ ] docFreqs ( Term [ ] terms ) throws IOException { return local . docFreqs ( terms ) ; } public int maxDoc ( ) throws IOException { return local . maxDoc ( ) ; } public TopDocs search ( Weight weight , Filter filter , int n ) throws IOException { return local . search ( weight , filter , n ) ; } public TopFieldDocs search ( Weight weight , Filter filter , int n , Sort sort ) throws IOException { return local . search ( weight , filter , n , sort ) ; } public Document doc ( int i ) throws CorruptIndexException , IOException { return local . doc ( i ) ; } public Document doc ( int i , FieldSelector fieldSelector ) throws CorruptIndexException , IOException { return local . doc ( i , fieldSelector ) ; } public Query rewrite ( Query original ) throws IOException { return local . rewrite ( original ) ; } public Explanation explain ( Weight weight , int doc ) throws IOException { return local . explain ( weight , doc ) ; } public static void main ( String args [ ] ) throws Exception { String indexName = null ; if ( args != null && args . length == 1 ) indexName = args [ 0 ] ; if ( indexName == null ) { System . out . println ( "Usage: org.apache.lucene.search.RemoteSearchable <index>" ) ; return ; } if ( System . getSecurityManager ( ) == null ) { System . setSecurityManager ( new RMISecurityManager ( ) ) ; } Searchable local = new IndexSearcher ( indexName ) ; RemoteSearchable impl = new RemoteSearchable ( local ) ; Naming . rebind ( "//localhost/Searchable" , impl ) ; } } 	0	['13', '4', '0', '14', '31', '0', '0', '14', '13', '0', '120', '1', '1', '0.6', '0.205128205', '0', '0', '8.153846154', '1', '0.9231', '0']
package org . apache . lucene . index ; public interface TermFreqVector { public String getField ( ) ; public int size ( ) ; public String [ ] getTerms ( ) ; public int [ ] getTermFrequencies ( ) ; public int indexOf ( String term ) ; public int [ ] indexesOf ( String [ ] terms , int start , int len ) ; } 	0	['6', '1', '0', '11', '6', '15', '11', '0', '6', '2', '6', '0', '0', '0', '0.375', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . List ; import java . util . Collection ; import java . util . ArrayList ; import java . util . Iterator ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . util . PriorityQueue ; import org . apache . lucene . util . ToStringUtils ; import org . apache . lucene . search . Query ; public class SpanOrQuery extends SpanQuery { private List clauses ; private String field ; public SpanOrQuery ( SpanQuery [ ] clauses ) { this . clauses = new ArrayList ( clauses . length ) ; for ( int i = 0 ; i < clauses . length ; i ++ ) { SpanQuery clause = clauses [ i ] ; if ( i == 0 ) { field = clause . getField ( ) ; } else if ( ! clause . getField ( ) . equals ( field ) ) { throw new IllegalArgumentException ( "Clauses must have same field." ) ; } this . clauses . add ( clause ) ; } } public SpanQuery [ ] getClauses ( ) { return ( SpanQuery [ ] ) clauses . toArray ( new SpanQuery [ clauses . size ( ) ] ) ; } public String getField ( ) { return field ; } public Collection getTerms ( ) { Collection terms = new ArrayList ( ) ; Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { SpanQuery clause = ( SpanQuery ) i . next ( ) ; terms . addAll ( clause . getTerms ( ) ) ; } return terms ; } public void extractTerms ( Set terms ) { Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { SpanQuery clause = ( SpanQuery ) i . next ( ) ; clause . extractTerms ( terms ) ; } } public Query rewrite ( IndexReader reader ) throws IOException { SpanOrQuery clone = null ; for ( int i = 0 ; i < clauses . size ( ) ; i ++ ) { SpanQuery c = ( SpanQuery ) clauses . get ( i ) ; SpanQuery query = ( SpanQuery ) c . rewrite ( reader ) ; if ( query != c ) { if ( clone == null ) clone = ( SpanOrQuery ) this . clone ( ) ; clone . clauses . set ( i , query ) ; } } if ( clone != null ) { return clone ; } else { return this ; } } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "spanOr([" ) ; Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { SpanQuery clause = ( SpanQuery ) i . next ( ) ; buffer . append ( clause . toString ( field ) ) ; if ( i . hasNext ( ) ) { buffer . append ( ", " ) ; } } buffer . append ( "])" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; final SpanOrQuery that = ( SpanOrQuery ) o ; if ( ! clauses . equals ( that . clauses ) ) return false ; if ( ! field . equals ( that . field ) ) return false ; return getBoost ( ) == that . getBoost ( ) ; } public int hashCode ( ) { int h = clauses . hashCode ( ) ; h ^= ( h << 10 ) | ( h > > > 23 ) ; h ^= Float . floatToRawIntBits ( getBoost ( ) ) ; return h ; } private class SpanQueue extends PriorityQueue { public SpanQueue ( int size ) { initialize ( size ) ; } protected final boolean lessThan ( Object o1 , Object o2 ) { Spans spans1 = ( Spans ) o1 ; Spans spans2 = ( Spans ) o2 ; if ( spans1 . doc ( ) == spans2 . doc ( ) ) { if ( spans1 . start ( ) == spans2 . start ( ) ) { return spans1 . end ( ) < spans2 . end ( ) ; } else { return spans1 . start ( ) < spans2 . start ( ) ; } } else { return spans1 . doc ( ) < spans2 . doc ( ) ; } } } public Spans getSpans ( final IndexReader reader ) throws IOException { if ( clauses . size ( ) == 1 ) return ( ( SpanQuery ) clauses . get ( 0 ) ) . getSpans ( reader ) ; return new Spans ( ) { private SpanQueue queue = null ; private boolean initSpanQueue ( int target ) throws IOException { queue = new SpanQueue ( clauses . size ( ) ) ; Iterator i = clauses . iterator ( ) ; while ( i . hasNext ( ) ) { Spans spans = ( ( SpanQuery ) i . next ( ) ) . getSpans ( reader ) ; if ( ( ( target == - 1 ) && spans . next ( ) ) || ( ( target != - 1 ) && spans . skipTo ( target ) ) ) { queue . put ( spans ) ; } } return queue . size ( ) != 0 ; } public boolean next ( ) throws IOException { if ( queue == null ) { return initSpanQueue ( - 1 ) ; } if ( queue . size ( ) == 0 ) { return false ; } if ( top ( ) . next ( ) ) { queue . adjustTop ( ) ; return true ; } queue . pop ( ) ; return queue . size ( ) != 0 ; } private Spans top ( ) { return ( Spans ) queue . top ( ) ; } public boolean skipTo ( int target ) throws IOException { if ( queue == null ) { return initSpanQueue ( target ) ; } while ( queue . size ( ) != 0 && top ( ) . doc ( ) < target ) { if ( top ( ) . skipTo ( target ) ) { queue . adjustTop ( ) ; } else { queue . pop ( ) ; } } return queue . size ( ) != 0 ; } public int doc ( ) { return top ( ) . doc ( ) ; } public int start ( ) { return top ( ) . start ( ) ; } public int end ( ) { return top ( ) . end ( ) ; } public String toString ( ) { return "spans(" + SpanOrQuery . this + ")@" + ( ( queue == null ) ? "START" : ( queue . size ( ) > 0 ? ( doc ( ) + ":" + start ( ) + "-" + end ( ) ) : "END" ) ) ; } } ; } } 	0	['11', '3', '0', '8', '42', '0', '3', '6', '10', '0.45', '286', '1', '0', '0.615384615', '0.220779221', '2', '2', '24.81818182', '7', '1.7273', '0']
package org . apache . lucene . store ; import java . io . IOException ; public class NoLockFactory extends LockFactory { private static NoLock singletonLock = new NoLock ( ) ; private static NoLockFactory singleton = new NoLockFactory ( ) ; public static NoLockFactory getNoLockFactory ( ) { return singleton ; } public Lock makeLock ( String lockName ) { return singletonLock ; } public void clearLock ( String lockName ) { } ; } ; class NoLock extends Lock { public boolean obtain ( ) throws IOException { return true ; } public void release ( ) { } public boolean isLocked ( ) { return false ; } public String toString ( ) { return "NoLock" ; } } 	0	['5', '2', '0', '4', '7', '6', '1', '3', '4', '0.75', '24', '1', '2', '0.571428571', '0.625', '0', '0', '3.4', '1', '0.6', '0']
package org . apache . lucene . search ; public class ScoreDoc implements java . io . Serializable { public float score ; public int doc ; public ScoreDoc ( int doc , float score ) { this . doc = doc ; this . score = score ; } } 	0	['1', '1', '1', '19', '2', '0', '19', '0', '1', '2', '12', '0', '0', '0', '1', '0', '0', '9', '0', '0', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Arrays ; import java . util . Comparator ; import org . apache . lucene . index . IndexReader ; class NearSpansOrdered implements Spans { private final int allowedSlop ; private boolean firstTime = true ; private boolean more = false ; private final Spans [ ] subSpans ; private boolean inSameDoc = false ; private int matchDoc = - 1 ; private int matchStart = - 1 ; private int matchEnd = - 1 ; private final Spans [ ] subSpansByDoc ; private final Comparator spanDocComparator = new Comparator ( ) { public int compare ( Object o1 , Object o2 ) { return ( ( Spans ) o1 ) . doc ( ) - ( ( Spans ) o2 ) . doc ( ) ; } } ; private SpanNearQuery query ; public NearSpansOrdered ( SpanNearQuery spanNearQuery , IndexReader reader ) throws IOException { if ( spanNearQuery . getClauses ( ) . length < 2 ) { throw new IllegalArgumentException ( "Less than 2 clauses: " + spanNearQuery ) ; } allowedSlop = spanNearQuery . getSlop ( ) ; SpanQuery [ ] clauses = spanNearQuery . getClauses ( ) ; subSpans = new Spans [ clauses . length ] ; subSpansByDoc = new Spans [ clauses . length ] ; for ( int i = 0 ; i < clauses . length ; i ++ ) { subSpans [ i ] = clauses [ i ] . getSpans ( reader ) ; subSpansByDoc [ i ] = subSpans [ i ] ; } query = spanNearQuery ; } public int doc ( ) { return matchDoc ; } public int start ( ) { return matchStart ; } public int end ( ) { return matchEnd ; } public boolean next ( ) throws IOException { if ( firstTime ) { firstTime = false ; for ( int i = 0 ; i < subSpans . length ; i ++ ) { if ( ! subSpans [ i ] . next ( ) ) { more = false ; return false ; } } more = true ; } return advanceAfterOrdered ( ) ; } public boolean skipTo ( int target ) throws IOException { if ( firstTime ) { firstTime = false ; for ( int i = 0 ; i < subSpans . length ; i ++ ) { if ( ! subSpans [ i ] . skipTo ( target ) ) { more = false ; return false ; } } more = true ; } else if ( more && ( subSpans [ 0 ] . doc ( ) < target ) ) { if ( subSpans [ 0 ] . skipTo ( target ) ) { inSameDoc = false ; } else { more = false ; return false ; } } return advanceAfterOrdered ( ) ; } private boolean advanceAfterOrdered ( ) throws IOException { while ( more && ( inSameDoc || toSameDoc ( ) ) ) { if ( stretchToOrder ( ) && shrinkToAfterShortestMatch ( ) ) { return true ; } } return false ; } private boolean toSameDoc ( ) throws IOException { Arrays . sort ( subSpansByDoc , spanDocComparator ) ; int firstIndex = 0 ; int maxDoc = subSpansByDoc [ subSpansByDoc . length - 1 ] . doc ( ) ; while ( subSpansByDoc [ firstIndex ] . doc ( ) != maxDoc ) { if ( ! subSpansByDoc [ firstIndex ] . skipTo ( maxDoc ) ) { more = false ; inSameDoc = false ; return false ; } maxDoc = subSpansByDoc [ firstIndex ] . doc ( ) ; if ( ++ firstIndex == subSpansByDoc . length ) { firstIndex = 0 ; } } for ( int i = 0 ; i < subSpansByDoc . length ; i ++ ) { assert ( subSpansByDoc [ i ] . doc ( ) == maxDoc ) : " NearSpansOrdered.toSameDoc() spans " + subSpansByDoc [ 0 ] + "\n at doc " + subSpansByDoc [ i ] . doc ( ) + ", but should be at " + maxDoc ; } inSameDoc = true ; return true ; } static final boolean docSpansOrdered ( Spans spans1 , Spans spans2 ) { assert spans1 . doc ( ) == spans2 . doc ( ) : "doc1 " + spans1 . doc ( ) + " != doc2 " + spans2 . doc ( ) ; int start1 = spans1 . start ( ) ; int start2 = spans2 . start ( ) ; return ( start1 == start2 ) ? ( spans1 . end ( ) < spans2 . end ( ) ) : ( start1 < start2 ) ; } private static final boolean docSpansOrdered ( int start1 , int end1 , int start2 , int end2 ) { return ( start1 == start2 ) ? ( end1 < end2 ) : ( start1 < start2 ) ; } private boolean stretchToOrder ( ) throws IOException { matchDoc = subSpans [ 0 ] . doc ( ) ; for ( int i = 1 ; inSameDoc && ( i < subSpans . length ) ; i ++ ) { while ( ! docSpansOrdered ( subSpans [ i - 1 ] , subSpans [ i ] ) ) { if ( ! subSpans [ i ] . next ( ) ) { inSameDoc = false ; more = false ; break ; } else if ( matchDoc != subSpans [ i ] . doc ( ) ) { inSameDoc = false ; break ; } } } return inSameDoc ; } private boolean shrinkToAfterShortestMatch ( ) throws IOException { matchStart = subSpans [ subSpans . length - 1 ] . start ( ) ; matchEnd = subSpans [ subSpans . length - 1 ] . end ( ) ; int matchSlop = 0 ; int lastStart = matchStart ; int lastEnd = matchEnd ; for ( int i = subSpans . length - 2 ; i >= 0 ; i -- ) { Spans prevSpans = subSpans [ i ] ; int prevStart = prevSpans . start ( ) ; int prevEnd = prevSpans . end ( ) ; while ( true ) { if ( ! prevSpans . next ( ) ) { inSameDoc = false ; more = false ; break ; } else if ( matchDoc != prevSpans . doc ( ) ) { inSameDoc = false ; break ; } else { int ppStart = prevSpans . start ( ) ; int ppEnd = prevSpans . end ( ) ; if ( ! docSpansOrdered ( ppStart , ppEnd , lastStart , lastEnd ) ) { break ; } else { prevStart = ppStart ; prevEnd = ppEnd ; } } } assert prevStart <= matchStart ; if ( matchStart > prevEnd ) { matchSlop += ( matchStart - prevEnd ) ; } matchStart = prevStart ; lastStart = prevStart ; lastEnd = prevEnd ; } return matchSlop <= allowedSlop ; } public String toString ( ) { return getClass ( ) . getName ( ) + "(" + query . toString ( ) + ")@" + ( firstTime ? "START" : ( more ? ( doc ( ) + ":" + start ( ) + "-" + end ( ) ) : "END" ) ) ; } } 	0	['15', '1', '0', '6', '41', '25', '3', '5', '7', '0.747252747', '661', '0.846153846', '3', '0', '0.202380952', '0', '0', '42.2', '6', '1.5333', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; public interface Weight extends java . io . Serializable { Query getQuery ( ) ; float getValue ( ) ; float sumOfSquaredWeights ( ) throws IOException ; void normalize ( float norm ) ; Scorer scorer ( IndexReader reader ) throws IOException ; Explanation explain ( IndexReader reader , int doc ) throws IOException ; } 	0	['6', '1', '0', '47', '6', '15', '44', '4', '6', '2', '6', '0', '0', '0', '0.416666667', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . analysis ; import java . io . File ; import java . io . IOException ; import java . io . Reader ; import java . util . Set ; public final class StopAnalyzer extends Analyzer { private Set stopWords ; public static final String [ ] ENGLISH_STOP_WORDS = { "a" , "an" , "and" , "are" , "as" , "at" , "be" , "but" , "by" , "for" , "if" , "in" , "into" , "is" , "it" , "no" , "not" , "of" , "on" , "or" , "such" , "that" , "the" , "their" , "then" , "there" , "these" , "they" , "this" , "to" , "was" , "will" , "with" } ; public StopAnalyzer ( ) { stopWords = StopFilter . makeStopSet ( ENGLISH_STOP_WORDS ) ; } public StopAnalyzer ( Set stopWords ) { this . stopWords = stopWords ; } public StopAnalyzer ( String [ ] stopWords ) { this . stopWords = StopFilter . makeStopSet ( stopWords ) ; } public StopAnalyzer ( File stopwordsFile ) throws IOException { stopWords = WordlistLoader . getWordSet ( stopwordsFile ) ; } public StopAnalyzer ( Reader stopwords ) throws IOException { stopWords = WordlistLoader . getWordSet ( stopwords ) ; } public TokenStream tokenStream ( String fieldName , Reader reader ) { return new StopFilter ( new LowerCaseTokenizer ( reader ) , stopWords ) ; } } 	0	['7', '2', '0', '6', '13', '0', '1', '5', '6', '0.5', '189', '0.5', '0', '0.666666667', '0.333333333', '0', '0', '25.71428571', '1', '0.1429', '0']
package org . apache . lucene . analysis . standard ; import java . io . * ; public class StandardTokenizerTokenManager implements StandardTokenizerConstants { public java . io . PrintStream debugStream = System . out ; public void setDebugStream ( java . io . PrintStream ds ) { debugStream = ds ; } private final int jjMoveStringLiteralDfa0_0 ( ) { return jjMoveNfa_0 ( 0 , 0 ) ; } private final void jjCheckNAdd ( int state ) { if ( jjrounds [ state ] != jjround ) { jjstateSet [ jjnewStateCnt ++ ] = state ; jjrounds [ state ] = jjround ; } } private final void jjAddStates ( int start , int end ) { do { jjstateSet [ jjnewStateCnt ++ ] = jjnextStates [ start ] ; } while ( start ++ != end ) ; } private final void jjCheckNAddTwoStates ( int state1 , int state2 ) { jjCheckNAdd ( state1 ) ; jjCheckNAdd ( state2 ) ; } private final void jjCheckNAddStates ( int start , int end ) { do { jjCheckNAdd ( jjnextStates [ start ] ) ; } while ( start ++ != end ) ; } private final void jjCheckNAddStates ( int start ) { jjCheckNAdd ( jjnextStates [ start ] ) ; jjCheckNAdd ( jjnextStates [ start + 1 ] ) ; } static final long [ ] jjbitVec0 = { 0xfff0000000000000L , 0xffffffffffffdfffL , 0xffffffffL , 0x600000000000000L } ; static final long [ ] jjbitVec2 = { 0x0L , 0xffffffffffffffffL , 0xffffffffffffffffL , 0xffffffffffffffffL } ; static final long [ ] jjbitVec3 = { 0xffffffffffffffffL , 0xffffffffffffffffL , 0xffffL , 0xffff000000000000L } ; static final long [ ] jjbitVec4 = { 0xffffffffffffffffL , 0xffffffffffffffffL , 0x0L , 0x0L } ; static final long [ ] jjbitVec5 = { 0xffffffffffffffffL , 0xffffffffffffffffL , 0xffffffffffffffffL , 0x0L } ; static final long [ ] jjbitVec6 = { 0x0L , 0xffffffe000000000L , 0xffffffffL , 0x0L } ; static final long [ ] jjbitVec7 = { 0x20000L , 0x0L , 0xfffff00000000000L , 0x7fffffL } ; static final long [ ] jjbitVec8 = { 0xffffffffffffffffL , 0xffffffffffffffffL , 0xffffffffffffL , 0x0L } ; static final long [ ] jjbitVec9 = { 0xfffffffeL , 0x0L , 0x0L , 0x0L } ; static final long [ ] jjbitVec10 = { 0x0L , 0x0L , 0x0L , 0xff7fffffff7fffffL } ; static final long [ ] jjbitVec11 = { 0x0L , 0x0L , 0xffffffff00000000L , 0x1fffffffL } ; static final long [ ] jjbitVec12 = { 0x1600L , 0x0L , 0x0L , 0x0L } ; static final long [ ] jjbitVec13 = { 0x0L , 0xffc000000000L , 0x0L , 0xffc000000000L } ; static final long [ ] jjbitVec14 = { 0x0L , 0x3ff00000000L , 0x0L , 0x3ff000000000000L } ; static final long [ ] jjbitVec15 = { 0x0L , 0xffc000000000L , 0x0L , 0xff8000000000L } ; static final long [ ] jjbitVec16 = { 0x0L , 0xffc000000000L , 0x0L , 0x0L } ; static final long [ ] jjbitVec17 = { 0x0L , 0x3ff0000L , 0x0L , 0x3ff0000L } ; static final long [ ] jjbitVec18 = { 0x0L , 0x3ffL , 0x0L , 0x0L } ; static final long [ ] jjbitVec19 = { 0xfffffffeL , 0x0L , 0xfffff00000000000L , 0x7fffffL } ; private final int jjMoveNfa_0 ( int startState , int curPos ) { int [ ] nextStates ; int startsAt = 0 ; jjnewStateCnt = 75 ; int i = 1 ; jjstateSet [ 0 ] = startState ; int j , kind = 0x7fffffff ; for ( ; ; ) { if ( ++ jjround == 0x7fffffff ) ReInitRounds ( ) ; if ( curChar < 64 ) { long l = 1L << curChar ; MatchLoop : do { switch ( jjstateSet [ -- i ] ) { case 0 : if ( ( 0x3ff000000000000L & l ) != 0L ) { if ( kind > 1 ) kind = 1 ; jjCheckNAddStates ( 0 , 11 ) ; } if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddStates ( 12 , 17 ) ; if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddStates ( 18 , 23 ) ; break ; case 2 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddStates ( 18 , 23 ) ; break ; case 3 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 3 , 4 ) ; break ; case 4 : case 5 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 5 , 6 ) ; break ; case 6 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAdd ( 7 ) ; break ; case 7 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAdd ( 7 ) ; break ; case 8 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 8 , 9 ) ; break ; case 9 : case 10 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 10 , 11 ) ; break ; case 11 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAdd ( 12 ) ; break ; case 12 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 12 , 13 ) ; break ; case 13 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 14 , 15 ) ; break ; case 14 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 14 , 15 ) ; break ; case 15 : case 16 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 11 , 16 ) ; break ; case 17 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 17 , 18 ) ; break ; case 18 : case 19 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 19 , 20 ) ; break ; case 20 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAdd ( 21 ) ; break ; case 21 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 21 , 22 ) ; break ; case 22 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 23 , 24 ) ; break ; case 23 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 23 , 24 ) ; break ; case 24 : case 25 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 25 , 26 ) ; break ; case 26 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAdd ( 27 ) ; break ; case 27 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 22 , 27 ) ; break ; case 28 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddStates ( 12 , 17 ) ; break ; case 29 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 1 ) kind = 1 ; jjCheckNAddStates ( 0 , 11 ) ; break ; case 30 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 1 ) kind = 1 ; jjCheckNAdd ( 30 ) ; break ; case 31 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddStates ( 24 , 26 ) ; break ; case 32 : if ( ( 0x600000000000L & l ) != 0L ) jjCheckNAdd ( 33 ) ; break ; case 33 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddStates ( 27 , 29 ) ; break ; case 35 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 35 , 36 ) ; break ; case 36 : if ( ( 0x600000000000L & l ) != 0L ) jjCheckNAdd ( 37 ) ; break ; case 37 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 5 ) kind = 5 ; jjCheckNAddTwoStates ( 36 , 37 ) ; break ; case 38 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 38 , 39 ) ; break ; case 39 : if ( curChar == 46 ) jjCheckNAdd ( 40 ) ; break ; case 40 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 6 ) kind = 6 ; jjCheckNAddTwoStates ( 39 , 40 ) ; break ; case 41 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 41 , 42 ) ; break ; case 42 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 43 , 44 ) ; break ; case 43 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 43 , 44 ) ; break ; case 44 : case 45 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAdd ( 45 ) ; break ; case 46 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 46 , 47 ) ; break ; case 47 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 48 , 49 ) ; break ; case 48 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 48 , 49 ) ; break ; case 49 : case 50 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 50 , 51 ) ; break ; case 51 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAdd ( 52 ) ; break ; case 52 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 47 , 52 ) ; break ; case 53 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 53 , 54 ) ; break ; case 54 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 55 , 56 ) ; break ; case 55 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 55 , 56 ) ; break ; case 56 : case 57 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 57 , 58 ) ; break ; case 58 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAdd ( 59 ) ; break ; case 59 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 59 , 60 ) ; break ; case 60 : if ( ( 0xf00000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 61 , 62 ) ; break ; case 61 : if ( ( 0x3ff000000000000L & l ) != 0L ) jjCheckNAddTwoStates ( 61 , 62 ) ; break ; case 62 : case 63 : if ( ( 0x3ff000000000000L & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 58 , 63 ) ; break ; case 66 : if ( curChar == 39 ) jjstateSet [ jjnewStateCnt ++ ] = 67 ; break ; case 69 : if ( curChar == 46 ) jjCheckNAdd ( 70 ) ; break ; case 71 : if ( curChar != 46 ) break ; if ( kind > 3 ) kind = 3 ; jjCheckNAdd ( 70 ) ; break ; case 73 : if ( curChar == 38 ) jjstateSet [ jjnewStateCnt ++ ] = 74 ; break ; default : break ; } } while ( i != startsAt ) ; } else if ( curChar < 128 ) { long l = 1L << ( curChar & 077 ) ; MatchLoop : do { switch ( jjstateSet [ -- i ] ) { case 0 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddStates ( 30 , 35 ) ; if ( ( 0x7fffffe07fffffeL & l ) != 0L ) { if ( kind > 1 ) kind = 1 ; jjCheckNAddStates ( 0 , 11 ) ; } if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddStates ( 18 , 23 ) ; break ; case 2 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddStates ( 18 , 23 ) ; break ; case 3 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 3 , 4 ) ; break ; case 5 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjAddStates ( 36 , 37 ) ; break ; case 6 : if ( curChar == 95 ) jjCheckNAdd ( 7 ) ; break ; case 7 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAdd ( 7 ) ; break ; case 8 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 8 , 9 ) ; break ; case 10 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 10 , 11 ) ; break ; case 11 : if ( curChar == 95 ) jjCheckNAdd ( 12 ) ; break ; case 12 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 12 , 13 ) ; break ; case 13 : if ( curChar == 95 ) jjCheckNAddTwoStates ( 14 , 15 ) ; break ; case 14 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 14 , 15 ) ; break ; case 16 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 11 , 16 ) ; break ; case 17 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 17 , 18 ) ; break ; case 19 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjAddStates ( 38 , 39 ) ; break ; case 20 : if ( curChar == 95 ) jjCheckNAdd ( 21 ) ; break ; case 21 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 21 , 22 ) ; break ; case 22 : if ( curChar == 95 ) jjCheckNAddTwoStates ( 23 , 24 ) ; break ; case 23 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 23 , 24 ) ; break ; case 25 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjAddStates ( 40 , 41 ) ; break ; case 26 : if ( curChar == 95 ) jjCheckNAdd ( 27 ) ; break ; case 27 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 22 , 27 ) ; break ; case 29 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 1 ) kind = 1 ; jjCheckNAddStates ( 0 , 11 ) ; break ; case 30 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 1 ) kind = 1 ; jjCheckNAdd ( 30 ) ; break ; case 31 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddStates ( 24 , 26 ) ; break ; case 32 : if ( curChar == 95 ) jjCheckNAdd ( 33 ) ; break ; case 33 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddStates ( 27 , 29 ) ; break ; case 34 : if ( curChar == 64 ) jjCheckNAdd ( 35 ) ; break ; case 35 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 35 , 36 ) ; break ; case 37 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 5 ) kind = 5 ; jjCheckNAddTwoStates ( 36 , 37 ) ; break ; case 38 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 38 , 39 ) ; break ; case 40 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 6 ) kind = 6 ; jjCheckNAddTwoStates ( 39 , 40 ) ; break ; case 41 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 41 , 42 ) ; break ; case 42 : if ( curChar == 95 ) jjCheckNAddTwoStates ( 43 , 44 ) ; break ; case 43 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 43 , 44 ) ; break ; case 45 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjstateSet [ jjnewStateCnt ++ ] = 45 ; break ; case 46 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 46 , 47 ) ; break ; case 47 : if ( curChar == 95 ) jjCheckNAddTwoStates ( 48 , 49 ) ; break ; case 48 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 48 , 49 ) ; break ; case 50 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjAddStates ( 42 , 43 ) ; break ; case 51 : if ( curChar == 95 ) jjCheckNAdd ( 52 ) ; break ; case 52 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 47 , 52 ) ; break ; case 53 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 53 , 54 ) ; break ; case 54 : if ( curChar == 95 ) jjCheckNAddTwoStates ( 55 , 56 ) ; break ; case 55 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 55 , 56 ) ; break ; case 57 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 57 , 58 ) ; break ; case 58 : if ( curChar == 95 ) jjCheckNAdd ( 59 ) ; break ; case 59 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 59 , 60 ) ; break ; case 60 : if ( curChar == 95 ) jjCheckNAddTwoStates ( 61 , 62 ) ; break ; case 61 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 61 , 62 ) ; break ; case 63 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 58 , 63 ) ; break ; case 64 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddStates ( 30 , 35 ) ; break ; case 65 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 65 , 66 ) ; break ; case 67 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 2 ) kind = 2 ; jjCheckNAddTwoStates ( 66 , 67 ) ; break ; case 68 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 68 , 69 ) ; break ; case 70 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjAddStates ( 44 , 45 ) ; break ; case 72 : if ( ( 0x7fffffe07fffffeL & l ) != 0L ) jjCheckNAddTwoStates ( 72 , 73 ) ; break ; case 73 : if ( curChar == 64 ) jjCheckNAdd ( 74 ) ; break ; case 74 : if ( ( 0x7fffffe07fffffeL & l ) == 0L ) break ; if ( kind > 4 ) kind = 4 ; jjCheckNAdd ( 74 ) ; break ; default : break ; } } while ( i != startsAt ) ; } else { int hiByte = ( int ) ( curChar > > 8 ) ; int i1 = hiByte > > 6 ; long l1 = 1L << ( hiByte & 077 ) ; int i2 = ( curChar & 0xff ) > > 6 ; long l2 = 1L << ( curChar & 077 ) ; MatchLoop : do { switch ( jjstateSet [ -- i ] ) { case 0 : if ( jjCanMove_0 ( hiByte , i1 , i2 , l1 , l2 ) ) { if ( kind > 12 ) kind = 12 ; } if ( jjCanMove_1 ( hiByte , i1 , i2 , l1 , l2 ) ) { if ( kind > 13 ) kind = 13 ; } if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 18 , 23 ) ; if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 12 , 17 ) ; if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) { if ( kind > 1 ) kind = 1 ; jjCheckNAddStates ( 0 , 11 ) ; } if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 30 , 35 ) ; break ; case 1 : if ( jjCanMove_1 ( hiByte , i1 , i2 , l1 , l2 ) && kind > 13 ) kind = 13 ; break ; case 2 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 18 , 23 ) ; break ; case 3 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 3 , 4 ) ; break ; case 4 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 5 , 6 ) ; break ; case 5 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 5 , 6 ) ; break ; case 7 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjstateSet [ jjnewStateCnt ++ ] = 7 ; break ; case 8 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 8 , 9 ) ; break ; case 9 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 10 , 11 ) ; break ; case 10 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 10 , 11 ) ; break ; case 12 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 46 , 47 ) ; break ; case 14 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 48 , 49 ) ; break ; case 15 : if ( ! jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 11 , 16 ) ; break ; case 16 : if ( ! jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 11 , 16 ) ; break ; case 17 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 17 , 18 ) ; break ; case 18 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 19 , 20 ) ; break ; case 19 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 19 , 20 ) ; break ; case 21 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 21 , 22 ) ; break ; case 23 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 50 , 51 ) ; break ; case 24 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 25 , 26 ) ; break ; case 25 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 25 , 26 ) ; break ; case 27 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 22 , 27 ) ; break ; case 28 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 12 , 17 ) ; break ; case 29 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 1 ) kind = 1 ; jjCheckNAddStates ( 0 , 11 ) ; break ; case 30 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 1 ) kind = 1 ; jjCheckNAdd ( 30 ) ; break ; case 31 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 24 , 26 ) ; break ; case 33 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 27 , 29 ) ; break ; case 35 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 35 , 36 ) ; break ; case 37 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 5 ) kind = 5 ; jjCheckNAddTwoStates ( 36 , 37 ) ; break ; case 38 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 38 , 39 ) ; break ; case 40 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 6 ) kind = 6 ; jjCheckNAddTwoStates ( 39 , 40 ) ; break ; case 41 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 41 , 42 ) ; break ; case 43 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 52 , 53 ) ; break ; case 44 : if ( ! jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAdd ( 45 ) ; break ; case 45 : if ( ! jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAdd ( 45 ) ; break ; case 46 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 46 , 47 ) ; break ; case 48 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 54 , 55 ) ; break ; case 49 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 50 , 51 ) ; break ; case 50 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 50 , 51 ) ; break ; case 52 : if ( ! jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 47 , 52 ) ; break ; case 53 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 53 , 54 ) ; break ; case 55 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 56 , 57 ) ; break ; case 56 : if ( jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 57 , 58 ) ; break ; case 57 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 57 , 58 ) ; break ; case 59 : if ( jjCanMove_4 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 58 , 59 ) ; break ; case 61 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 60 , 61 ) ; break ; case 62 : if ( ! jjCanMove_3 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 58 , 63 ) ; break ; case 63 : if ( ! jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 7 ) kind = 7 ; jjCheckNAddTwoStates ( 58 , 63 ) ; break ; case 64 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddStates ( 30 , 35 ) ; break ; case 65 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 65 , 66 ) ; break ; case 67 : if ( ! jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 2 ) kind = 2 ; jjCheckNAddTwoStates ( 66 , 67 ) ; break ; case 68 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 68 , 69 ) ; break ; case 70 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjAddStates ( 44 , 45 ) ; break ; case 72 : if ( jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) jjCheckNAddTwoStates ( 72 , 73 ) ; break ; case 74 : if ( ! jjCanMove_2 ( hiByte , i1 , i2 , l1 , l2 ) ) break ; if ( kind > 4 ) kind = 4 ; jjstateSet [ jjnewStateCnt ++ ] = 74 ; break ; default : break ; } } while ( i != startsAt ) ; } if ( kind != 0x7fffffff ) { jjmatchedKind = kind ; jjmatchedPos = curPos ; kind = 0x7fffffff ; } ++ curPos ; if ( ( i = jjnewStateCnt ) == ( startsAt = 75 - ( jjnewStateCnt = startsAt ) ) ) return curPos ; try { curChar = input_stream . readChar ( ) ; } catch ( java . io . IOException e ) { return curPos ; } } } static final int [ ] jjnextStates = { 30 , 31 , 32 , 34 , 38 , 39 , 41 , 42 , 46 , 47 , 53 , 54 , 5 , 6 , 10 , 11 , 19 , 20 , 3 , 4 , 8 , 9 , 17 , 18 , 31 , 32 , 34 , 32 , 33 , 34 , 65 , 66 , 68 , 69 , 72 , 73 , 5 , 6 , 19 , 20 , 25 , 26 , 50 , 51 , 70 , 71 , 12 , 13 , 14 , 15 , 23 , 24 , 43 , 44 , 48 , 49 , 55 , 56 , 59 , 60 , 61 , 62 , } ; private static final boolean jjCanMove_0 ( int hiByte , int i1 , int i2 , long l1 , long l2 ) { switch ( hiByte ) { case 48 : return ( ( jjbitVec2 [ i2 ] & l2 ) != 0L ) ; case 49 : return ( ( jjbitVec3 [ i2 ] & l2 ) != 0L ) ; case 51 : return ( ( jjbitVec4 [ i2 ] & l2 ) != 0L ) ; case 77 : return ( ( jjbitVec5 [ i2 ] & l2 ) != 0L ) ; case 255 : return ( ( jjbitVec6 [ i2 ] & l2 ) != 0L ) ; default : if ( ( jjbitVec0 [ i1 ] & l1 ) != 0L ) return true ; return false ; } } private static final boolean jjCanMove_1 ( int hiByte , int i1 , int i2 , long l1 , long l2 ) { switch ( hiByte ) { case 215 : return ( ( jjbitVec8 [ i2 ] & l2 ) != 0L ) ; default : if ( ( jjbitVec7 [ i1 ] & l1 ) != 0L ) return true ; return false ; } } private static final boolean jjCanMove_2 ( int hiByte , int i1 , int i2 , long l1 , long l2 ) { switch ( hiByte ) { case 0 : return ( ( jjbitVec10 [ i2 ] & l2 ) != 0L ) ; case 255 : return ( ( jjbitVec11 [ i2 ] & l2 ) != 0L ) ; default : if ( ( jjbitVec9 [ i1 ] & l1 ) != 0L ) return true ; return false ; } } private static final boolean jjCanMove_3 ( int hiByte , int i1 , int i2 , long l1 , long l2 ) { switch ( hiByte ) { case 6 : return ( ( jjbitVec14 [ i2 ] & l2 ) != 0L ) ; case 11 : return ( ( jjbitVec15 [ i2 ] & l2 ) != 0L ) ; case 13 : return ( ( jjbitVec16 [ i2 ] & l2 ) != 0L ) ; case 14 : return ( ( jjbitVec17 [ i2 ] & l2 ) != 0L ) ; case 16 : return ( ( jjbitVec18 [ i2 ] & l2 ) != 0L ) ; default : if ( ( jjbitVec12 [ i1 ] & l1 ) != 0L ) if ( ( jjbitVec13 [ i2 ] & l2 ) == 0L ) return false ; else return true ; return false ; } } private static final boolean jjCanMove_4 ( int hiByte , int i1 , int i2 , long l1 , long l2 ) { switch ( hiByte ) { case 0 : return ( ( jjbitVec10 [ i2 ] & l2 ) != 0L ) ; case 215 : return ( ( jjbitVec8 [ i2 ] & l2 ) != 0L ) ; case 255 : return ( ( jjbitVec11 [ i2 ] & l2 ) != 0L ) ; default : if ( ( jjbitVec19 [ i1 ] & l1 ) != 0L ) return true ; return false ; } } public static final String [ ] jjstrLiteralImages = { "" , null , null , null , null , null , null , null , null , null , null , null , null , null , null , null , } ; public static final String [ ] lexStateNames = { "DEFAULT" , } ; static final long [ ] jjtoToken = { 0x30ffL , } ; static final long [ ] jjtoSkip = { 0x8000L , } ; protected CharStream input_stream ; private final int [ ] jjrounds = new int [ 75 ] ; private final int [ ] jjstateSet = new int [ 150 ] ; protected char curChar ; public StandardTokenizerTokenManager ( CharStream stream ) { input_stream = stream ; } public StandardTokenizerTokenManager ( CharStream stream , int lexState ) { this ( stream ) ; SwitchTo ( lexState ) ; } public void ReInit ( CharStream stream ) { jjmatchedPos = jjnewStateCnt = 0 ; curLexState = defaultLexState ; input_stream = stream ; ReInitRounds ( ) ; } private final void ReInitRounds ( ) { int i ; jjround = 0x80000001 ; for ( i = 75 ; i -- > 0 ; ) jjrounds [ i ] = 0x80000000 ; } public void ReInit ( CharStream stream , int lexState ) { ReInit ( stream ) ; SwitchTo ( lexState ) ; } public void SwitchTo ( int lexState ) { if ( lexState >= 1 || lexState < 0 ) throw new TokenMgrError ( "Error: Ignoring invalid lexical state : " + lexState + ". State unchanged." , TokenMgrError . INVALID_LEXICAL_STATE ) ; else curLexState = lexState ; } protected Token jjFillToken ( ) { Token t = Token . newToken ( jjmatchedKind ) ; t . kind = jjmatchedKind ; String im = jjstrLiteralImages [ jjmatchedKind ] ; t . image = ( im == null ) ? input_stream . GetImage ( ) : im ; t . beginLine = input_stream . getBeginLine ( ) ; t . beginColumn = input_stream . getBeginColumn ( ) ; t . endLine = input_stream . getEndLine ( ) ; t . endColumn = input_stream . getEndColumn ( ) ; return t ; } int curLexState = 0 ; int defaultLexState = 0 ; int jjnewStateCnt ; int jjround ; int jjmatchedPos ; int jjmatchedKind ; public Token getNextToken ( ) { int kind ; Token specialToken = null ; Token matchedToken ; int curPos = 0 ; EOFLoop : for ( ; ; ) { try { curChar = input_stream . BeginToken ( ) ; } catch ( java . io . IOException e ) { jjmatchedKind = 0 ; matchedToken = jjFillToken ( ) ; return matchedToken ; } jjmatchedKind = 0x7fffffff ; jjmatchedPos = 0 ; curPos = jjMoveStringLiteralDfa0_0 ( ) ; if ( jjmatchedPos == 0 && jjmatchedKind > 15 ) { jjmatchedKind = 15 ; } if ( jjmatchedKind != 0x7fffffff ) { if ( jjmatchedPos + 1 < curPos ) input_stream . backup ( curPos - jjmatchedPos - 1 ) ; if ( ( jjtoToken [ jjmatchedKind > > 6 ] & ( 1L << ( jjmatchedKind & 077 ) ) ) != 0L ) { matchedToken = jjFillToken ( ) ; return matchedToken ; } else { continue EOFLoop ; } } int error_line = input_stream . getEndLine ( ) ; int error_column = input_stream . getEndColumn ( ) ; String error_after = null ; boolean EOFSeen = false ; try { input_stream . readChar ( ) ; input_stream . backup ( 1 ) ; } catch ( java . io . IOException e1 ) { EOFSeen = true ; error_after = curPos <= 1 ? "" : input_stream . GetImage ( ) ; if ( curChar == '\n' || curChar == '\r' ) { error_line ++ ; error_column = 0 ; } else error_column ++ ; } if ( ! EOFSeen ) { input_stream . backup ( 1 ) ; error_after = curPos <= 1 ? "" : input_stream . GetImage ( ) ; } throw new TokenMgrError ( EOFSeen , curLexState , error_line , error_column , error_after , curChar , TokenMgrError . LEXICAL_ERROR ) ; } } } 	0	['22', '1', '0', '5', '38', '153', '1', '4', '7', '0.850340136', '3785', '0.114285714', '1', '0', '0.380952381', '0', '0', '169.4545455', '236', '14.0455', '0']
package org . apache . lucene . analysis . standard ; public class Token { public int kind ; public int beginLine , beginColumn , endLine , endColumn ; public String image ; public Token next ; public Token specialToken ; public String toString ( ) { return image ; } public static final Token newToken ( int ofKind ) { switch ( ofKind ) { default : return new Token ( ) ; } } } 	0	['3', '1', '0', '3', '4', '3', '3', '0', '3', '1.4375', '23', '0', '2', '0', '0.5', '0', '0', '4', '2', '1', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermEnum ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . util . ToStringUtils ; public class PrefixQuery extends Query { private Term prefix ; public PrefixQuery ( Term prefix ) { this . prefix = prefix ; } public Term getPrefix ( ) { return prefix ; } public Query rewrite ( IndexReader reader ) throws IOException { BooleanQuery query = new BooleanQuery ( true ) ; TermEnum enumerator = reader . terms ( prefix ) ; try { String prefixText = prefix . text ( ) ; String prefixField = prefix . field ( ) ; do { Term term = enumerator . term ( ) ; if ( term != null && term . text ( ) . startsWith ( prefixText ) && term . field ( ) == prefixField ) { TermQuery tq = new TermQuery ( term ) ; tq . setBoost ( getBoost ( ) ) ; query . add ( tq , BooleanClause . Occur . SHOULD ) ; } else { break ; } } while ( enumerator . next ( ) ) ; } finally { enumerator . close ( ) ; } return query ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! prefix . field ( ) . equals ( field ) ) { buffer . append ( prefix . field ( ) ) ; buffer . append ( ":" ) ; } buffer . append ( prefix . text ( ) ) ; buffer . append ( '*' ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( ! ( o instanceof PrefixQuery ) ) return false ; PrefixQuery other = ( PrefixQuery ) o ; return ( this . getBoost ( ) == other . getBoost ( ) ) && this . prefix . equals ( other . prefix ) ; } public int hashCode ( ) { return Float . floatToIntBits ( getBoost ( ) ) ^ prefix . hashCode ( ) ^ 0x6634D93C ; } } 	0	['6', '2', '0', '9', '28', '0', '1', '8', '6', '0', '147', '1', '1', '0.705882353', '0.333333333', '2', '3', '23.33333333', '4', '1.5', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public final class LowerCaseTokenizer extends LetterTokenizer { public LowerCaseTokenizer ( Reader in ) { super ( in ) ; } protected char normalize ( char c ) { return Character . toLowerCase ( c ) ; } } 	0	['2', '5', '0', '3', '4', '1', '2', '1', '1', '2', '9', '0', '0', '0.888888889', '0.666666667', '1', '1', '3.5', '1', '0.5', '0']
package org . apache . lucene . util ; import java . io . IOException ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . IndexInput ; import org . apache . lucene . store . IndexOutput ; public final class BitVector { private byte [ ] bits ; private int size ; private int count = - 1 ; public BitVector ( int n ) { size = n ; bits = new byte [ ( size > > 3 ) + 1 ] ; } public final void set ( int bit ) { if ( bit >= size ) { throw new ArrayIndexOutOfBoundsException ( bit ) ; } bits [ bit > > 3 ] |= 1 << ( bit & 7 ) ; count = - 1 ; } public final void clear ( int bit ) { if ( bit >= size ) { throw new ArrayIndexOutOfBoundsException ( bit ) ; } bits [ bit > > 3 ] &= ~ ( 1 << ( bit & 7 ) ) ; count = - 1 ; } public final boolean get ( int bit ) { if ( bit >= size ) { throw new ArrayIndexOutOfBoundsException ( bit ) ; } return ( bits [ bit > > 3 ] & ( 1 << ( bit & 7 ) ) ) != 0 ; } public final int size ( ) { return size ; } public final int count ( ) { if ( count == - 1 ) { int c = 0 ; int end = bits . length ; for ( int i = 0 ; i < end ; i ++ ) c += BYTE_COUNTS [ bits [ i ] & 0xFF ] ; count = c ; } return count ; } private static final byte [ ] BYTE_COUNTS = { 0 , 1 , 1 , 2 , 1 , 2 , 2 , 3 , 1 , 2 , 2 , 3 , 2 , 3 , 3 , 4 , 1 , 2 , 2 , 3 , 2 , 3 , 3 , 4 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 1 , 2 , 2 , 3 , 2 , 3 , 3 , 4 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 1 , 2 , 2 , 3 , 2 , 3 , 3 , 4 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 4 , 5 , 5 , 6 , 5 , 6 , 6 , 7 , 1 , 2 , 2 , 3 , 2 , 3 , 3 , 4 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 4 , 5 , 5 , 6 , 5 , 6 , 6 , 7 , 2 , 3 , 3 , 4 , 3 , 4 , 4 , 5 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 4 , 5 , 5 , 6 , 5 , 6 , 6 , 7 , 3 , 4 , 4 , 5 , 4 , 5 , 5 , 6 , 4 , 5 , 5 , 6 , 5 , 6 , 6 , 7 , 4 , 5 , 5 , 6 , 5 , 6 , 6 , 7 , 5 , 6 , 6 , 7 , 6 , 7 , 7 , 8 } ; public final void write ( Directory d , String name ) throws IOException { IndexOutput output = d . createOutput ( name ) ; try { if ( isSparse ( ) ) { writeDgaps ( output ) ; } else { writeBits ( output ) ; } } finally { output . close ( ) ; } } private void writeBits ( IndexOutput output ) throws IOException { output . writeInt ( size ( ) ) ; output . writeInt ( count ( ) ) ; output . writeBytes ( bits , bits . length ) ; } private void writeDgaps ( IndexOutput output ) throws IOException { output . writeInt ( - 1 ) ; output . writeInt ( size ( ) ) ; output . writeInt ( count ( ) ) ; int last = 0 ; int n = count ( ) ; int m = bits . length ; for ( int i = 0 ; i < m && n > 0 ; i ++ ) { if ( bits [ i ] != 0 ) { output . writeVInt ( i - last ) ; output . writeByte ( bits [ i ] ) ; last = i ; n -= BYTE_COUNTS [ bits [ i ] & 0xFF ] ; } } } private boolean isSparse ( ) { int factor = 10 ; if ( bits . length < ( 1 << 7 ) ) return factor * ( 4 + ( 8 + 8 ) * count ( ) ) < size ( ) ; if ( bits . length < ( 1 << 14 ) ) return factor * ( 4 + ( 8 + 16 ) * count ( ) ) < size ( ) ; if ( bits . length < ( 1 << 21 ) ) return factor * ( 4 + ( 8 + 24 ) * count ( ) ) < size ( ) ; if ( bits . length < ( 1 << 28 ) ) return factor * ( 4 + ( 8 + 32 ) * count ( ) ) < size ( ) ; return factor * ( 4 + ( 8 + 40 ) * count ( ) ) < size ( ) ; } public BitVector ( Directory d , String name ) throws IOException { IndexInput input = d . openInput ( name ) ; try { size = input . readInt ( ) ; if ( size == - 1 ) { readDgaps ( input ) ; } else { readBits ( input ) ; } } finally { input . close ( ) ; } } private void readBits ( IndexInput input ) throws IOException { count = input . readInt ( ) ; bits = new byte [ ( size > > 3 ) + 1 ] ; input . readBytes ( bits , 0 , bits . length ) ; } private void readDgaps ( IndexInput input ) throws IOException { size = input . readInt ( ) ; count = input . readInt ( ) ; bits = new byte [ ( size > > 3 ) + 1 ] ; int last = 0 ; int n = count ( ) ; while ( n > 0 ) { last += input . readVInt ( ) ; bits [ last ] = input . readByte ( ) ; n -= BYTE_COUNTS [ bits [ last ] & 0xFF ] ; } } } 	0	['14', '1', '0', '5', '28', '0', '2', '3', '8', '0.288461538', '1483', '1', '0', '0', '0.320512821', '0', '0', '104.6428571', '10', '1.8571', '0']
package org . apache . lucene . index ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . Token ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . document . Document ; import org . apache . lucene . document . Fieldable ; import org . apache . lucene . search . Similarity ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . IndexOutput ; import java . io . IOException ; import java . io . PrintStream ; import java . io . Reader ; import java . io . StringReader ; import java . util . Arrays ; import java . util . BitSet ; import java . util . Enumeration ; import java . util . Hashtable ; import java . util . Iterator ; import java . util . LinkedList ; import java . util . List ; final class DocumentWriter { private Analyzer analyzer ; private Directory directory ; private Similarity similarity ; private FieldInfos fieldInfos ; private int maxFieldLength ; private int termIndexInterval = IndexWriter . DEFAULT_TERM_INDEX_INTERVAL ; private PrintStream infoStream ; DocumentWriter ( Directory directory , Analyzer analyzer , Similarity similarity , int maxFieldLength ) { this . directory = directory ; this . analyzer = analyzer ; this . similarity = similarity ; this . maxFieldLength = maxFieldLength ; } DocumentWriter ( Directory directory , Analyzer analyzer , IndexWriter writer ) { this . directory = directory ; this . analyzer = analyzer ; this . similarity = writer . getSimilarity ( ) ; this . maxFieldLength = writer . getMaxFieldLength ( ) ; this . termIndexInterval = writer . getTermIndexInterval ( ) ; } final void addDocument ( String segment , Document doc ) throws CorruptIndexException , IOException { fieldInfos = new FieldInfos ( ) ; fieldInfos . add ( doc ) ; postingTable . clear ( ) ; fieldLengths = new int [ fieldInfos . size ( ) ] ; fieldPositions = new int [ fieldInfos . size ( ) ] ; fieldOffsets = new int [ fieldInfos . size ( ) ] ; fieldStoresPayloads = new BitSet ( fieldInfos . size ( ) ) ; fieldBoosts = new float [ fieldInfos . size ( ) ] ; Arrays . fill ( fieldBoosts , doc . getBoost ( ) ) ; try { invertDocument ( doc ) ; Posting [ ] postings = sortPostingTable ( ) ; fieldInfos . write ( directory , segment + ".fnm" ) ; FieldsWriter fieldsWriter = new FieldsWriter ( directory , segment , fieldInfos ) ; try { fieldsWriter . addDocument ( doc ) ; } finally { fieldsWriter . close ( ) ; } writePostings ( postings , segment ) ; writeNorms ( segment ) ; } finally { IOException ex = null ; Iterator it = openTokenStreams . iterator ( ) ; while ( it . hasNext ( ) ) { try { ( ( TokenStream ) it . next ( ) ) . close ( ) ; } catch ( IOException e ) { if ( ex != null ) { ex = e ; } } } openTokenStreams . clear ( ) ; if ( ex != null ) { throw ex ; } } } private final Hashtable postingTable = new Hashtable ( ) ; private int [ ] fieldLengths ; private int [ ] fieldPositions ; private int [ ] fieldOffsets ; private float [ ] fieldBoosts ; private BitSet fieldStoresPayloads ; private List openTokenStreams = new LinkedList ( ) ; private final void invertDocument ( Document doc ) throws IOException { Iterator fieldIterator = doc . getFields ( ) . iterator ( ) ; while ( fieldIterator . hasNext ( ) ) { Fieldable field = ( Fieldable ) fieldIterator . next ( ) ; String fieldName = field . name ( ) ; int fieldNumber = fieldInfos . fieldNumber ( fieldName ) ; int length = fieldLengths [ fieldNumber ] ; int position = fieldPositions [ fieldNumber ] ; if ( length > 0 ) position += analyzer . getPositionIncrementGap ( fieldName ) ; int offset = fieldOffsets [ fieldNumber ] ; if ( field . isIndexed ( ) ) { if ( ! field . isTokenized ( ) ) { String stringValue = field . stringValue ( ) ; if ( field . isStoreOffsetWithTermVector ( ) ) addPosition ( fieldName , stringValue , position ++ , null , new TermVectorOffsetInfo ( offset , offset + stringValue . length ( ) ) ) ; else addPosition ( fieldName , stringValue , position ++ , null , null ) ; offset += stringValue . length ( ) ; length ++ ; } else { TokenStream stream = field . tokenStreamValue ( ) ; if ( stream == null ) { Reader reader ; if ( field . readerValue ( ) != null ) reader = field . readerValue ( ) ; else if ( field . stringValue ( ) != null ) reader = new StringReader ( field . stringValue ( ) ) ; else throw new IllegalArgumentException ( "field must have either String or Reader value" ) ; stream = analyzer . tokenStream ( fieldName , reader ) ; } openTokenStreams . add ( stream ) ; stream . reset ( ) ; Token lastToken = null ; for ( Token t = stream . next ( ) ; t != null ; t = stream . next ( ) ) { position += ( t . getPositionIncrement ( ) - 1 ) ; Payload payload = t . getPayload ( ) ; if ( payload != null ) { fieldStoresPayloads . set ( fieldNumber ) ; } TermVectorOffsetInfo termVectorOffsetInfo ; if ( field . isStoreOffsetWithTermVector ( ) ) { termVectorOffsetInfo = new TermVectorOffsetInfo ( offset + t . startOffset ( ) , offset + t . endOffset ( ) ) ; } else { termVectorOffsetInfo = null ; } addPosition ( fieldName , t . termText ( ) , position ++ , payload , termVectorOffsetInfo ) ; lastToken = t ; if ( ++ length >= maxFieldLength ) { if ( infoStream != null ) infoStream . println ( "maxFieldLength " + maxFieldLength + " reached, ignoring following tokens" ) ; break ; } } if ( lastToken != null ) offset += lastToken . endOffset ( ) + 1 ; } fieldLengths [ fieldNumber ] = length ; fieldPositions [ fieldNumber ] = position ; fieldBoosts [ fieldNumber ] *= field . getBoost ( ) ; fieldOffsets [ fieldNumber ] = offset ; } } for ( int i = fieldStoresPayloads . nextSetBit ( 0 ) ; i >= 0 ; i = fieldStoresPayloads . nextSetBit ( i + 1 ) ) { fieldInfos . fieldInfo ( i ) . storePayloads = true ; } } private final Term termBuffer = new Term ( "" , "" ) ; private final void addPosition ( String field , String text , int position , Payload payload , TermVectorOffsetInfo offset ) { termBuffer . set ( field , text ) ; Posting ti = ( Posting ) postingTable . get ( termBuffer ) ; if ( ti != null ) { int freq = ti . freq ; if ( ti . positions . length == freq ) { int [ ] newPositions = new int [ freq * 2 ] ; int [ ] positions = ti . positions ; System . arraycopy ( positions , 0 , newPositions , 0 , freq ) ; ti . positions = newPositions ; if ( ti . payloads != null ) { Payload [ ] newPayloads = new Payload [ freq * 2 ] ; Payload [ ] payloads = ti . payloads ; System . arraycopy ( payloads , 0 , newPayloads , 0 , payloads . length ) ; ti . payloads = newPayloads ; } } ti . positions [ freq ] = position ; if ( payload != null ) { if ( ti . payloads == null ) { ti . payloads = new Payload [ ti . positions . length ] ; } ti . payloads [ freq ] = payload ; } if ( offset != null ) { if ( ti . offsets . length == freq ) { TermVectorOffsetInfo [ ] newOffsets = new TermVectorOffsetInfo [ freq * 2 ] ; TermVectorOffsetInfo [ ] offsets = ti . offsets ; System . arraycopy ( offsets , 0 , newOffsets , 0 , freq ) ; ti . offsets = newOffsets ; } ti . offsets [ freq ] = offset ; } ti . freq = freq + 1 ; } else { Term term = new Term ( field , text , false ) ; postingTable . put ( term , new Posting ( term , position , payload , offset ) ) ; } } private final Posting [ ] sortPostingTable ( ) { Posting [ ] array = new Posting [ postingTable . size ( ) ] ; Enumeration postings = postingTable . elements ( ) ; for ( int i = 0 ; postings . hasMoreElements ( ) ; i ++ ) array [ i ] = ( Posting ) postings . nextElement ( ) ; quickSort ( array , 0 , array . length - 1 ) ; return array ; } private static final void quickSort ( Posting [ ] postings , int lo , int hi ) { if ( lo >= hi ) return ; int mid = ( lo + hi ) / 2 ; if ( postings [ lo ] . term . compareTo ( postings [ mid ] . term ) > 0 ) { Posting tmp = postings [ lo ] ; postings [ lo ] = postings [ mid ] ; postings [ mid ] = tmp ; } if ( postings [ mid ] . term . compareTo ( postings [ hi ] . term ) > 0 ) { Posting tmp = postings [ mid ] ; postings [ mid ] = postings [ hi ] ; postings [ hi ] = tmp ; if ( postings [ lo ] . term . compareTo ( postings [ mid ] . term ) > 0 ) { Posting tmp2 = postings [ lo ] ; postings [ lo ] = postings [ mid ] ; postings [ mid ] = tmp2 ; } } int left = lo + 1 ; int right = hi - 1 ; if ( left >= right ) return ; Term partition = postings [ mid ] . term ; for ( ; ; ) { while ( postings [ right ] . term . compareTo ( partition ) > 0 ) -- right ; while ( left < right && postings [ left ] . term . compareTo ( partition ) <= 0 ) ++ left ; if ( left < right ) { Posting tmp = postings [ left ] ; postings [ left ] = postings [ right ] ; postings [ right ] = tmp ; -- right ; } else { break ; } } quickSort ( postings , lo , left ) ; quickSort ( postings , left + 1 , hi ) ; } private final void writePostings ( Posting [ ] postings , String segment ) throws CorruptIndexException , IOException { IndexOutput freq = null , prox = null ; TermInfosWriter tis = null ; TermVectorsWriter termVectorWriter = null ; try { freq = directory . createOutput ( segment + ".frq" ) ; prox = directory . createOutput ( segment + ".prx" ) ; tis = new TermInfosWriter ( directory , segment , fieldInfos , termIndexInterval ) ; TermInfo ti = new TermInfo ( ) ; String currentField = null ; boolean currentFieldHasPayloads = false ; for ( int i = 0 ; i < postings . length ; i ++ ) { Posting posting = postings [ i ] ; String termField = posting . term . field ( ) ; if ( currentField != termField ) { currentField = termField ; FieldInfo fi = fieldInfos . fieldInfo ( currentField ) ; currentFieldHasPayloads = fi . storePayloads ; if ( fi . storeTermVector ) { if ( termVectorWriter == null ) { termVectorWriter = new TermVectorsWriter ( directory , segment , fieldInfos ) ; termVectorWriter . openDocument ( ) ; } termVectorWriter . openField ( currentField ) ; } else if ( termVectorWriter != null ) { termVectorWriter . closeField ( ) ; } } ti . set ( 1 , freq . getFilePointer ( ) , prox . getFilePointer ( ) , - 1 ) ; tis . add ( posting . term , ti ) ; int postingFreq = posting . freq ; if ( postingFreq == 1 ) freq . writeVInt ( 1 ) ; else { freq . writeVInt ( 0 ) ; freq . writeVInt ( postingFreq ) ; } int lastPosition = 0 ; int [ ] positions = posting . positions ; Payload [ ] payloads = posting . payloads ; int lastPayloadLength = - 1 ; for ( int j = 0 ; j < postingFreq ; j ++ ) { int position = positions [ j ] ; int delta = position - lastPosition ; if ( currentFieldHasPayloads ) { int payloadLength = 0 ; Payload payload = null ; if ( payloads != null ) { payload = payloads [ j ] ; if ( payload != null ) { payloadLength = payload . length ; } } if ( payloadLength == lastPayloadLength ) { prox . writeVInt ( delta * 2 ) ; } else { prox . writeVInt ( delta * 2 + 1 ) ; prox . writeVInt ( payloadLength ) ; lastPayloadLength = payloadLength ; } if ( payloadLength > 0 ) { prox . writeBytes ( payload . data , payload . offset , payload . length ) ; } } else { prox . writeVInt ( delta ) ; } lastPosition = position ; } if ( termVectorWriter != null && termVectorWriter . isFieldOpen ( ) ) { termVectorWriter . addTerm ( posting . term . text ( ) , postingFreq , posting . positions , posting . offsets ) ; } } if ( termVectorWriter != null ) termVectorWriter . closeDocument ( ) ; } finally { IOException keep = null ; if ( freq != null ) try { freq . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( prox != null ) try { prox . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( tis != null ) try { tis . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( termVectorWriter != null ) try { termVectorWriter . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( keep != null ) throw ( IOException ) keep . fillInStackTrace ( ) ; } } private final void writeNorms ( String segment ) throws IOException { for ( int n = 0 ; n < fieldInfos . size ( ) ; n ++ ) { FieldInfo fi = fieldInfos . fieldInfo ( n ) ; if ( fi . isIndexed && ! fi . omitNorms ) { float norm = fieldBoosts [ n ] * similarity . lengthNorm ( fi . name , fieldLengths [ n ] ) ; IndexOutput norms = directory . createOutput ( segment + ".f" + n ) ; try { norms . writeByte ( Similarity . encodeNorm ( norm ) ) ; } finally { norms . close ( ) ; } } } } void setInfoStream ( PrintStream infoStream ) { this . infoStream = infoStream ; } int getNumFields ( ) { return fieldInfos . size ( ) ; } } final class Posting { Term term ; int freq ; int [ ] positions ; Payload [ ] payloads ; TermVectorOffsetInfo [ ] offsets ; Posting ( Term t , int position , Payload payload , TermVectorOffsetInfo offset ) { term = t ; freq = 1 ; positions = new int [ 1 ] ; positions [ 0 ] = position ; if ( payload != null ) { payloads = new Payload [ 1 ] ; payloads [ 0 ] = payload ; } else payloads = null ; if ( offset != null ) { offsets = new TermVectorOffsetInfo [ 1 ] ; offsets [ 0 ] = offset ; } else offsets = null ; } } 	0	['11', '1', '0', '20', '102', '1', '1', '20', '0', '0.733333333', '1192', '1', '5', '0', '0.227272727', '0', '0', '106', '10', '2.3636', '0']
package org . apache . lucene . util ; public final class Constants { private Constants ( ) { } public static final String JAVA_VERSION = System . getProperty ( "java.version" ) ; public static final boolean JAVA_1_1 = JAVA_VERSION . startsWith ( "1.1." ) ; public static final boolean JAVA_1_2 = JAVA_VERSION . startsWith ( "1.2." ) ; public static final boolean JAVA_1_3 = JAVA_VERSION . startsWith ( "1.3." ) ; public static final String OS_NAME = System . getProperty ( "os.name" ) ; public static final boolean LINUX = OS_NAME . startsWith ( "Linux" ) ; public static final boolean WINDOWS = OS_NAME . startsWith ( "Windows" ) ; public static final boolean SUN_OS = OS_NAME . startsWith ( "SunOS" ) ; } 	0	['2', '1', '0', '0', '5', '1', '0', '0', '0', '1', '44', '0', '0', '0', '1', '0', '0', '17', '0', '0', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . util . ToStringUtils ; public abstract class MultiTermQuery extends Query { private Term term ; public MultiTermQuery ( Term term ) { this . term = term ; } public Term getTerm ( ) { return term ; } protected abstract FilteredTermEnum getEnum ( IndexReader reader ) throws IOException ; public Query rewrite ( IndexReader reader ) throws IOException { FilteredTermEnum enumerator = getEnum ( reader ) ; BooleanQuery query = new BooleanQuery ( true ) ; try { do { Term t = enumerator . term ( ) ; if ( t != null ) { TermQuery tq = new TermQuery ( t ) ; tq . setBoost ( getBoost ( ) * enumerator . difference ( ) ) ; query . add ( tq , BooleanClause . Occur . SHOULD ) ; } } while ( enumerator . next ( ) ) ; } finally { enumerator . close ( ) ; } return query ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! term . field ( ) . equals ( field ) ) { buffer . append ( term . field ( ) ) ; buffer . append ( ":" ) ; } buffer . append ( term . text ( ) ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof MultiTermQuery ) ) return false ; final MultiTermQuery multiTermQuery = ( MultiTermQuery ) o ; if ( ! term . equals ( multiTermQuery . term ) ) return false ; return getBoost ( ) == multiTermQuery . getBoost ( ) ; } public int hashCode ( ) { return term . hashCode ( ) + Float . floatToRawIntBits ( getBoost ( ) ) ; } } 	0	['7', '2', '2', '10', '27', '1', '2', '8', '6', '0.333333333', '134', '1', '1', '0.666666667', '0.342857143', '2', '3', '18', '5', '1.5714', '0']
package org . apache . lucene . search ; import java . io . IOException ; final class BooleanScorer extends Scorer { private SubScorer scorers = null ; private BucketTable bucketTable = new BucketTable ( ) ; private int maxCoord = 1 ; private float [ ] coordFactors = null ; private int requiredMask = 0 ; private int prohibitedMask = 0 ; private int nextMask = 1 ; private final int minNrShouldMatch ; BooleanScorer ( Similarity similarity ) { this ( similarity , 1 ) ; } BooleanScorer ( Similarity similarity , int minNrShouldMatch ) { super ( similarity ) ; this . minNrShouldMatch = minNrShouldMatch ; } static final class SubScorer { public Scorer scorer ; public boolean done ; public boolean required = false ; public boolean prohibited = false ; public HitCollector collector ; public SubScorer next ; public SubScorer ( Scorer scorer , boolean required , boolean prohibited , HitCollector collector , SubScorer next ) throws IOException { this . scorer = scorer ; this . done = ! scorer . next ( ) ; this . required = required ; this . prohibited = prohibited ; this . collector = collector ; this . next = next ; } } final void add ( Scorer scorer , boolean required , boolean prohibited ) throws IOException { int mask = 0 ; if ( required || prohibited ) { if ( nextMask == 0 ) throw new IndexOutOfBoundsException ( "More than 32 required/prohibited clauses in query." ) ; mask = nextMask ; nextMask = nextMask << 1 ; } else mask = 0 ; if ( ! prohibited ) maxCoord ++ ; if ( prohibited ) prohibitedMask |= mask ; else if ( required ) requiredMask |= mask ; scorers = new SubScorer ( scorer , required , prohibited , bucketTable . newCollector ( mask ) , scorers ) ; } private final void computeCoordFactors ( ) { coordFactors = new float [ maxCoord ] ; for ( int i = 0 ; i < maxCoord ; i ++ ) coordFactors [ i ] = getSimilarity ( ) . coord ( i , maxCoord - 1 ) ; } private int end ; private Bucket current ; public void score ( HitCollector hc ) throws IOException { next ( ) ; score ( hc , Integer . MAX_VALUE ) ; } protected boolean score ( HitCollector hc , int max ) throws IOException { if ( coordFactors == null ) computeCoordFactors ( ) ; boolean more ; Bucket tmp ; do { bucketTable . first = null ; while ( current != null ) { if ( ( current . bits & prohibitedMask ) == 0 && ( current . bits & requiredMask ) == requiredMask ) { if ( current . doc >= max ) { tmp = current ; current = current . next ; tmp . next = bucketTable . first ; bucketTable . first = tmp ; continue ; } if ( current . coord >= minNrShouldMatch ) { hc . collect ( current . doc , current . score * coordFactors [ current . coord ] ) ; } } current = current . next ; } if ( bucketTable . first != null ) { current = bucketTable . first ; bucketTable . first = current . next ; return true ; } more = false ; end += BucketTable . SIZE ; for ( SubScorer sub = scorers ; sub != null ; sub = sub . next ) { if ( ! sub . done ) { sub . done = ! sub . scorer . score ( sub . collector , end ) ; if ( ! sub . done ) more = true ; } } current = bucketTable . first ; } while ( current != null || more ) ; return false ; } public int doc ( ) { return current . doc ; } public boolean next ( ) throws IOException { boolean more ; do { while ( bucketTable . first != null ) { current = bucketTable . first ; bucketTable . first = current . next ; if ( ( current . bits & prohibitedMask ) == 0 && ( current . bits & requiredMask ) == requiredMask && current . coord >= minNrShouldMatch ) { return true ; } } more = false ; end += BucketTable . SIZE ; for ( SubScorer sub = scorers ; sub != null ; sub = sub . next ) { Scorer scorer = sub . scorer ; while ( ! sub . done && scorer . doc ( ) < end ) { sub . collector . collect ( scorer . doc ( ) , scorer . score ( ) ) ; sub . done = ! scorer . next ( ) ; } if ( ! sub . done ) { more = true ; } } } while ( bucketTable . first != null || more ) ; return false ; } public float score ( ) { if ( coordFactors == null ) computeCoordFactors ( ) ; return current . score * coordFactors [ current . coord ] ; } static final class Bucket { int doc = - 1 ; float score ; int bits ; int coord ; Bucket next ; } static final class BucketTable { public static final int SIZE = 1 << 11 ; public static final int MASK = SIZE - 1 ; final Bucket [ ] buckets = new Bucket [ SIZE ] ; Bucket first = null ; public BucketTable ( ) { } public final int size ( ) { return SIZE ; } public HitCollector newCollector ( int mask ) { return new Collector ( mask , this ) ; } } static final class Collector extends HitCollector { private BucketTable bucketTable ; private int mask ; public Collector ( int mask , BucketTable bucketTable ) { this . mask = mask ; this . bucketTable = bucketTable ; } public final void collect ( final int doc , final float score ) { final BucketTable table = bucketTable ; final int i = doc & BucketTable . MASK ; Bucket bucket = table . buckets [ i ] ; if ( bucket == null ) table . buckets [ i ] = bucket = new Bucket ( ) ; if ( bucket . doc != doc ) { bucket . doc = doc ; bucket . score = score ; bucket . bits = mask ; bucket . coord = 1 ; bucket . next = table . first ; table . first = bucket ; } else { bucket . score += score ; bucket . bits |= mask ; bucket . coord ++ ; } } } public boolean skipTo ( int target ) { throw new UnsupportedOperationException ( ) ; } public Explanation explain ( int doc ) { throw new UnsupportedOperationException ( ) ; } public String toString ( ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "boolean(" ) ; for ( SubScorer sub = scorers ; sub != null ; sub = sub . next ) { buffer . append ( sub . scorer . toString ( ) ) ; buffer . append ( " " ) ; } buffer . append ( ")" ) ; return buffer . toString ( ) ; } } 	0	['12', '2', '0', '8', '29', '26', '1', '7', '7', '0.609090909', '461', '1', '3', '0.444444444', '0.305555556', '1', '3', '36.58333333', '2', '1.0833', '0']
package org . apache . lucene . search ; public class QueryFilter extends CachingWrapperFilter { public QueryFilter ( Query query ) { super ( new QueryWrapperFilter ( query ) ) ; } public boolean equals ( Object o ) { return super . equals ( ( QueryFilter ) o ) ; } public int hashCode ( ) { return super . hashCode ( ) ^ 0x923F64B9 ; } } 	0	['3', '3', '0', '4', '7', '3', '0', '4', '3', '2', '20', '0', '0', '0.714285714', '0.555555556', '2', '3', '5.666666667', '1', '0.6667', '0']
package org . apache . lucene . queryParser ; import java . io . * ; public final class FastCharStream implements CharStream { char [ ] buffer = null ; int bufferLength = 0 ; int bufferPosition = 0 ; int tokenStart = 0 ; int bufferStart = 0 ; Reader input ; public FastCharStream ( Reader r ) { input = r ; } public final char readChar ( ) throws IOException { if ( bufferPosition >= bufferLength ) refill ( ) ; return buffer [ bufferPosition ++ ] ; } private final void refill ( ) throws IOException { int newPosition = bufferLength - tokenStart ; if ( tokenStart == 0 ) { if ( buffer == null ) { buffer = new char [ 2048 ] ; } else if ( bufferLength == buffer . length ) { char [ ] newBuffer = new char [ buffer . length * 2 ] ; System . arraycopy ( buffer , 0 , newBuffer , 0 , bufferLength ) ; buffer = newBuffer ; } } else { System . arraycopy ( buffer , tokenStart , buffer , 0 , newPosition ) ; } bufferLength = newPosition ; bufferPosition = newPosition ; bufferStart += tokenStart ; tokenStart = 0 ; int charsRead = input . read ( buffer , newPosition , buffer . length - newPosition ) ; if ( charsRead == - 1 ) throw new IOException ( "read past eof" ) ; else bufferLength += charsRead ; } public final char BeginToken ( ) throws IOException { tokenStart = bufferPosition ; return readChar ( ) ; } public final void backup ( int amount ) { bufferPosition -= amount ; } public final String GetImage ( ) { return new String ( buffer , tokenStart , bufferPosition - tokenStart ) ; } public final char [ ] GetSuffix ( int len ) { char [ ] value = new char [ len ] ; System . arraycopy ( buffer , bufferPosition - len , value , 0 , len ) ; return value ; } public final void Done ( ) { try { input . close ( ) ; } catch ( IOException e ) { System . err . println ( "Caught: " + e + "; ignoring." ) ; } } public final int getColumn ( ) { return bufferStart + bufferPosition ; } public final int getLine ( ) { return 1 ; } public final int getEndColumn ( ) { return bufferStart + bufferPosition ; } public final int getEndLine ( ) { return 1 ; } public final int getBeginColumn ( ) { return bufferStart + tokenStart ; } public final int getBeginLine ( ) { return 1 ; } } 	0	['14', '1', '0', '2', '25', '3', '1', '1', '13', '0.602564103', '237', '0', '0', '0', '0.404761905', '0', '0', '15.5', '1', '0.9286', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; public class WildcardTermEnum extends FilteredTermEnum { Term searchTerm ; String field = "" ; String text = "" ; String pre = "" ; int preLen = 0 ; boolean endEnum = false ; public WildcardTermEnum ( IndexReader reader , Term term ) throws IOException { super ( ) ; searchTerm = term ; field = searchTerm . field ( ) ; text = searchTerm . text ( ) ; int sidx = text . indexOf ( WILDCARD_STRING ) ; int cidx = text . indexOf ( WILDCARD_CHAR ) ; int idx = sidx ; if ( idx == - 1 ) { idx = cidx ; } else if ( cidx >= 0 ) { idx = Math . min ( idx , cidx ) ; } pre = searchTerm . text ( ) . substring ( 0 , idx ) ; preLen = pre . length ( ) ; text = text . substring ( preLen ) ; setEnum ( reader . terms ( new Term ( searchTerm . field ( ) , pre ) ) ) ; } protected final boolean termCompare ( Term term ) { if ( field == term . field ( ) ) { String searchText = term . text ( ) ; if ( searchText . startsWith ( pre ) ) { return wildcardEquals ( text , 0 , searchText , preLen ) ; } } endEnum = true ; return false ; } public final float difference ( ) { return 1.0f ; } public final boolean endEnum ( ) { return endEnum ; } public static final char WILDCARD_STRING = '*' ; public static final char WILDCARD_CHAR = '?' ; public static final boolean wildcardEquals ( String pattern , int patternIdx , String string , int stringIdx ) { int p = patternIdx ; for ( int s = stringIdx ; ; ++ p , ++ s ) { boolean sEnd = ( s >= string . length ( ) ) ; boolean pEnd = ( p >= pattern . length ( ) ) ; if ( sEnd ) { boolean justWildcardsLeft = true ; int wildcardSearchPos = p ; while ( wildcardSearchPos < pattern . length ( ) && justWildcardsLeft ) { char wildchar = pattern . charAt ( wildcardSearchPos ) ; if ( wildchar != WILDCARD_CHAR && wildchar != WILDCARD_STRING ) { justWildcardsLeft = false ; } else { if ( wildchar == WILDCARD_CHAR ) { return false ; } wildcardSearchPos ++ ; } } if ( justWildcardsLeft ) { return true ; } } if ( sEnd || pEnd ) { break ; } if ( pattern . charAt ( p ) == WILDCARD_CHAR ) { continue ; } if ( pattern . charAt ( p ) == WILDCARD_STRING ) { ++ p ; for ( int i = string . length ( ) ; i >= s ; -- i ) { if ( wildcardEquals ( pattern , p , string , i ) ) { return true ; } } break ; } if ( pattern . charAt ( p ) != string . charAt ( s ) ) { break ; } } return false ; } public void close ( ) throws IOException { super . close ( ) ; searchTerm = null ; field = null ; text = null ; } } 	0	['6', '3', '0', '5', '20', '5', '1', '4', '5', '0.825', '247', '0', '1', '0.722222222', '0.333333333', '1', '4', '38.83333333', '16', '3.6667', '0']
package org . apache . lucene . store ; import java . io . IOException ; public class LockObtainFailedException extends IOException { public LockObtainFailedException ( String message ) { super ( message ) ; } } 	0	['1', '4', '0', '5', '2', '0', '5', '0', '1', '2', '5', '0', '0', '1', '1', '0', '0', '4', '0', '0', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . * ; abstract class PhraseScorer extends Scorer { private Weight weight ; protected byte [ ] norms ; protected float value ; private boolean firstTime = true ; private boolean more = true ; protected PhraseQueue pq ; protected PhrasePositions first , last ; private float freq ; PhraseScorer ( Weight weight , TermPositions [ ] tps , int [ ] offsets , Similarity similarity , byte [ ] norms ) { super ( similarity ) ; this . norms = norms ; this . weight = weight ; this . value = weight . getValue ( ) ; for ( int i = 0 ; i < tps . length ; i ++ ) { PhrasePositions pp = new PhrasePositions ( tps [ i ] , offsets [ i ] ) ; if ( last != null ) { last . next = pp ; } else first = pp ; last = pp ; } pq = new PhraseQueue ( tps . length ) ; } public int doc ( ) { return first . doc ; } public boolean next ( ) throws IOException { if ( firstTime ) { init ( ) ; firstTime = false ; } else if ( more ) { more = last . next ( ) ; } return doNext ( ) ; } private boolean doNext ( ) throws IOException { while ( more ) { while ( more && first . doc < last . doc ) { more = first . skipTo ( last . doc ) ; firstToLast ( ) ; } if ( more ) { freq = phraseFreq ( ) ; if ( freq == 0.0f ) more = last . next ( ) ; else return true ; } } return false ; } public float score ( ) throws IOException { float raw = getSimilarity ( ) . tf ( freq ) * value ; return raw * Similarity . decodeNorm ( norms [ first . doc ] ) ; } public boolean skipTo ( int target ) throws IOException { firstTime = false ; for ( PhrasePositions pp = first ; more && pp != null ; pp = pp . next ) { more = pp . skipTo ( target ) ; } if ( more ) sort ( ) ; return doNext ( ) ; } protected abstract float phraseFreq ( ) throws IOException ; private void init ( ) throws IOException { for ( PhrasePositions pp = first ; more && pp != null ; pp = pp . next ) more = pp . next ( ) ; if ( more ) sort ( ) ; } private void sort ( ) { pq . clear ( ) ; for ( PhrasePositions pp = first ; pp != null ; pp = pp . next ) pq . put ( pp ) ; pqToList ( ) ; } protected final void pqToList ( ) { last = first = null ; while ( pq . top ( ) != null ) { PhrasePositions pp = ( PhrasePositions ) pq . pop ( ) ; if ( last != null ) { last . next = pp ; } else first = pp ; last = pp ; pp . next = null ; } } protected final void firstToLast ( ) { last . next = first ; last = first ; first = first . next ; last . next = null ; } public Explanation explain ( final int doc ) throws IOException { Explanation tfExplanation = new Explanation ( ) ; while ( next ( ) && doc ( ) < doc ) { } float phraseFreq = ( doc ( ) == doc ) ? freq : 0.0f ; tfExplanation . setValue ( getSimilarity ( ) . tf ( phraseFreq ) ) ; tfExplanation . setDescription ( "tf(phraseFreq=" + phraseFreq + ")" ) ; return tfExplanation ; } public String toString ( ) { return "scorer(" + weight + ")" ; } } 	0	['13', '2', '2', '9', '34', '0', '2', '7', '6', '0.666666667', '345', '1', '4', '0.4', '0.21978022', '1', '3', '24.84615385', '3', '1.1538', '0']
package org . apache . lucene . document ; import java . util . Set ; public class SetBasedFieldSelector implements FieldSelector { private Set fieldsToLoad ; private Set lazyFieldsToLoad ; public SetBasedFieldSelector ( Set fieldsToLoad , Set lazyFieldsToLoad ) { this . fieldsToLoad = fieldsToLoad ; this . lazyFieldsToLoad = lazyFieldsToLoad ; } public FieldSelectorResult accept ( String fieldName ) { FieldSelectorResult result = FieldSelectorResult . NO_LOAD ; if ( fieldsToLoad . contains ( fieldName ) == true ) { result = FieldSelectorResult . LOAD ; } if ( lazyFieldsToLoad . contains ( fieldName ) == true ) { result = FieldSelectorResult . LAZY_LOAD ; } return result ; } } 	0	['2', '1', '0', '2', '4', '0', '0', '2', '2', '0', '33', '1', '0', '0', '0.666666667', '0', '0', '14.5', '3', '1.5', '0']
package org . apache . lucene . search ; import java . util . ArrayList ; public class Explanation implements java . io . Serializable { private float value ; private String description ; private ArrayList details ; public Explanation ( ) { } public Explanation ( float value , String description ) { this . value = value ; this . description = description ; } public boolean isMatch ( ) { return ( 0.0f < getValue ( ) ) ; } public float getValue ( ) { return value ; } public void setValue ( float value ) { this . value = value ; } public String getDescription ( ) { return description ; } public void setDescription ( String description ) { this . description = description ; } protected String getSummary ( ) { return getValue ( ) + " = " + getDescription ( ) ; } public Explanation [ ] getDetails ( ) { if ( details == null ) return null ; return ( Explanation [ ] ) details . toArray ( new Explanation [ 0 ] ) ; } public void addDetail ( Explanation detail ) { if ( details == null ) details = new ArrayList ( ) ; details . add ( detail ) ; } public String toString ( ) { return toString ( 0 ) ; } protected String toString ( int depth ) { StringBuffer buffer = new StringBuffer ( ) ; for ( int i = 0 ; i < depth ; i ++ ) { buffer . append ( "  " ) ; } buffer . append ( getSummary ( ) ) ; buffer . append ( "\n" ) ; Explanation [ ] details = getDetails ( ) ; if ( details != null ) { for ( int i = 0 ; i < details . length ; i ++ ) { buffer . append ( details [ i ] . toString ( depth + 1 ) ) ; } } return buffer . toString ( ) ; } public String toHtml ( ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "<ul>\n" ) ; buffer . append ( "<li>" ) ; buffer . append ( getSummary ( ) ) ; buffer . append ( "<br />\n" ) ; Explanation [ ] details = getDetails ( ) ; if ( details != null ) { for ( int i = 0 ; i < details . length ; i ++ ) { buffer . append ( details [ i ] . toHtml ( ) ) ; } } buffer . append ( "</li>\n" ) ; buffer . append ( "</ul>\n" ) ; return buffer . toString ( ) ; } } 	0	['13', '1', '1', '41', '21', '64', '41', '0', '11', '0.611111111', '197', '1', '0', '0', '0.292307692', '0', '0', '13.92307692', '4', '1.4615', '0']
package org . apache . lucene . index ; public class FieldReaderException extends RuntimeException { public FieldReaderException ( ) { } public FieldReaderException ( Throwable cause ) { super ( cause ) ; } public FieldReaderException ( String message ) { super ( message ) ; } public FieldReaderException ( String message , Throwable cause ) { super ( message , cause ) ; } } 	0	['4', '4', '0', '1', '8', '6', '1', '0', '4', '2', '20', '0', '0', '1', '0.666666667', '0', '0', '4', '0', '0', '0']
