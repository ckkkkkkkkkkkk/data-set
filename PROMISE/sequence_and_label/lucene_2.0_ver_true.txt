package org . apache . lucene . analysis ; import java . io . Reader ; public final class WhitespaceAnalyzer extends Analyzer { public TokenStream tokenStream ( String fieldName , Reader reader ) { return new WhitespaceTokenizer ( reader ) ; } } 	0	['2', '2', '0', '3', '4', '1', '0', '3', '2', '2', '10', '0', '0', '0.666666667', '0.666666667', '0', '0', '4', '1', '0.5', '0']
package org . apache . lucene . search ; import org . apache . lucene . analysis . Analyzer ; import org . apache . lucene . analysis . Token ; import org . apache . lucene . analysis . TokenStream ; import org . apache . lucene . index . TermFreqVector ; import java . io . IOException ; import java . io . StringReader ; import java . util . * ; public class QueryTermVector implements TermFreqVector { private String [ ] terms = new String [ 0 ] ; private int [ ] termFreqs = new int [ 0 ] ; public String getField ( ) { return null ; } public QueryTermVector ( String [ ] queryTerms ) { processTerms ( queryTerms ) ; } public QueryTermVector ( String queryString , Analyzer analyzer ) { if ( analyzer != null ) { TokenStream stream = analyzer . tokenStream ( "" , new StringReader ( queryString ) ) ; if ( stream != null ) { Token next = null ; List terms = new ArrayList ( ) ; try { while ( ( next = stream . next ( ) ) != null ) { terms . add ( next . termText ( ) ) ; } processTerms ( ( String [ ] ) terms . toArray ( new String [ terms . size ( ) ] ) ) ; } catch ( IOException e ) { } } } } private void processTerms ( String [ ] queryTerms ) { if ( queryTerms != null ) { Arrays . sort ( queryTerms ) ; Map tmpSet = new HashMap ( queryTerms . length ) ; List tmpList = new ArrayList ( queryTerms . length ) ; List tmpFreqs = new ArrayList ( queryTerms . length ) ; int j = 0 ; for ( int i = 0 ; i < queryTerms . length ; i ++ ) { String term = queryTerms [ i ] ; Integer position = ( Integer ) tmpSet . get ( term ) ; if ( position == null ) { tmpSet . put ( term , new Integer ( j ++ ) ) ; tmpList . add ( term ) ; tmpFreqs . add ( new Integer ( 1 ) ) ; } else { Integer integer = ( Integer ) tmpFreqs . get ( position . intValue ( ) ) ; tmpFreqs . set ( position . intValue ( ) , new Integer ( integer . intValue ( ) + 1 ) ) ; } } terms = ( String [ ] ) tmpList . toArray ( terms ) ; termFreqs = new int [ tmpFreqs . size ( ) ] ; int i = 0 ; for ( Iterator iter = tmpFreqs . iterator ( ) ; iter . hasNext ( ) ; ) { Integer integer = ( Integer ) iter . next ( ) ; termFreqs [ i ++ ] = integer . intValue ( ) ; } } } public final String toString ( ) { StringBuffer sb = new StringBuffer ( ) ; sb . append ( '{' ) ; for ( int i = 0 ; i < terms . length ; i ++ ) { if ( i > 0 ) sb . append ( ", " ) ; sb . append ( terms [ i ] ) . append ( '/' ) . append ( termFreqs [ i ] ) ; } sb . append ( '}' ) ; return sb . toString ( ) ; } public int size ( ) { return terms . length ; } public String [ ] getTerms ( ) { return terms ; } public int [ ] getTermFrequencies ( ) { return termFreqs ; } public int indexOf ( String term ) { int res = Arrays . binarySearch ( terms , term ) ; return res >= 0 ? res : - 1 ; } public int [ ] indexesOf ( String [ ] terms , int start , int len ) { int res [ ] = new int [ len ] ; for ( int i = 0 ; i < len ; i ++ ) { res [ i ] = indexOf ( terms [ i ] ) ; } return res ; } } 	0	['10', '1', '0', '4', '37', '0', '0', '4', '9', '0.388888889', '278', '1', '0', '0', '0.34', '0', '0', '26.6', '5', '1.6', '0']
package org . apache . lucene . analysis ; import java . io . * ; class PorterStemmer { private char [ ] b ; private int i , j , k , k0 ; private boolean dirty = false ; private static final int INC = 50 ; private static final int EXTRA = 1 ; public PorterStemmer ( ) { b = new char [ INC ] ; i = 0 ; } public void reset ( ) { i = 0 ; dirty = false ; } public void add ( char ch ) { if ( b . length <= i + EXTRA ) { char [ ] new_b = new char [ b . length + INC ] ; for ( int c = 0 ; c < b . length ; c ++ ) new_b [ c ] = b [ c ] ; b = new_b ; } b [ i ++ ] = ch ; } public String toString ( ) { return new String ( b , 0 , i ) ; } public int getResultLength ( ) { return i ; } public char [ ] getResultBuffer ( ) { return b ; } private final boolean cons ( int i ) { switch ( b [ i ] ) { case 'a' : case 'e' : case 'i' : case 'o' : case 'u' : return false ; case 'y' : return ( i == k0 ) ? true : ! cons ( i - 1 ) ; default : return true ; } } private final int m ( ) { int n = 0 ; int i = k0 ; while ( true ) { if ( i > j ) return n ; if ( ! cons ( i ) ) break ; i ++ ; } i ++ ; while ( true ) { while ( true ) { if ( i > j ) return n ; if ( cons ( i ) ) break ; i ++ ; } i ++ ; n ++ ; while ( true ) { if ( i > j ) return n ; if ( ! cons ( i ) ) break ; i ++ ; } i ++ ; } } private final boolean vowelinstem ( ) { int i ; for ( i = k0 ; i <= j ; i ++ ) if ( ! cons ( i ) ) return true ; return false ; } private final boolean doublec ( int j ) { if ( j < k0 + 1 ) return false ; if ( b [ j ] != b [ j - 1 ] ) return false ; return cons ( j ) ; } private final boolean cvc ( int i ) { if ( i < k0 + 2 || ! cons ( i ) || cons ( i - 1 ) || ! cons ( i - 2 ) ) return false ; else { int ch = b [ i ] ; if ( ch == 'w' || ch == 'x' || ch == 'y' ) return false ; } return true ; } private final boolean ends ( String s ) { int l = s . length ( ) ; int o = k - l + 1 ; if ( o < k0 ) return false ; for ( int i = 0 ; i < l ; i ++ ) if ( b [ o + i ] != s . charAt ( i ) ) return false ; j = k - l ; return true ; } void setto ( String s ) { int l = s . length ( ) ; int o = j + 1 ; for ( int i = 0 ; i < l ; i ++ ) b [ o + i ] = s . charAt ( i ) ; k = j + l ; dirty = true ; } void r ( String s ) { if ( m ( ) > 0 ) setto ( s ) ; } private final void step1 ( ) { if ( b [ k ] == 's' ) { if ( ends ( "sses" ) ) k -= 2 ; else if ( ends ( "ies" ) ) setto ( "i" ) ; else if ( b [ k - 1 ] != 's' ) k -- ; } if ( ends ( "eed" ) ) { if ( m ( ) > 0 ) k -- ; } else if ( ( ends ( "ed" ) || ends ( "ing" ) ) && vowelinstem ( ) ) { k = j ; if ( ends ( "at" ) ) setto ( "ate" ) ; else if ( ends ( "bl" ) ) setto ( "ble" ) ; else if ( ends ( "iz" ) ) setto ( "ize" ) ; else if ( doublec ( k ) ) { int ch = b [ k -- ] ; if ( ch == 'l' || ch == 's' || ch == 'z' ) k ++ ; } else if ( m ( ) == 1 && cvc ( k ) ) setto ( "e" ) ; } } private final void step2 ( ) { if ( ends ( "y" ) && vowelinstem ( ) ) { b [ k ] = 'i' ; dirty = true ; } } private final void step3 ( ) { if ( k == k0 ) return ; switch ( b [ k - 1 ] ) { case 'a' : if ( ends ( "ational" ) ) { r ( "ate" ) ; break ; } if ( ends ( "tional" ) ) { r ( "tion" ) ; break ; } break ; case 'c' : if ( ends ( "enci" ) ) { r ( "ence" ) ; break ; } if ( ends ( "anci" ) ) { r ( "ance" ) ; break ; } break ; case 'e' : if ( ends ( "izer" ) ) { r ( "ize" ) ; break ; } break ; case 'l' : if ( ends ( "bli" ) ) { r ( "ble" ) ; break ; } if ( ends ( "alli" ) ) { r ( "al" ) ; break ; } if ( ends ( "entli" ) ) { r ( "ent" ) ; break ; } if ( ends ( "eli" ) ) { r ( "e" ) ; break ; } if ( ends ( "ousli" ) ) { r ( "ous" ) ; break ; } break ; case 'o' : if ( ends ( "ization" ) ) { r ( "ize" ) ; break ; } if ( ends ( "ation" ) ) { r ( "ate" ) ; break ; } if ( ends ( "ator" ) ) { r ( "ate" ) ; break ; } break ; case 's' : if ( ends ( "alism" ) ) { r ( "al" ) ; break ; } if ( ends ( "iveness" ) ) { r ( "ive" ) ; break ; } if ( ends ( "fulness" ) ) { r ( "ful" ) ; break ; } if ( ends ( "ousness" ) ) { r ( "ous" ) ; break ; } break ; case 't' : if ( ends ( "aliti" ) ) { r ( "al" ) ; break ; } if ( ends ( "iviti" ) ) { r ( "ive" ) ; break ; } if ( ends ( "biliti" ) ) { r ( "ble" ) ; break ; } break ; case 'g' : if ( ends ( "logi" ) ) { r ( "log" ) ; break ; } } } private final void step4 ( ) { switch ( b [ k ] ) { case 'e' : if ( ends ( "icate" ) ) { r ( "ic" ) ; break ; } if ( ends ( "ative" ) ) { r ( "" ) ; break ; } if ( ends ( "alize" ) ) { r ( "al" ) ; break ; } break ; case 'i' : if ( ends ( "iciti" ) ) { r ( "ic" ) ; break ; } break ; case 'l' : if ( ends ( "ical" ) ) { r ( "ic" ) ; break ; } if ( ends ( "ful" ) ) { r ( "" ) ; break ; } break ; case 's' : if ( ends ( "ness" ) ) { r ( "" ) ; break ; } break ; } } private final void step5 ( ) { if ( k == k0 ) return ; switch ( b [ k - 1 ] ) { case 'a' : if ( ends ( "al" ) ) break ; return ; case 'c' : if ( ends ( "ance" ) ) break ; if ( ends ( "ence" ) ) break ; return ; case 'e' : if ( ends ( "er" ) ) break ; return ; case 'i' : if ( ends ( "ic" ) ) break ; return ; case 'l' : if ( ends ( "able" ) ) break ; if ( ends ( "ible" ) ) break ; return ; case 'n' : if ( ends ( "ant" ) ) break ; if ( ends ( "ement" ) ) break ; if ( ends ( "ment" ) ) break ; if ( ends ( "ent" ) ) break ; return ; case 'o' : if ( ends ( "ion" ) && j >= 0 && ( b [ j ] == 's' || b [ j ] == 't' ) ) break ; if ( ends ( "ou" ) ) break ; return ; case 's' : if ( ends ( "ism" ) ) break ; return ; case 't' : if ( ends ( "ate" ) ) break ; if ( ends ( "iti" ) ) break ; return ; case 'u' : if ( ends ( "ous" ) ) break ; return ; case 'v' : if ( ends ( "ive" ) ) break ; return ; case 'z' : if ( ends ( "ize" ) ) break ; return ; default : return ; } if ( m ( ) > 1 ) k = j ; } private final void step6 ( ) { j = k ; if ( b [ k ] == 'e' ) { int a = m ( ) ; if ( a > 1 || a == 1 && ! cvc ( k - 1 ) ) k -- ; } if ( b [ k ] == 'l' && doublec ( k ) && m ( ) > 1 ) k -- ; } public String stem ( String s ) { if ( stem ( s . toCharArray ( ) , s . length ( ) ) ) return toString ( ) ; else return s ; } public boolean stem ( char [ ] word ) { return stem ( word , word . length ) ; } public boolean stem ( char [ ] wordBuffer , int offset , int wordLen ) { reset ( ) ; if ( b . length < wordLen ) { char [ ] new_b = new char [ wordLen + EXTRA ] ; b = new_b ; } for ( int j = 0 ; j < wordLen ; j ++ ) b [ j ] = wordBuffer [ offset + j ] ; i = wordLen ; return stem ( 0 ) ; } public boolean stem ( char [ ] word , int wordLen ) { return stem ( word , 0 , wordLen ) ; } public boolean stem ( ) { return stem ( 0 ) ; } public boolean stem ( int i0 ) { k = i - 1 ; k0 = i0 ; if ( k > k0 + 1 ) { step1 ( ) ; step2 ( ) ; step3 ( ) ; step4 ( ) ; step5 ( ) ; step6 ( ) ; } if ( i != k + 1 ) dirty = true ; i = k + 1 ; return dirty ; } public static void main ( String [ ] args ) { PorterStemmer s = new PorterStemmer ( ) ; for ( int i = 0 ; i < args . length ; i ++ ) { try { InputStream in = new FileInputStream ( args [ i ] ) ; byte [ ] buffer = new byte [ 1024 ] ; int bufferLen , offset , ch ; bufferLen = in . read ( buffer ) ; offset = 0 ; s . reset ( ) ; while ( true ) { if ( offset < bufferLen ) ch = buffer [ offset ++ ] ; else { bufferLen = in . read ( buffer ) ; offset = 0 ; if ( bufferLen < 0 ) ch = - 1 ; else ch = buffer [ offset ++ ] ; } if ( Character . isLetter ( ( char ) ch ) ) { s . add ( Character . toLowerCase ( ( char ) ch ) ) ; } else { s . stem ( ) ; System . out . print ( s . toString ( ) ) ; s . reset ( ) ; if ( ch < 0 ) break ; else { System . out . print ( ( char ) ch ) ; } } } in . close ( ) ; } catch ( IOException e ) { System . out . println ( "error reading " + args [ i ] ) ; } } } } 	0	['27', '1', '0', '1', '43', '13', '1', '0', '13', '0.600961538', '1174', '1', '0', '0', '0.25308642', '0', '0', '42.18518519', '26', '5.7407', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermDocs ; import org . apache . lucene . index . TermEnum ; import java . io . IOException ; import java . util . BitSet ; public class RangeFilter extends Filter { private String fieldName ; private String lowerTerm ; private String upperTerm ; private boolean includeLower ; private boolean includeUpper ; public RangeFilter ( String fieldName , String lowerTerm , String upperTerm , boolean includeLower , boolean includeUpper ) { this . fieldName = fieldName ; this . lowerTerm = lowerTerm ; this . upperTerm = upperTerm ; this . includeLower = includeLower ; this . includeUpper = includeUpper ; if ( null == lowerTerm && null == upperTerm ) { throw new IllegalArgumentException ( "At least one value must be non-null" ) ; } if ( includeLower && null == lowerTerm ) { throw new IllegalArgumentException ( "The lower bound must be non-null to be inclusive" ) ; } if ( includeUpper && null == upperTerm ) { throw new IllegalArgumentException ( "The upper bound must be non-null to be inclusive" ) ; } } public static RangeFilter Less ( String fieldName , String upperTerm ) { return new RangeFilter ( fieldName , null , upperTerm , false , true ) ; } public static RangeFilter More ( String fieldName , String lowerTerm ) { return new RangeFilter ( fieldName , lowerTerm , null , true , false ) ; } public BitSet bits ( IndexReader reader ) throws IOException { BitSet bits = new BitSet ( reader . maxDoc ( ) ) ; TermEnum enumerator = ( null != lowerTerm ? reader . terms ( new Term ( fieldName , lowerTerm ) ) : reader . terms ( new Term ( fieldName , "" ) ) ) ; try { if ( enumerator . term ( ) == null ) { return bits ; } boolean checkLower = false ; if ( ! includeLower ) checkLower = true ; TermDocs termDocs = reader . termDocs ( ) ; try { do { Term term = enumerator . term ( ) ; if ( term != null && term . field ( ) . equals ( fieldName ) ) { if ( ! checkLower || null == lowerTerm || term . text ( ) . compareTo ( lowerTerm ) > 0 ) { checkLower = false ; if ( upperTerm != null ) { int compare = upperTerm . compareTo ( term . text ( ) ) ; if ( ( compare < 0 ) || ( ! includeUpper && compare == 0 ) ) { break ; } } termDocs . seek ( enumerator . term ( ) ) ; while ( termDocs . next ( ) ) { bits . set ( termDocs . doc ( ) ) ; } } } else { break ; } } while ( enumerator . next ( ) ) ; } finally { termDocs . close ( ) ; } } finally { enumerator . close ( ) ; } return bits ; } public String toString ( ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( fieldName ) ; buffer . append ( ":" ) ; buffer . append ( includeLower ? "[" : "{" ) ; if ( null != lowerTerm ) { buffer . append ( lowerTerm ) ; } buffer . append ( "-" ) ; if ( null != upperTerm ) { buffer . append ( upperTerm ) ; } buffer . append ( includeUpper ? "]" : "}" ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof RangeFilter ) ) return false ; RangeFilter other = ( RangeFilter ) o ; if ( ! this . fieldName . equals ( other . fieldName ) || this . includeLower != other . includeLower || this . includeUpper != other . includeUpper ) { return false ; } if ( this . lowerTerm != null ? ! this . lowerTerm . equals ( other . lowerTerm ) : other . lowerTerm != null ) return false ; if ( this . upperTerm != null ? ! this . upperTerm . equals ( other . upperTerm ) : other . upperTerm != null ) return false ; return true ; } public int hashCode ( ) { int h = fieldName . hashCode ( ) ; h ^= lowerTerm != null ? lowerTerm . hashCode ( ) : 0xB6ECE882 ; h = ( h << 1 ) | ( h > > > 31 ) ; h ^= ( upperTerm != null ? ( upperTerm . hashCode ( ) ) : 0x91BEC2C2 ) ; h ^= ( includeLower ? 0xD484B933 : 0 ) ^ ( includeUpper ? 0x6AE423AC : 0 ) ; return h ; } } 	0	['7', '2', '0', '6', '30', '1', '1', '5', '7', '0', '373', '1', '0', '0.142857143', '0.314285714', '1', '1', '51.57142857', '12', '3.5714', '0']
package org . apache . lucene . search ; import org . apache . lucene . util . PriorityQueue ; final class HitQueue extends PriorityQueue { HitQueue ( int size ) { initialize ( size ) ; } protected final boolean lessThan ( Object a , Object b ) { ScoreDoc hitA = ( ScoreDoc ) a ; ScoreDoc hitB = ( ScoreDoc ) b ; if ( hitA . score == hitB . score ) return hitA . doc > hitB . doc ; else return hitA . score < hitB . score ; } } 	0	['2', '2', '0', '6', '4', '1', '4', '2', '0', '2', '39', '0', '0', '0.916666667', '0.666666667', '1', '3', '18.5', '4', '2', '0']
package org . apache . lucene . search ; import java . io . IOException ; class NonMatchingScorer extends Scorer { public NonMatchingScorer ( ) { super ( null ) ; } public int doc ( ) { throw new UnsupportedOperationException ( ) ; } public boolean next ( ) throws IOException { return false ; } public float score ( ) { throw new UnsupportedOperationException ( ) ; } public boolean skipTo ( int target ) { return false ; } public Explanation explain ( int doc ) { Explanation e = new Explanation ( ) ; e . setDescription ( "No document matches." ) ; return e ; } } 	0	['6', '2', '0', '4', '10', '15', '1', '3', '6', '2', '31', '0', '0', '0.615384615', '0.666666667', '1', '3', '4.166666667', '1', '0.8333', '0']
package org . apache . lucene . search ; public class TopFieldDocs extends TopDocs { public SortField [ ] fields ; TopFieldDocs ( int totalHits , ScoreDoc [ ] scoreDocs , SortField [ ] fields , float maxScore ) { super ( totalHits , scoreDocs , maxScore ) ; this . fields = fields ; } } 	0	['1', '2', '0', '14', '2', '0', '11', '3', '0', '2', '11', '0', '1', '1', '1', '0', '0', '9', '0', '0', '0']
package org . apache . lucene . analysis . standard ; public interface StandardTokenizerConstants { int EOF = 0 ; int ALPHANUM = 1 ; int APOSTROPHE = 2 ; int ACRONYM = 3 ; int COMPANY = 4 ; int EMAIL = 5 ; int HOST = 6 ; int NUM = 7 ; int P = 8 ; int HAS_DIGIT = 9 ; int ALPHA = 10 ; int LETTER = 11 ; int CJ = 12 ; int KOREAN = 13 ; int DIGIT = 14 ; int NOISE = 15 ; int DEFAULT = 0 ; String [ ] tokenImage = { "<EOF>" , "<ALPHANUM>" , "<APOSTROPHE>" , "<ACRONYM>" , "<COMPANY>" , "<EMAIL>" , "<HOST>" , "<NUM>" , "<P>" , "<HAS_DIGIT>" , "<ALPHA>" , "<LETTER>" , "<CJ>" , "<KOREAN>" , "<DIGIT>" , "<NOISE>" , } ; } 	0	['1', '1', '0', '3', '1', '0', '3', '0', '0', '2', '87', '0', '0', '0', '0', '0', '0', '68', '0', '0', '0']
package org . apache . lucene . index ; import java . io . IOException ; public abstract class TermEnum { public abstract boolean next ( ) throws IOException ; public abstract Term term ( ) ; public abstract int docFreq ( ) ; public abstract void close ( ) throws IOException ; public boolean skipTo ( Term target ) throws IOException { do { if ( ! next ( ) ) return false ; } while ( target . compareTo ( term ( ) ) > 0 ) ; return true ; } } 	0	['6', '1', '5', '25', '8', '15', '24', '1', '6', '2', '21', '0', '0', '0', '0.583333333', '0', '0', '2.5', '1', '0.8333', '0']
package org . apache . lucene . index ; import org . apache . lucene . store . Directory ; import org . apache . lucene . store . IndexOutput ; import org . apache . lucene . util . StringHelper ; import java . io . IOException ; import java . util . Vector ; final class TermVectorsWriter { static final byte STORE_POSITIONS_WITH_TERMVECTOR = 0x1 ; static final byte STORE_OFFSET_WITH_TERMVECTOR = 0x2 ; static final int FORMAT_VERSION = 2 ; static final int FORMAT_SIZE = 4 ; static final String TVX_EXTENSION = ".tvx" ; static final String TVD_EXTENSION = ".tvd" ; static final String TVF_EXTENSION = ".tvf" ; private IndexOutput tvx = null , tvd = null , tvf = null ; private Vector fields = null ; private Vector terms = null ; private FieldInfos fieldInfos ; private TVField currentField = null ; private long currentDocPointer = - 1 ; public TermVectorsWriter ( Directory directory , String segment , FieldInfos fieldInfos ) throws IOException { tvx = directory . createOutput ( segment + TVX_EXTENSION ) ; tvx . writeInt ( FORMAT_VERSION ) ; tvd = directory . createOutput ( segment + TVD_EXTENSION ) ; tvd . writeInt ( FORMAT_VERSION ) ; tvf = directory . createOutput ( segment + TVF_EXTENSION ) ; tvf . writeInt ( FORMAT_VERSION ) ; this . fieldInfos = fieldInfos ; fields = new Vector ( fieldInfos . size ( ) ) ; terms = new Vector ( ) ; } public final void openDocument ( ) throws IOException { closeDocument ( ) ; currentDocPointer = tvd . getFilePointer ( ) ; } public final void closeDocument ( ) throws IOException { if ( isDocumentOpen ( ) ) { closeField ( ) ; writeDoc ( ) ; fields . clear ( ) ; currentDocPointer = - 1 ; } } public final boolean isDocumentOpen ( ) { return currentDocPointer != - 1 ; } public final void openField ( String field ) throws IOException { FieldInfo fieldInfo = fieldInfos . fieldInfo ( field ) ; openField ( fieldInfo . number , fieldInfo . storePositionWithTermVector , fieldInfo . storeOffsetWithTermVector ) ; } private void openField ( int fieldNumber , boolean storePositionWithTermVector , boolean storeOffsetWithTermVector ) throws IOException { if ( ! isDocumentOpen ( ) ) throw new IllegalStateException ( "Cannot open field when no document is open." ) ; closeField ( ) ; currentField = new TVField ( fieldNumber , storePositionWithTermVector , storeOffsetWithTermVector ) ; } public final void closeField ( ) throws IOException { if ( isFieldOpen ( ) ) { writeField ( ) ; fields . add ( currentField ) ; terms . clear ( ) ; currentField = null ; } } public final boolean isFieldOpen ( ) { return currentField != null ; } public final void addTerm ( String termText , int freq ) { addTerm ( termText , freq , null , null ) ; } public final void addTerm ( String termText , int freq , int [ ] positions , TermVectorOffsetInfo [ ] offsets ) { if ( ! isDocumentOpen ( ) ) throw new IllegalStateException ( "Cannot add terms when document is not open" ) ; if ( ! isFieldOpen ( ) ) throw new IllegalStateException ( "Cannot add terms when field is not open" ) ; addTermInternal ( termText , freq , positions , offsets ) ; } private final void addTermInternal ( String termText , int freq , int [ ] positions , TermVectorOffsetInfo [ ] offsets ) { TVTerm term = new TVTerm ( ) ; term . termText = termText ; term . freq = freq ; term . positions = positions ; term . offsets = offsets ; terms . add ( term ) ; } public final void addAllDocVectors ( TermFreqVector [ ] vectors ) throws IOException { openDocument ( ) ; if ( vectors != null ) { for ( int i = 0 ; i < vectors . length ; i ++ ) { boolean storePositionWithTermVector = false ; boolean storeOffsetWithTermVector = false ; try { TermPositionVector tpVector = ( TermPositionVector ) vectors [ i ] ; if ( tpVector . size ( ) > 0 && tpVector . getTermPositions ( 0 ) != null ) storePositionWithTermVector = true ; if ( tpVector . size ( ) > 0 && tpVector . getOffsets ( 0 ) != null ) storeOffsetWithTermVector = true ; FieldInfo fieldInfo = fieldInfos . fieldInfo ( tpVector . getField ( ) ) ; openField ( fieldInfo . number , storePositionWithTermVector , storeOffsetWithTermVector ) ; for ( int j = 0 ; j < tpVector . size ( ) ; j ++ ) addTermInternal ( tpVector . getTerms ( ) [ j ] , tpVector . getTermFrequencies ( ) [ j ] , tpVector . getTermPositions ( j ) , tpVector . getOffsets ( j ) ) ; closeField ( ) ; } catch ( ClassCastException ignore ) { TermFreqVector tfVector = vectors [ i ] ; FieldInfo fieldInfo = fieldInfos . fieldInfo ( tfVector . getField ( ) ) ; openField ( fieldInfo . number , storePositionWithTermVector , storeOffsetWithTermVector ) ; for ( int j = 0 ; j < tfVector . size ( ) ; j ++ ) addTermInternal ( tfVector . getTerms ( ) [ j ] , tfVector . getTermFrequencies ( ) [ j ] , null , null ) ; closeField ( ) ; } } } closeDocument ( ) ; } final void close ( ) throws IOException { try { closeDocument ( ) ; } finally { IOException keep = null ; if ( tvx != null ) try { tvx . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( tvd != null ) try { tvd . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( tvf != null ) try { tvf . close ( ) ; } catch ( IOException e ) { if ( keep == null ) keep = e ; } if ( keep != null ) throw ( IOException ) keep . fillInStackTrace ( ) ; } } private void writeField ( ) throws IOException { currentField . tvfPointer = tvf . getFilePointer ( ) ; final int size = terms . size ( ) ; tvf . writeVInt ( size ) ; boolean storePositions = currentField . storePositions ; boolean storeOffsets = currentField . storeOffsets ; byte bits = 0x0 ; if ( storePositions ) bits |= STORE_POSITIONS_WITH_TERMVECTOR ; if ( storeOffsets ) bits |= STORE_OFFSET_WITH_TERMVECTOR ; tvf . writeByte ( bits ) ; String lastTermText = "" ; for ( int i = 0 ; i < size ; i ++ ) { TVTerm term = ( TVTerm ) terms . elementAt ( i ) ; int start = StringHelper . stringDifference ( lastTermText , term . termText ) ; int length = term . termText . length ( ) - start ; tvf . writeVInt ( start ) ; tvf . writeVInt ( length ) ; tvf . writeChars ( term . termText , start , length ) ; tvf . writeVInt ( term . freq ) ; lastTermText = term . termText ; if ( storePositions ) { if ( term . positions == null ) throw new IllegalStateException ( "Trying to write positions that are null!" ) ; int position = 0 ; for ( int j = 0 ; j < term . freq ; j ++ ) { tvf . writeVInt ( term . positions [ j ] - position ) ; position = term . positions [ j ] ; } } if ( storeOffsets ) { if ( term . offsets == null ) throw new IllegalStateException ( "Trying to write offsets that are null!" ) ; int position = 0 ; for ( int j = 0 ; j < term . freq ; j ++ ) { tvf . writeVInt ( term . offsets [ j ] . getStartOffset ( ) - position ) ; tvf . writeVInt ( term . offsets [ j ] . getEndOffset ( ) - term . offsets [ j ] . getStartOffset ( ) ) ; position = term . offsets [ j ] . getEndOffset ( ) ; } } } } private void writeDoc ( ) throws IOException { if ( isFieldOpen ( ) ) throw new IllegalStateException ( "Field is still open while writing document" ) ; tvx . writeLong ( currentDocPointer ) ; final int size = fields . size ( ) ; tvd . writeVInt ( size ) ; for ( int i = 0 ; i < size ; i ++ ) { TVField field = ( TVField ) fields . elementAt ( i ) ; tvd . writeVInt ( field . number ) ; } long lastFieldPointer = 0 ; for ( int i = 0 ; i < size ; i ++ ) { TVField field = ( TVField ) fields . elementAt ( i ) ; tvd . writeVLong ( field . tvfPointer - lastFieldPointer ) ; lastFieldPointer = field . tvfPointer ; } } private static class TVField { int number ; long tvfPointer = 0 ; boolean storePositions = false ; boolean storeOffsets = false ; TVField ( int number , boolean storePos , boolean storeOff ) { this . number = number ; storePositions = storePos ; storeOffsets = storeOff ; } } private static class TVTerm { String termText ; int freq = 0 ; int positions [ ] = null ; TermVectorOffsetInfo [ ] offsets = null ; } } 	0	['15', '1', '0', '13', '54', '41', '2', '11', '10', '0.804761905', '675', '0.533333333', '5', '0', '0.237037037', '0', '0', '43', '3', '1.2', '0']
package org . apache . lucene . search ; import java . io . IOException ; import java . util . HashSet ; import java . util . Iterator ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; public abstract class Query implements java . io . Serializable , Cloneable { private float boost = 1.0f ; public void setBoost ( float b ) { boost = b ; } public float getBoost ( ) { return boost ; } public abstract String toString ( String field ) ; public String toString ( ) { return toString ( "" ) ; } protected Weight createWeight ( Searcher searcher ) throws IOException { throw new UnsupportedOperationException ( ) ; } public Weight weight ( Searcher searcher ) throws IOException { Query query = searcher . rewrite ( this ) ; Weight weight = query . createWeight ( searcher ) ; float sum = weight . sumOfSquaredWeights ( ) ; float norm = getSimilarity ( searcher ) . queryNorm ( sum ) ; weight . normalize ( norm ) ; return weight ; } public Query rewrite ( IndexReader reader ) throws IOException { return this ; } public Query combine ( Query [ ] queries ) { HashSet uniques = new HashSet ( ) ; for ( int i = 0 ; i < queries . length ; i ++ ) { Query query = queries [ i ] ; BooleanClause [ ] clauses = null ; boolean splittable = ( query instanceof BooleanQuery ) ; if ( splittable ) { BooleanQuery bq = ( BooleanQuery ) query ; splittable = bq . isCoordDisabled ( ) ; clauses = bq . getClauses ( ) ; for ( int j = 0 ; splittable && j < clauses . length ; j ++ ) { splittable = ( clauses [ j ] . getOccur ( ) == BooleanClause . Occur . SHOULD ) ; } } if ( splittable ) { for ( int j = 0 ; j < clauses . length ; j ++ ) { uniques . add ( clauses [ j ] . getQuery ( ) ) ; } } else { uniques . add ( query ) ; } } if ( uniques . size ( ) == 1 ) { return ( Query ) uniques . iterator ( ) . next ( ) ; } Iterator it = uniques . iterator ( ) ; BooleanQuery result = new BooleanQuery ( true ) ; while ( it . hasNext ( ) ) result . add ( ( Query ) it . next ( ) , BooleanClause . Occur . SHOULD ) ; return result ; } public void extractTerms ( Set terms ) { throw new UnsupportedOperationException ( ) ; } public static Query mergeBooleanQueries ( Query [ ] queries ) { HashSet allClauses = new HashSet ( ) ; for ( int i = 0 ; i < queries . length ; i ++ ) { BooleanClause [ ] clauses = ( ( BooleanQuery ) queries [ i ] ) . getClauses ( ) ; for ( int j = 0 ; j < clauses . length ; j ++ ) { allClauses . add ( clauses [ j ] ) ; } } boolean coordDisabled = queries . length == 0 ? false : ( ( BooleanQuery ) queries [ 0 ] ) . isCoordDisabled ( ) ; BooleanQuery result = new BooleanQuery ( coordDisabled ) ; Iterator i = allClauses . iterator ( ) ; while ( i . hasNext ( ) ) { result . add ( ( BooleanClause ) i . next ( ) ) ; } return result ; } public Similarity getSimilarity ( Searcher searcher ) { return searcher . getSimilarity ( ) ; } public Object clone ( ) { try { return ( Query ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeException ( "Clone not supported: " + e . getMessage ( ) ) ; } } } 	0	['13', '1', '13', '45', '39', '72', '42', '7', '12', '0.833333333', '249', '1', '0', '0', '0.230769231', '0', '0', '18.07692308', '9', '1.8462', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermEnum ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . util . ToStringUtils ; public class RangeQuery extends Query { private Term lowerTerm ; private Term upperTerm ; private boolean inclusive ; public RangeQuery ( Term lowerTerm , Term upperTerm , boolean inclusive ) { if ( lowerTerm == null && upperTerm == null ) { throw new IllegalArgumentException ( "At least one term must be non-null" ) ; } if ( lowerTerm != null && upperTerm != null && lowerTerm . field ( ) != upperTerm . field ( ) ) { throw new IllegalArgumentException ( "Both terms must be for the same field" ) ; } if ( lowerTerm != null ) { this . lowerTerm = lowerTerm ; } else { this . lowerTerm = new Term ( upperTerm . field ( ) , "" ) ; } this . upperTerm = upperTerm ; this . inclusive = inclusive ; } public Query rewrite ( IndexReader reader ) throws IOException { BooleanQuery query = new BooleanQuery ( true ) ; TermEnum enumerator = reader . terms ( lowerTerm ) ; try { boolean checkLower = false ; if ( ! inclusive ) checkLower = true ; String testField = getField ( ) ; do { Term term = enumerator . term ( ) ; if ( term != null && term . field ( ) == testField ) { if ( ! checkLower || term . text ( ) . compareTo ( lowerTerm . text ( ) ) > 0 ) { checkLower = false ; if ( upperTerm != null ) { int compare = upperTerm . text ( ) . compareTo ( term . text ( ) ) ; if ( ( compare < 0 ) || ( ! inclusive && compare == 0 ) ) break ; } TermQuery tq = new TermQuery ( term ) ; tq . setBoost ( getBoost ( ) ) ; query . add ( tq , BooleanClause . Occur . SHOULD ) ; } } else { break ; } } while ( enumerator . next ( ) ) ; } finally { enumerator . close ( ) ; } return query ; } public String getField ( ) { return ( lowerTerm != null ? lowerTerm . field ( ) : upperTerm . field ( ) ) ; } public Term getLowerTerm ( ) { return lowerTerm ; } public Term getUpperTerm ( ) { return upperTerm ; } public boolean isInclusive ( ) { return inclusive ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! getField ( ) . equals ( field ) ) { buffer . append ( getField ( ) ) ; buffer . append ( ":" ) ; } buffer . append ( inclusive ? "[" : "{" ) ; buffer . append ( lowerTerm != null ? lowerTerm . text ( ) : "null" ) ; buffer . append ( " TO " ) ; buffer . append ( upperTerm != null ? upperTerm . text ( ) : "null" ) ; buffer . append ( inclusive ? "]" : "}" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof RangeQuery ) ) return false ; final RangeQuery other = ( RangeQuery ) o ; if ( this . getBoost ( ) != other . getBoost ( ) ) return false ; if ( this . inclusive != other . inclusive ) return false ; if ( this . lowerTerm != null ? ! this . lowerTerm . equals ( other . lowerTerm ) : other . lowerTerm != null ) return false ; if ( this . upperTerm != null ? ! this . upperTerm . equals ( other . upperTerm ) : other . upperTerm != null ) return false ; return true ; } public int hashCode ( ) { int h = Float . floatToIntBits ( getBoost ( ) ) ; h ^= lowerTerm != null ? lowerTerm . hashCode ( ) : 0 ; h ^= ( h << 25 ) | ( h > > > 8 ) ; h ^= upperTerm != null ? upperTerm . hashCode ( ) : 0 ; h ^= this . inclusive ? 0x2742E74A : 0 ; return h ; } } 	0	['9', '2', '0', '9', '32', '0', '1', '8', '9', '0.291666667', '340', '1', '2', '0.6', '0.259259259', '2', '3', '36.44444444', '11', '3', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermEnum ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . util . ToStringUtils ; public class PrefixQuery extends Query { private Term prefix ; public PrefixQuery ( Term prefix ) { this . prefix = prefix ; } public Term getPrefix ( ) { return prefix ; } public Query rewrite ( IndexReader reader ) throws IOException { BooleanQuery query = new BooleanQuery ( true ) ; TermEnum enumerator = reader . terms ( prefix ) ; try { String prefixText = prefix . text ( ) ; String prefixField = prefix . field ( ) ; do { Term term = enumerator . term ( ) ; if ( term != null && term . text ( ) . startsWith ( prefixText ) && term . field ( ) == prefixField ) { TermQuery tq = new TermQuery ( term ) ; tq . setBoost ( getBoost ( ) ) ; query . add ( tq , BooleanClause . Occur . SHOULD ) ; } else { break ; } } while ( enumerator . next ( ) ) ; } finally { enumerator . close ( ) ; } return query ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! prefix . field ( ) . equals ( field ) ) { buffer . append ( prefix . field ( ) ) ; buffer . append ( ":" ) ; } buffer . append ( prefix . text ( ) ) ; buffer . append ( '*' ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( ! ( o instanceof PrefixQuery ) ) return false ; PrefixQuery other = ( PrefixQuery ) o ; return ( this . getBoost ( ) == other . getBoost ( ) ) && this . prefix . equals ( other . prefix ) ; } public int hashCode ( ) { return Float . floatToIntBits ( getBoost ( ) ) ^ prefix . hashCode ( ) ^ 0x6634D93C ; } } 	0	['6', '2', '0', '9', '28', '0', '1', '8', '6', '0', '147', '1', '1', '0.705882353', '0.333333333', '2', '3', '23.33333333', '4', '1.5', '0']
package org . apache . lucene . analysis . standard ; import java . io . * ; public class StandardTokenizer extends org . apache . lucene . analysis . Tokenizer implements StandardTokenizerConstants { public StandardTokenizer ( Reader reader ) { this ( new FastCharStream ( reader ) ) ; this . input = reader ; } final public org . apache . lucene . analysis . Token next ( ) throws ParseException , IOException { Token token = null ; switch ( ( jj_ntk == - 1 ) ? jj_ntk ( ) : jj_ntk ) { case ALPHANUM : token = jj_consume_token ( ALPHANUM ) ; break ; case APOSTROPHE : token = jj_consume_token ( APOSTROPHE ) ; break ; case ACRONYM : token = jj_consume_token ( ACRONYM ) ; break ; case COMPANY : token = jj_consume_token ( COMPANY ) ; break ; case EMAIL : token = jj_consume_token ( EMAIL ) ; break ; case HOST : token = jj_consume_token ( HOST ) ; break ; case NUM : token = jj_consume_token ( NUM ) ; break ; case CJ : token = jj_consume_token ( CJ ) ; break ; case 0 : token = jj_consume_token ( 0 ) ; break ; default : jj_la1 [ 0 ] = jj_gen ; jj_consume_token ( - 1 ) ; throw new ParseException ( ) ; } if ( token . kind == EOF ) { { if ( true ) return null ; } } else { { if ( true ) return new org . apache . lucene . analysis . Token ( token . image , token . beginColumn , token . endColumn , tokenImage [ token . kind ] ) ; } } throw new Error ( "Missing return statement in function" ) ; } public StandardTokenizerTokenManager token_source ; public Token token , jj_nt ; private int jj_ntk ; private int jj_gen ; final private int [ ] jj_la1 = new int [ 1 ] ; static private int [ ] jj_la1_0 ; static { jj_la1_0 ( ) ; } private static void jj_la1_0 ( ) { jj_la1_0 = new int [ ] { 0x10ff , } ; } public StandardTokenizer ( CharStream stream ) { token_source = new StandardTokenizerTokenManager ( stream ) ; token = new Token ( ) ; jj_ntk = - 1 ; jj_gen = 0 ; for ( int i = 0 ; i < 1 ; i ++ ) jj_la1 [ i ] = - 1 ; } public void ReInit ( CharStream stream ) { token_source . ReInit ( stream ) ; token = new Token ( ) ; jj_ntk = - 1 ; jj_gen = 0 ; for ( int i = 0 ; i < 1 ; i ++ ) jj_la1 [ i ] = - 1 ; } public StandardTokenizer ( StandardTokenizerTokenManager tm ) { token_source = tm ; token = new Token ( ) ; jj_ntk = - 1 ; jj_gen = 0 ; for ( int i = 0 ; i < 1 ; i ++ ) jj_la1 [ i ] = - 1 ; } public void ReInit ( StandardTokenizerTokenManager tm ) { token_source = tm ; token = new Token ( ) ; jj_ntk = - 1 ; jj_gen = 0 ; for ( int i = 0 ; i < 1 ; i ++ ) jj_la1 [ i ] = - 1 ; } final private Token jj_consume_token ( int kind ) throws ParseException { Token oldToken ; if ( ( oldToken = token ) . next != null ) token = token . next ; else token = token . next = token_source . getNextToken ( ) ; jj_ntk = - 1 ; if ( token . kind == kind ) { jj_gen ++ ; return token ; } token = oldToken ; jj_kind = kind ; throw generateParseException ( ) ; } final public Token getNextToken ( ) { if ( token . next != null ) token = token . next ; else token = token . next = token_source . getNextToken ( ) ; jj_ntk = - 1 ; jj_gen ++ ; return token ; } final public Token getToken ( int index ) { Token t = token ; for ( int i = 0 ; i < index ; i ++ ) { if ( t . next != null ) t = t . next ; else t = t . next = token_source . getNextToken ( ) ; } return t ; } final private int jj_ntk ( ) { if ( ( jj_nt = token . next ) == null ) return ( jj_ntk = ( token . next = token_source . getNextToken ( ) ) . kind ) ; else return ( jj_ntk = jj_nt . kind ) ; } private java . util . Vector jj_expentries = new java . util . Vector ( ) ; private int [ ] jj_expentry ; private int jj_kind = - 1 ; public ParseException generateParseException ( ) { jj_expentries . removeAllElements ( ) ; boolean [ ] la1tokens = new boolean [ 16 ] ; for ( int i = 0 ; i < 16 ; i ++ ) { la1tokens [ i ] = false ; } if ( jj_kind >= 0 ) { la1tokens [ jj_kind ] = true ; jj_kind = - 1 ; } for ( int i = 0 ; i < 1 ; i ++ ) { if ( jj_la1 [ i ] == jj_gen ) { for ( int j = 0 ; j < 32 ; j ++ ) { if ( ( jj_la1_0 [ i ] & ( 1 << j ) ) != 0 ) { la1tokens [ j ] = true ; } } } } for ( int i = 0 ; i < 16 ; i ++ ) { if ( la1tokens [ i ] ) { jj_expentry = new int [ 1 ] ; jj_expentry [ 0 ] = i ; jj_expentries . addElement ( jj_expentry ) ; } } int [ ] [ ] exptokseq = new int [ jj_expentries . size ( ) ] [ ] ; for ( int i = 0 ; i < jj_expentries . size ( ) ; i ++ ) { exptokseq [ i ] = ( int [ ] ) jj_expentries . elementAt ( i ) ; } return new ParseException ( token , exptokseq , tokenImage ) ; } final public void enable_tracing ( ) { } final public void disable_tracing ( ) { } } 	0	['15', '3', '0', '9', '29', '15', '1', '8', '11', '0.6', '523', '0.7', '3', '0.214285714', '0.285714286', '1', '1', '33.2', '10', '1.7333', '0']
package org . apache . lucene . search ; public class TopDocs implements java . io . Serializable { public int totalHits ; public ScoreDoc [ ] scoreDocs ; private float maxScore ; public float getMaxScore ( ) { return maxScore ; } public void setMaxScore ( float maxScore ) { this . maxScore = maxScore ; } TopDocs ( int totalHits , ScoreDoc [ ] scoreDocs , float maxScore ) { this . totalHits = totalHits ; this . scoreDocs = scoreDocs ; this . maxScore = maxScore ; } } 	0	['3', '1', '1', '14', '4', '0', '13', '1', '2', '0.666666667', '25', '0.333333333', '1', '0', '0.583333333', '0', '0', '6.333333333', '1', '0.6667', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; import java . io . IOException ; public abstract class Tokenizer extends TokenStream { protected Reader input ; protected Tokenizer ( ) { } protected Tokenizer ( Reader input ) { this . input = input ; } public void close ( ) throws IOException { input . close ( ) ; } } 	0	['3', '2', '3', '4', '5', '1', '3', '1', '1', '0.5', '17', '1', '0', '0.666666667', '0.666666667', '0', '0', '4.333333333', '1', '0.3333', '0']
package org . apache . lucene ; public final class LucenePackage { private LucenePackage ( ) { } public static Package get ( ) { return LucenePackage . class . getPackage ( ) ; } } 	0	['3', '1', '0', '0', '8', '3', '0', '0', '1', '1', '27', '0', '0', '0', '0.333333333', '0', '0', '7.666666667', '2', '1', '0']
package org . apache . lucene . util ; import java . io . ObjectStreamException ; import java . io . Serializable ; import java . io . StreamCorruptedException ; import java . util . HashMap ; import java . util . Map ; public abstract class Parameter implements Serializable { static Map allParameters = new HashMap ( ) ; private String name ; private Parameter ( ) { } protected Parameter ( String name ) { this . name = name ; String key = makeKey ( name ) ; if ( allParameters . containsKey ( key ) ) throw new IllegalArgumentException ( "Parameter name " + key + " already used!" ) ; allParameters . put ( key , this ) ; } private String makeKey ( String name ) { return getClass ( ) + " " + name ; } public String toString ( ) { return name ; } protected Object readResolve ( ) throws ObjectStreamException { Object par = allParameters . get ( makeKey ( name ) ) ; if ( par == null ) throw new StreamCorruptedException ( "Unknown parameter value: " + name ) ; return par ; } } 	0	['6', '1', '5', '5', '18', '5', '5', '0', '1', '0.6', '88', '0.5', '0', '0', '0.7', '0', '0', '13.33333333', '1', '0.5', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . search . Weight ; import org . apache . lucene . search . Searcher ; public abstract class SpanQuery extends Query { public abstract Spans getSpans ( IndexReader reader ) throws IOException ; public abstract String getField ( ) ; public abstract Collection getTerms ( ) ; protected Weight createWeight ( Searcher searcher ) throws IOException { return new SpanWeight ( this , searcher ) ; } } 	0	['5', '2', '5', '15', '7', '10', '10', '6', '4', '2', '14', '0', '0', '0.75', '0.466666667', '1', '1', '1.8', '1', '0.8', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public final class SimpleAnalyzer extends Analyzer { public TokenStream tokenStream ( String fieldName , Reader reader ) { return new LowerCaseTokenizer ( reader ) ; } } 	0	['2', '2', '0', '4', '4', '1', '1', '3', '2', '2', '10', '0', '0', '0.666666667', '0.666666667', '0', '0', '4', '1', '0.5', '0']
package org . apache . lucene . search ; import org . apache . lucene . util . PriorityQueue ; import java . text . Collator ; import java . util . Locale ; class FieldDocSortedHitQueue extends PriorityQueue { volatile SortField [ ] fields ; volatile Collator [ ] collators ; FieldDocSortedHitQueue ( SortField [ ] fields , int size ) { this . fields = fields ; this . collators = hasCollators ( fields ) ; initialize ( size ) ; } synchronized void setFields ( SortField [ ] fields ) { if ( this . fields == null ) { this . fields = fields ; this . collators = hasCollators ( fields ) ; } } SortField [ ] getFields ( ) { return fields ; } private Collator [ ] hasCollators ( final SortField [ ] fields ) { if ( fields == null ) return null ; Collator [ ] ret = new Collator [ fields . length ] ; for ( int i = 0 ; i < fields . length ; ++ i ) { Locale locale = fields [ i ] . getLocale ( ) ; if ( locale != null ) ret [ i ] = Collator . getInstance ( locale ) ; } return ret ; } protected final boolean lessThan ( final Object a , final Object b ) { final FieldDoc docA = ( FieldDoc ) a ; final FieldDoc docB = ( FieldDoc ) b ; final int n = fields . length ; int c = 0 ; for ( int i = 0 ; i < n && c == 0 ; ++ i ) { final int type = fields [ i ] . getType ( ) ; switch ( type ) { case SortField . SCORE : float r1 = ( ( Float ) docA . fields [ i ] ) . floatValue ( ) ; float r2 = ( ( Float ) docB . fields [ i ] ) . floatValue ( ) ; if ( r1 > r2 ) c = - 1 ; if ( r1 < r2 ) c = 1 ; break ; case SortField . DOC : case SortField . INT : int i1 = ( ( Integer ) docA . fields [ i ] ) . intValue ( ) ; int i2 = ( ( Integer ) docB . fields [ i ] ) . intValue ( ) ; if ( i1 < i2 ) c = - 1 ; if ( i1 > i2 ) c = 1 ; break ; case SortField . STRING : String s1 = ( String ) docA . fields [ i ] ; String s2 = ( String ) docB . fields [ i ] ; if ( s1 == null ) c = ( s2 == null ) ? 0 : - 1 ; else if ( s2 == null ) c = 1 ; else if ( fields [ i ] . getLocale ( ) == null ) { c = s1 . compareTo ( s2 ) ; } else { c = collators [ i ] . compare ( s1 , s2 ) ; } break ; case SortField . FLOAT : float f1 = ( ( Float ) docA . fields [ i ] ) . floatValue ( ) ; float f2 = ( ( Float ) docB . fields [ i ] ) . floatValue ( ) ; if ( f1 < f2 ) c = - 1 ; if ( f1 > f2 ) c = 1 ; break ; case SortField . CUSTOM : c = docA . fields [ i ] . compareTo ( docB . fields [ i ] ) ; break ; case SortField . AUTO : throw new RuntimeException ( "FieldDocSortedHitQueue cannot use an AUTO SortField" ) ; default : throw new RuntimeException ( "invalid SortField type: " + type ) ; } if ( fields [ i ] . getReverse ( ) ) { c = - c ; } } if ( c == 0 ) return docA . doc > docB . doc ; return c > 0 ; } } 	0	['5', '2', '0', '6', '21', '0', '3', '3', '0', '0.375', '274', '0', '1', '0.733333333', '0.5', '1', '3', '53.4', '18', '5', '0']
package org . apache . lucene . search ; public abstract class HitCollector { public abstract void collect ( int doc , float score ) ; } 	0	['2', '1', '6', '21', '3', '1', '21', '0', '2', '2', '5', '0', '0', '0', '0.666666667', '0', '0', '1.5', '1', '0.5', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public class WhitespaceTokenizer extends CharTokenizer { public WhitespaceTokenizer ( Reader in ) { super ( in ) ; } protected boolean isTokenChar ( char c ) { return ! Character . isWhitespace ( c ) ; } } 	0	['2', '4', '0', '2', '4', '1', '1', '1', '1', '2', '13', '0', '0', '0.857142857', '0.666666667', '1', '1', '5.5', '2', '1', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . util . ToStringUtils ; public class SpanNotQuery extends SpanQuery { private SpanQuery include ; private SpanQuery exclude ; public SpanNotQuery ( SpanQuery include , SpanQuery exclude ) { this . include = include ; this . exclude = exclude ; if ( ! include . getField ( ) . equals ( exclude . getField ( ) ) ) throw new IllegalArgumentException ( "Clauses must have same field." ) ; } public SpanQuery getInclude ( ) { return include ; } public SpanQuery getExclude ( ) { return exclude ; } public String getField ( ) { return include . getField ( ) ; } public Collection getTerms ( ) { return include . getTerms ( ) ; } public void extractTerms ( Set terms ) { include . extractTerms ( terms ) ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "spanNot(" ) ; buffer . append ( include . toString ( field ) ) ; buffer . append ( ", " ) ; buffer . append ( exclude . toString ( field ) ) ; buffer . append ( ")" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public Spans getSpans ( final IndexReader reader ) throws IOException { return new Spans ( ) { private Spans includeSpans = include . getSpans ( reader ) ; private boolean moreInclude = true ; private Spans excludeSpans = exclude . getSpans ( reader ) ; private boolean moreExclude = excludeSpans . next ( ) ; public boolean next ( ) throws IOException { if ( moreInclude ) moreInclude = includeSpans . next ( ) ; while ( moreInclude && moreExclude ) { if ( includeSpans . doc ( ) > excludeSpans . doc ( ) ) moreExclude = excludeSpans . skipTo ( includeSpans . doc ( ) ) ; while ( moreExclude && includeSpans . doc ( ) == excludeSpans . doc ( ) && excludeSpans . end ( ) <= includeSpans . start ( ) ) { moreExclude = excludeSpans . next ( ) ; } if ( ! moreExclude || includeSpans . doc ( ) != excludeSpans . doc ( ) || includeSpans . end ( ) <= excludeSpans . start ( ) ) break ; moreInclude = includeSpans . next ( ) ; } return moreInclude ; } public boolean skipTo ( int target ) throws IOException { if ( moreInclude ) moreInclude = includeSpans . skipTo ( target ) ; if ( ! moreInclude ) return false ; if ( moreExclude && includeSpans . doc ( ) > excludeSpans . doc ( ) ) moreExclude = excludeSpans . skipTo ( includeSpans . doc ( ) ) ; while ( moreExclude && includeSpans . doc ( ) == excludeSpans . doc ( ) && excludeSpans . end ( ) <= includeSpans . start ( ) ) { moreExclude = excludeSpans . next ( ) ; } if ( ! moreExclude || includeSpans . doc ( ) != excludeSpans . doc ( ) || includeSpans . end ( ) <= excludeSpans . start ( ) ) return true ; return next ( ) ; } public int doc ( ) { return includeSpans . doc ( ) ; } public int start ( ) { return includeSpans . start ( ) ; } public int end ( ) { return includeSpans . end ( ) ; } public String toString ( ) { return "spans(" + SpanNotQuery . this . toString ( ) + ")" ; } } ; } public Query rewrite ( IndexReader reader ) throws IOException { SpanNotQuery clone = null ; SpanQuery rewrittenInclude = ( SpanQuery ) include . rewrite ( reader ) ; if ( rewrittenInclude != include ) { clone = ( SpanNotQuery ) this . clone ( ) ; clone . include = rewrittenInclude ; } SpanQuery rewrittenExclude = ( SpanQuery ) exclude . rewrite ( reader ) ; if ( rewrittenExclude != exclude ) { if ( clone == null ) clone = ( SpanNotQuery ) this . clone ( ) ; clone . exclude = rewrittenExclude ; } if ( clone != null ) { return clone ; } else { return this ; } } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof SpanNotQuery ) ) return false ; SpanNotQuery other = ( SpanNotQuery ) o ; return this . include . equals ( other . include ) && this . exclude . equals ( other . exclude ) && this . getBoost ( ) == other . getBoost ( ) ; } public int hashCode ( ) { int h = include . hashCode ( ) ; h = ( h << 1 ) | ( h > > > 31 ) ; h ^= exclude . hashCode ( ) ; h = ( h << 1 ) | ( h > > > 31 ) ; h ^= Float . floatToRawIntBits ( getBoost ( ) ) ; return h ; } } 	0	['13', '3', '0', '6', '31', '0', '1', '6', '11', '0.375', '218', '1', '2', '0.571428571', '0.208791209', '2', '2', '15.61538462', '6', '1.3077', '0']
package org . apache . lucene . analysis . standard ; import org . apache . lucene . analysis . * ; public final class StandardFilter extends TokenFilter implements StandardTokenizerConstants { public StandardFilter ( TokenStream in ) { super ( in ) ; } private static final String APOSTROPHE_TYPE = tokenImage [ APOSTROPHE ] ; private static final String ACRONYM_TYPE = tokenImage [ ACRONYM ] ; public final org . apache . lucene . analysis . Token next ( ) throws java . io . IOException { org . apache . lucene . analysis . Token t = input . next ( ) ; if ( t == null ) return null ; String text = t . termText ( ) ; String type = t . type ( ) ; if ( type == APOSTROPHE_TYPE && ( text . endsWith ( "'s" ) || text . endsWith ( "'S" ) ) ) { return new org . apache . lucene . analysis . Token ( text . substring ( 0 , text . length ( ) - 2 ) , t . startOffset ( ) , t . endOffset ( ) , type ) ; } else if ( type == ACRONYM_TYPE ) { StringBuffer trimmed = new StringBuffer ( ) ; for ( int i = 0 ; i < text . length ( ) ; i ++ ) { char c = text . charAt ( i ) ; if ( c != '.' ) trimmed . append ( c ) ; } return new org . apache . lucene . analysis . Token ( trimmed . toString ( ) , t . startOffset ( ) , t . endOffset ( ) , type ) ; } else { return t ; } } } 	0	['3', '3', '0', '5', '17', '1', '1', '4', '2', '0.5', '98', '1', '0', '0.75', '0.75', '0', '0', '31', '1', '0.3333', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; import java . io . Reader ; public abstract class CharTokenizer extends Tokenizer { public CharTokenizer ( Reader input ) { super ( input ) ; } private int offset = 0 , bufferIndex = 0 , dataLen = 0 ; private static final int MAX_WORD_LEN = 255 ; private static final int IO_BUFFER_SIZE = 1024 ; private final char [ ] buffer = new char [ MAX_WORD_LEN ] ; private final char [ ] ioBuffer = new char [ IO_BUFFER_SIZE ] ; protected abstract boolean isTokenChar ( char c ) ; protected char normalize ( char c ) { return c ; } public final Token next ( ) throws IOException { int length = 0 ; int start = offset ; while ( true ) { final char c ; offset ++ ; if ( bufferIndex >= dataLen ) { dataLen = input . read ( ioBuffer ) ; bufferIndex = 0 ; } ; if ( dataLen == - 1 ) { if ( length > 0 ) break ; else return null ; } else c = ioBuffer [ bufferIndex ++ ] ; if ( isTokenChar ( c ) ) { if ( length == 0 ) start = offset - 1 ; buffer [ length ++ ] = normalize ( c ) ; if ( length == MAX_WORD_LEN ) break ; } else if ( length > 0 ) break ; } return new Token ( new String ( buffer , 0 , length ) , start , start + length ) ; } } 	0	['4', '3', '2', '4', '8', '4', '2', '2', '2', '0.857142857', '122', '1', '0', '0.5', '0.583333333', '0', '0', '27.75', '1', '0.75', '0']
package org . apache . lucene . document ; import java . text . ParseException ; import java . text . SimpleDateFormat ; import java . util . Calendar ; import java . util . Date ; import java . util . TimeZone ; public class DateTools { private final static TimeZone GMT = TimeZone . getTimeZone ( "GMT" ) ; private DateTools ( ) { } public static String dateToString ( Date date , Resolution resolution ) { return timeToString ( date . getTime ( ) , resolution ) ; } public static String timeToString ( long time , Resolution resolution ) { Calendar cal = Calendar . getInstance ( GMT ) ; cal . setTime ( new Date ( round ( time , resolution ) ) ) ; SimpleDateFormat sdf = new SimpleDateFormat ( ) ; sdf . setTimeZone ( GMT ) ; String pattern = null ; if ( resolution == Resolution . YEAR ) { pattern = "yyyy" ; } else if ( resolution == Resolution . MONTH ) { pattern = "yyyyMM" ; } else if ( resolution == Resolution . DAY ) { pattern = "yyyyMMdd" ; } else if ( resolution == Resolution . HOUR ) { pattern = "yyyyMMddHH" ; } else if ( resolution == Resolution . MINUTE ) { pattern = "yyyyMMddHHmm" ; } else if ( resolution == Resolution . SECOND ) { pattern = "yyyyMMddHHmmss" ; } else if ( resolution == Resolution . MILLISECOND ) { pattern = "yyyyMMddHHmmssSSS" ; } else { throw new IllegalArgumentException ( "unknown resolution " + resolution ) ; } sdf . applyPattern ( pattern ) ; return sdf . format ( cal . getTime ( ) ) ; } public static long stringToTime ( String dateString ) throws ParseException { return stringToDate ( dateString ) . getTime ( ) ; } public static Date stringToDate ( String dateString ) throws ParseException { String pattern = null ; if ( dateString . length ( ) == 4 ) pattern = "yyyy" ; else if ( dateString . length ( ) == 6 ) pattern = "yyyyMM" ; else if ( dateString . length ( ) == 8 ) pattern = "yyyyMMdd" ; else if ( dateString . length ( ) == 10 ) pattern = "yyyyMMddHH" ; else if ( dateString . length ( ) == 12 ) pattern = "yyyyMMddHHmm" ; else if ( dateString . length ( ) == 14 ) pattern = "yyyyMMddHHmmss" ; else if ( dateString . length ( ) == 17 ) pattern = "yyyyMMddHHmmssSSS" ; else throw new ParseException ( "Input is not valid date string: " + dateString , 0 ) ; SimpleDateFormat sdf = new SimpleDateFormat ( pattern ) ; sdf . setTimeZone ( GMT ) ; Date date = sdf . parse ( dateString ) ; return date ; } public static Date round ( Date date , Resolution resolution ) { return new Date ( round ( date . getTime ( ) , resolution ) ) ; } public static long round ( long time , Resolution resolution ) { Calendar cal = Calendar . getInstance ( GMT ) ; cal . setTime ( new Date ( time ) ) ; if ( resolution == Resolution . YEAR ) { cal . set ( Calendar . MONTH , 0 ) ; cal . set ( Calendar . DAY_OF_MONTH , 1 ) ; cal . set ( Calendar . HOUR_OF_DAY , 0 ) ; cal . set ( Calendar . MINUTE , 0 ) ; cal . set ( Calendar . SECOND , 0 ) ; cal . set ( Calendar . MILLISECOND , 0 ) ; } else if ( resolution == Resolution . MONTH ) { cal . set ( Calendar . DAY_OF_MONTH , 1 ) ; cal . set ( Calendar . HOUR_OF_DAY , 0 ) ; cal . set ( Calendar . MINUTE , 0 ) ; cal . set ( Calendar . SECOND , 0 ) ; cal . set ( Calendar . MILLISECOND , 0 ) ; } else if ( resolution == Resolution . DAY ) { cal . set ( Calendar . HOUR_OF_DAY , 0 ) ; cal . set ( Calendar . MINUTE , 0 ) ; cal . set ( Calendar . SECOND , 0 ) ; cal . set ( Calendar . MILLISECOND , 0 ) ; } else if ( resolution == Resolution . HOUR ) { cal . set ( Calendar . MINUTE , 0 ) ; cal . set ( Calendar . SECOND , 0 ) ; cal . set ( Calendar . MILLISECOND , 0 ) ; } else if ( resolution == Resolution . MINUTE ) { cal . set ( Calendar . SECOND , 0 ) ; cal . set ( Calendar . MILLISECOND , 0 ) ; } else if ( resolution == Resolution . SECOND ) { cal . set ( Calendar . MILLISECOND , 0 ) ; } else if ( resolution == Resolution . MILLISECOND ) { } else { throw new IllegalArgumentException ( "unknown resolution " + resolution ) ; } return cal . getTime ( ) . getTime ( ) ; } public static class Resolution { public static final Resolution YEAR = new Resolution ( "year" ) ; public static final Resolution MONTH = new Resolution ( "month" ) ; public static final Resolution DAY = new Resolution ( "day" ) ; public static final Resolution HOUR = new Resolution ( "hour" ) ; public static final Resolution MINUTE = new Resolution ( "minute" ) ; public static final Resolution SECOND = new Resolution ( "second" ) ; public static final Resolution MILLISECOND = new Resolution ( "millisecond" ) ; private String resolution ; private Resolution ( ) { } private Resolution ( String resolution ) { this . resolution = resolution ; } public String toString ( ) { return resolution ; } } } 	0	['8', '1', '0', '1', '29', '16', '0', '1', '6', '0.142857143', '330', '1', '0', '0', '0.314285714', '0', '0', '40.125', '8', '2.5', '0']
package org . apache . lucene . search ; public interface ScoreDocComparator { static final ScoreDocComparator RELEVANCE = new ScoreDocComparator ( ) { public int compare ( ScoreDoc i , ScoreDoc j ) { if ( i . score > j . score ) return - 1 ; if ( i . score < j . score ) return 1 ; return 0 ; } public Comparable sortValue ( ScoreDoc i ) { return new Float ( i . score ) ; } public int sortType ( ) { return SortField . SCORE ; } } ; static final ScoreDocComparator INDEXORDER = new ScoreDocComparator ( ) { public int compare ( ScoreDoc i , ScoreDoc j ) { if ( i . doc < j . doc ) return - 1 ; if ( i . doc > j . doc ) return 1 ; return 0 ; } public Comparable sortValue ( ScoreDoc i ) { return new Integer ( i . doc ) ; } public int sortType ( ) { return SortField . DOC ; } } ; int compare ( ScoreDoc i , ScoreDoc j ) ; Comparable sortValue ( ScoreDoc i ) ; int sortType ( ) ; } 	0	['4', '1', '0', '11', '6', '6', '10', '3', '3', '1', '15', '0', '2', '0', '0.833333333', '0', '0', '2.25', '1', '0.75', '0']
package org . apache . lucene . index ; import java . util . * ; class SegmentTermVector implements TermFreqVector { private String field ; private String terms [ ] ; private int termFreqs [ ] ; SegmentTermVector ( String field , String terms [ ] , int termFreqs [ ] ) { this . field = field ; this . terms = terms ; this . termFreqs = termFreqs ; } public String getField ( ) { return field ; } public String toString ( ) { StringBuffer sb = new StringBuffer ( ) ; sb . append ( '{' ) ; sb . append ( field ) . append ( ": " ) ; if ( terms != null ) { for ( int i = 0 ; i < terms . length ; i ++ ) { if ( i > 0 ) sb . append ( ", " ) ; sb . append ( terms [ i ] ) . append ( '/' ) . append ( termFreqs [ i ] ) ; } } sb . append ( '}' ) ; return sb . toString ( ) ; } public int size ( ) { return terms == null ? 0 : terms . length ; } public String [ ] getTerms ( ) { return terms ; } public int [ ] getTermFrequencies ( ) { return termFreqs ; } public int indexOf ( String termText ) { if ( terms == null ) return - 1 ; int res = Arrays . binarySearch ( terms , termText ) ; return res >= 0 ? res : - 1 ; } public int [ ] indexesOf ( String [ ] termNumbers , int start , int len ) { int res [ ] = new int [ len ] ; for ( int i = 0 ; i < len ; i ++ ) { res [ i ] = indexOf ( termNumbers [ start + i ] ) ; } return res ; } } 	0	['8', '1', '1', '3', '15', '0', '2', '1', '7', '0.571428571', '133', '1', '0', '0', '0.35', '0', '0', '15.25', '4', '1.75', '0']
package org . apache . lucene . document ; import org . apache . lucene . search . PrefixQuery ; import org . apache . lucene . search . RangeQuery ; import java . util . Date ; public class DateField { private DateField ( ) { } private static int DATE_LEN = Long . toString ( 1000L * 365 * 24 * 60 * 60 * 1000 , Character . MAX_RADIX ) . length ( ) ; public static String MIN_DATE_STRING ( ) { return timeToString ( 0 ) ; } public static String MAX_DATE_STRING ( ) { char [ ] buffer = new char [ DATE_LEN ] ; char c = Character . forDigit ( Character . MAX_RADIX - 1 , Character . MAX_RADIX ) ; for ( int i = 0 ; i < DATE_LEN ; i ++ ) buffer [ i ] = c ; return new String ( buffer ) ; } public static String dateToString ( Date date ) { return timeToString ( date . getTime ( ) ) ; } public static String timeToString ( long time ) { if ( time < 0 ) throw new RuntimeException ( "time '" + time + "' is too early, must be >= 0" ) ; String s = Long . toString ( time , Character . MAX_RADIX ) ; if ( s . length ( ) > DATE_LEN ) throw new RuntimeException ( "time '" + time + "' is too late, length of string " + "representation must be <= " + DATE_LEN ) ; if ( s . length ( ) < DATE_LEN ) { StringBuffer sb = new StringBuffer ( s ) ; while ( sb . length ( ) < DATE_LEN ) sb . insert ( 0 , 0 ) ; s = sb . toString ( ) ; } return s ; } public static long stringToTime ( String s ) { return Long . parseLong ( s , Character . MAX_RADIX ) ; } public static Date stringToDate ( String s ) { return new Date ( stringToTime ( s ) ) ; } } 	0	['8', '1', '0', '1', '25', '22', '1', '0', '6', '0.428571429', '126', '1', '0', '0', '0.178571429', '0', '0', '14.625', '5', '1.375', '0']
package org . apache . lucene . search ; public class FieldDoc extends ScoreDoc { public Comparable [ ] fields ; public FieldDoc ( int doc , float score ) { super ( doc , score ) ; } public FieldDoc ( int doc , float score , Comparable [ ] fields ) { super ( doc , score ) ; this . fields = fields ; } } 	0	['2', '2', '0', '4', '3', '1', '3', '1', '2', '1', '16', '0', '0', '0', '0.875', '0', '0', '6.5', '0', '0', '0']
package org . apache . lucene . queryParser ; public class TokenMgrError extends Error { static final int LEXICAL_ERROR = 0 ; static final int STATIC_LEXER_ERROR = 1 ; static final int INVALID_LEXICAL_STATE = 2 ; static final int LOOP_DETECTED = 3 ; int errorCode ; protected static final String addEscapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( "\\b" ) ; continue ; case '\t' : retval . append ( "\\t" ) ; continue ; case '\n' : retval . append ( "\\n" ) ; continue ; case '\f' : retval . append ( "\\f" ) ; continue ; case '\r' : retval . append ( "\\r" ) ; continue ; case '\"' : retval . append ( "\\\"" ) ; continue ; case '\'' : retval . append ( "\\\'" ) ; continue ; case '\\' : retval . append ( "\\\\" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = "0000" + Integer . toString ( ch , 16 ) ; retval . append ( "\\u" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; } protected static String LexicalError ( boolean EOFSeen , int lexState , int errorLine , int errorColumn , String errorAfter , char curChar ) { return ( "Lexical error at line " + errorLine + ", column " + errorColumn + ".  Encountered: " + ( EOFSeen ? "<EOF> " : ( "\"" + addEscapes ( String . valueOf ( curChar ) ) + "\"" ) + " (" + ( int ) curChar + "), " ) + "after : \"" + addEscapes ( errorAfter ) + "\"" ) ; } public String getMessage ( ) { return super . getMessage ( ) ; } public TokenMgrError ( ) { } public TokenMgrError ( String message , int reason ) { super ( message ) ; errorCode = reason ; } public TokenMgrError ( boolean EOFSeen , int lexState , int errorLine , int errorColumn , String errorAfter , char curChar , int reason ) { this ( LexicalError ( EOFSeen , lexState , errorLine , errorColumn , errorAfter , curChar ) , reason ) ; } } 	0	['6', '3', '0', '2', '19', '15', '2', '0', '4', '1.12', '184', '0', '0', '0.8125', '0.5', '1', '1', '28.83333333', '14', '2.8333', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import java . io . IOException ; import java . io . Serializable ; public interface SortComparatorSource extends Serializable { ScoreDocComparator newComparator ( IndexReader reader , String fieldname ) throws IOException ; } 	0	['1', '1', '0', '5', '1', '0', '3', '2', '1', '2', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search ; import java . io . IOException ; public class ReqOptSumScorer extends Scorer { private Scorer reqScorer ; private Scorer optScorer ; public ReqOptSumScorer ( Scorer reqScorer , Scorer optScorer ) { super ( null ) ; this . reqScorer = reqScorer ; this . optScorer = optScorer ; } private boolean firstTimeOptScorer = true ; public boolean next ( ) throws IOException { return reqScorer . next ( ) ; } public boolean skipTo ( int target ) throws IOException { return reqScorer . skipTo ( target ) ; } public int doc ( ) { return reqScorer . doc ( ) ; } public float score ( ) throws IOException { int curDoc = reqScorer . doc ( ) ; float reqScore = reqScorer . score ( ) ; if ( firstTimeOptScorer ) { firstTimeOptScorer = false ; if ( ! optScorer . skipTo ( curDoc ) ) { optScorer = null ; return reqScore ; } } else if ( optScorer == null ) { return reqScore ; } else if ( ( optScorer . doc ( ) < curDoc ) && ( ! optScorer . skipTo ( curDoc ) ) ) { optScorer = null ; return reqScore ; } return ( optScorer . doc ( ) == curDoc ) ? reqScore + optScorer . score ( ) : reqScore ; } public Explanation explain ( int doc ) throws IOException { Explanation res = new Explanation ( ) ; res . setDescription ( "required, optional" ) ; res . addDetail ( reqScorer . explain ( doc ) ) ; res . addDetail ( optScorer . explain ( doc ) ) ; return res ; } } 	0	['6', '2', '0', '4', '15', '0', '1', '3', '6', '0.466666667', '113', '1', '2', '0.615384615', '0.5', '1', '3', '17.33333333', '1', '0.8333', '0']
package org . apache . lucene . document ; public class NumberTools { private static final int RADIX = 36 ; private static final char NEGATIVE_PREFIX = '-' ; private static final char POSITIVE_PREFIX = '0' ; public static final String MIN_STRING_VALUE = NEGATIVE_PREFIX + "0000000000000" ; public static final String MAX_STRING_VALUE = POSITIVE_PREFIX + "1y2p0ij32e8e7" ; public static final int STR_SIZE = MIN_STRING_VALUE . length ( ) ; public static String longToString ( long l ) { if ( l == Long . MIN_VALUE ) { return MIN_STRING_VALUE ; } StringBuffer buf = new StringBuffer ( STR_SIZE ) ; if ( l < 0 ) { buf . append ( NEGATIVE_PREFIX ) ; l = Long . MAX_VALUE + l + 1 ; } else { buf . append ( POSITIVE_PREFIX ) ; } String num = Long . toString ( l , RADIX ) ; int padLen = STR_SIZE - num . length ( ) - buf . length ( ) ; while ( padLen -- > 0 ) { buf . append ( '0' ) ; } buf . append ( num ) ; return buf . toString ( ) ; } public static long stringToLong ( String str ) { if ( str == null ) { throw new NullPointerException ( "string cannot be null" ) ; } if ( str . length ( ) != STR_SIZE ) { throw new NumberFormatException ( "string is the wrong size" ) ; } if ( str . equals ( MIN_STRING_VALUE ) ) { return Long . MIN_VALUE ; } char prefix = str . charAt ( 0 ) ; long l = Long . parseLong ( str . substring ( 1 ) , RADIX ) ; if ( prefix == POSITIVE_PREFIX ) { } else if ( prefix == NEGATIVE_PREFIX ) { l = l - Long . MAX_VALUE - 1 ; } else { throw new NumberFormatException ( "string does not begin with the correct prefix" ) ; } return l ; } } 	0	['4', '1', '0', '0', '18', '0', '0', '0', '3', '1.166666667', '130', '0.5', '0', '0', '0.333333333', '0', '0', '30', '6', '2.5', '0']
package org . apache . lucene . search ; public class SimilarityDelegator extends Similarity { private Similarity delegee ; public SimilarityDelegator ( Similarity delegee ) { this . delegee = delegee ; } public float lengthNorm ( String fieldName , int numTerms ) { return delegee . lengthNorm ( fieldName , numTerms ) ; } public float queryNorm ( float sumOfSquaredWeights ) { return delegee . queryNorm ( sumOfSquaredWeights ) ; } public float tf ( float freq ) { return delegee . tf ( freq ) ; } public float sloppyFreq ( int distance ) { return delegee . sloppyFreq ( distance ) ; } public float idf ( int docFreq , int numDocs ) { return delegee . idf ( docFreq , numDocs ) ; } public float coord ( int overlap , int maxOverlap ) { return delegee . coord ( overlap , maxOverlap ) ; } } 	0	['7', '2', '1', '2', '14', '0', '1', '1', '7', '0', '47', '1', '1', '0.7', '0.428571429', '1', '2', '5.571428571', '1', '0.8571', '0']
package org . apache . lucene . analysis . standard ; public class Token { public int kind ; public int beginLine , beginColumn , endLine , endColumn ; public String image ; public Token next ; public Token specialToken ; public String toString ( ) { return image ; } public static final Token newToken ( int ofKind ) { switch ( ofKind ) { default : return new Token ( ) ; } } } 	0	['3', '1', '0', '3', '4', '3', '3', '0', '3', '1.4375', '23', '0', '2', '0', '0.5', '0', '0', '4', '2', '1', '0']
package org . apache . lucene . index ; public interface TermPositionVector extends TermFreqVector { public int [ ] getTermPositions ( int index ) ; public TermVectorOffsetInfo [ ] getOffsets ( int index ) ; } 	0	['2', '1', '0', '4', '2', '1', '2', '2', '2', '2', '2', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; import java . util . HashSet ; import java . util . Set ; public final class StopFilter extends TokenFilter { private final Set stopWords ; private final boolean ignoreCase ; public StopFilter ( TokenStream input , String [ ] stopWords ) { this ( input , stopWords , false ) ; } public StopFilter ( TokenStream in , String [ ] stopWords , boolean ignoreCase ) { super ( in ) ; this . ignoreCase = ignoreCase ; this . stopWords = makeStopSet ( stopWords , ignoreCase ) ; } public StopFilter ( TokenStream input , Set stopWords , boolean ignoreCase ) { super ( input ) ; this . ignoreCase = ignoreCase ; this . stopWords = stopWords ; } public StopFilter ( TokenStream in , Set stopWords ) { this ( in , stopWords , false ) ; } public static final Set makeStopSet ( String [ ] stopWords ) { return makeStopSet ( stopWords , false ) ; } public static final Set makeStopSet ( String [ ] stopWords , boolean ignoreCase ) { HashSet stopTable = new HashSet ( stopWords . length ) ; for ( int i = 0 ; i < stopWords . length ; i ++ ) stopTable . add ( ignoreCase ? stopWords [ i ] . toLowerCase ( ) : stopWords [ i ] ) ; return stopTable ; } public final Token next ( ) throws IOException { for ( Token token = input . next ( ) ; token != null ; token = input . next ( ) ) { String termText = ignoreCase ? token . termText . toLowerCase ( ) : token . termText ; if ( ! stopWords . contains ( termText ) ) return token ; } return null ; } } 	0	['7', '3', '0', '5', '13', '15', '2', '3', '7', '0.333333333', '106', '1', '0', '0.5', '0.514285714', '0', '0', '13.85714286', '3', '0.7143', '0']
package org . apache . lucene . analysis . standard ; import org . apache . lucene . analysis . * ; import java . io . File ; import java . io . IOException ; import java . io . Reader ; import java . util . Set ; public class StandardAnalyzer extends Analyzer { private Set stopSet ; public static final String [ ] STOP_WORDS = StopAnalyzer . ENGLISH_STOP_WORDS ; public StandardAnalyzer ( ) { this ( STOP_WORDS ) ; } public StandardAnalyzer ( Set stopWords ) { stopSet = stopWords ; } public StandardAnalyzer ( String [ ] stopWords ) { stopSet = StopFilter . makeStopSet ( stopWords ) ; } public StandardAnalyzer ( File stopwords ) throws IOException { stopSet = WordlistLoader . getWordSet ( stopwords ) ; } public StandardAnalyzer ( Reader stopwords ) throws IOException { stopSet = WordlistLoader . getWordSet ( stopwords ) ; } public TokenStream tokenStream ( String fieldName , Reader reader ) { TokenStream result = new StandardTokenizer ( reader ) ; result = new StandardFilter ( result ) ; result = new LowerCaseFilter ( result ) ; result = new StopFilter ( result , stopSet ) ; return result ; } } 	0	['7', '2', '0', '8', '15', '0', '0', '8', '6', '0.5', '67', '0.5', '0', '0.666666667', '0.333333333', '0', '0', '8.285714286', '1', '0.1429', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; public interface Spans { boolean next ( ) throws IOException ; boolean skipTo ( int target ) throws IOException ; int doc ( ) ; int start ( ) ; int end ( ) ; } 	0	['5', '1', '0', '15', '5', '10', '15', '0', '5', '2', '5', '0', '0', '0', '0.6', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search ; import java . util . Iterator ; import java . util . NoSuchElementException ; public class HitIterator implements Iterator { private Hits hits ; private int hitNumber = 0 ; HitIterator ( Hits hits ) { this . hits = hits ; } public boolean hasNext ( ) { return hitNumber < hits . length ( ) ; } public Object next ( ) { if ( hitNumber == hits . length ( ) ) throw new NoSuchElementException ( ) ; Object next = new Hit ( hits , hitNumber ) ; hitNumber ++ ; return next ; } public void remove ( ) { throw new UnsupportedOperationException ( ) ; } public int length ( ) { return hits . length ( ) ; } } 	0	['5', '1', '0', '2', '10', '0', '1', '2', '4', '0.375', '60', '1', '1', '0', '0.6', '0', '0', '10.6', '2', '1.2', '0']
package org . apache . lucene . util ; public final class Constants { private Constants ( ) { } public static final String JAVA_VERSION = System . getProperty ( "java.version" ) ; public static final boolean JAVA_1_1 = JAVA_VERSION . startsWith ( "1.1." ) ; public static final boolean JAVA_1_2 = JAVA_VERSION . startsWith ( "1.2." ) ; public static final boolean JAVA_1_3 = JAVA_VERSION . startsWith ( "1.3." ) ; public static final String OS_NAME = System . getProperty ( "os.name" ) ; public static final boolean LINUX = OS_NAME . startsWith ( "Linux" ) ; public static final boolean WINDOWS = OS_NAME . startsWith ( "Windows" ) ; public static final boolean SUN_OS = OS_NAME . startsWith ( "SunOS" ) ; } 	0	['2', '1', '0', '0', '5', '1', '0', '0', '0', '1', '44', '0', '0', '0', '1', '0', '0', '17', '0', '0', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import org . apache . lucene . util . ToStringUtils ; public abstract class MultiTermQuery extends Query { private Term term ; public MultiTermQuery ( Term term ) { this . term = term ; } public Term getTerm ( ) { return term ; } protected abstract FilteredTermEnum getEnum ( IndexReader reader ) throws IOException ; public Query rewrite ( IndexReader reader ) throws IOException { FilteredTermEnum enumerator = getEnum ( reader ) ; BooleanQuery query = new BooleanQuery ( true ) ; try { do { Term t = enumerator . term ( ) ; if ( t != null ) { TermQuery tq = new TermQuery ( t ) ; tq . setBoost ( getBoost ( ) * enumerator . difference ( ) ) ; query . add ( tq , BooleanClause . Occur . SHOULD ) ; } } while ( enumerator . next ( ) ) ; } finally { enumerator . close ( ) ; } return query ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! term . field ( ) . equals ( field ) ) { buffer . append ( term . field ( ) ) ; buffer . append ( ":" ) ; } buffer . append ( term . text ( ) ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof MultiTermQuery ) ) return false ; final MultiTermQuery multiTermQuery = ( MultiTermQuery ) o ; if ( ! term . equals ( multiTermQuery . term ) ) return false ; return getBoost ( ) == multiTermQuery . getBoost ( ) ; } public int hashCode ( ) { return term . hashCode ( ) + Float . floatToRawIntBits ( getBoost ( ) ) ; } } 	0	['7', '2', '2', '10', '27', '1', '2', '8', '6', '0.333333333', '134', '1', '1', '0.666666667', '0.342857143', '2', '3', '18', '5', '1.5714', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . Term ; import org . apache . lucene . util . PriorityQueue ; public class ParallelMultiSearcher extends MultiSearcher { private Searchable [ ] searchables ; private int [ ] starts ; public ParallelMultiSearcher ( Searchable [ ] searchables ) throws IOException { super ( searchables ) ; this . searchables = searchables ; this . starts = getStarts ( ) ; } public int docFreq ( Term term ) throws IOException { return super . docFreq ( term ) ; } public TopDocs search ( Weight weight , Filter filter , int nDocs ) throws IOException { HitQueue hq = new HitQueue ( nDocs ) ; int totalHits = 0 ; MultiSearcherThread [ ] msta = new MultiSearcherThread [ searchables . length ] ; for ( int i = 0 ; i < searchables . length ; i ++ ) { msta [ i ] = new MultiSearcherThread ( searchables [ i ] , weight , filter , nDocs , hq , i , starts , "MultiSearcher thread #" + ( i + 1 ) ) ; msta [ i ] . start ( ) ; } for ( int i = 0 ; i < searchables . length ; i ++ ) { try { msta [ i ] . join ( ) ; } catch ( InterruptedException ie ) { ; } IOException ioe = msta [ i ] . getIOException ( ) ; if ( ioe == null ) { totalHits += msta [ i ] . hits ( ) ; } else { throw ioe ; } } ScoreDoc [ ] scoreDocs = new ScoreDoc [ hq . size ( ) ] ; for ( int i = hq . size ( ) - 1 ; i >= 0 ; i -- ) scoreDocs [ i ] = ( ScoreDoc ) hq . pop ( ) ; float maxScore = ( totalHits == 0 ) ? Float . NEGATIVE_INFINITY : scoreDocs [ 0 ] . score ; return new TopDocs ( totalHits , scoreDocs , maxScore ) ; } public TopFieldDocs search ( Weight weight , Filter filter , int nDocs , Sort sort ) throws IOException { FieldDocSortedHitQueue hq = new FieldDocSortedHitQueue ( null , nDocs ) ; int totalHits = 0 ; MultiSearcherThread [ ] msta = new MultiSearcherThread [ searchables . length ] ; for ( int i = 0 ; i < searchables . length ; i ++ ) { msta [ i ] = new MultiSearcherThread ( searchables [ i ] , weight , filter , nDocs , hq , sort , i , starts , "MultiSearcher thread #" + ( i + 1 ) ) ; msta [ i ] . start ( ) ; } float maxScore = Float . NEGATIVE_INFINITY ; for ( int i = 0 ; i < searchables . length ; i ++ ) { try { msta [ i ] . join ( ) ; } catch ( InterruptedException ie ) { ; } IOException ioe = msta [ i ] . getIOException ( ) ; if ( ioe == null ) { totalHits += msta [ i ] . hits ( ) ; maxScore = Math . max ( maxScore , msta [ i ] . getMaxScore ( ) ) ; } else { throw ioe ; } } ScoreDoc [ ] scoreDocs = new ScoreDoc [ hq . size ( ) ] ; for ( int i = hq . size ( ) - 1 ; i >= 0 ; i -- ) scoreDocs [ i ] = ( ScoreDoc ) hq . pop ( ) ; return new TopFieldDocs ( totalHits , scoreDocs , hq . getFields ( ) , maxScore ) ; } public void search ( Weight weight , Filter filter , final HitCollector results ) throws IOException { for ( int i = 0 ; i < searchables . length ; i ++ ) { final int start = starts [ i ] ; searchables [ i ] . search ( weight , filter , new HitCollector ( ) { public void collect ( int doc , float score ) { results . collect ( doc + start , score ) ; } } ) ; } } public Query rewrite ( Query original ) throws IOException { return super . rewrite ( original ) ; } } class MultiSearcherThread extends Thread { private Searchable searchable ; private Weight weight ; private Filter filter ; private int nDocs ; private TopDocs docs ; private int i ; private PriorityQueue hq ; private int [ ] starts ; private IOException ioe ; private Sort sort ; public MultiSearcherThread ( Searchable searchable , Weight weight , Filter filter , int nDocs , HitQueue hq , int i , int [ ] starts , String name ) { super ( name ) ; this . searchable = searchable ; this . weight = weight ; this . filter = filter ; this . nDocs = nDocs ; this . hq = hq ; this . i = i ; this . starts = starts ; } public MultiSearcherThread ( Searchable searchable , Weight weight , Filter filter , int nDocs , FieldDocSortedHitQueue hq , Sort sort , int i , int [ ] starts , String name ) { super ( name ) ; this . searchable = searchable ; this . weight = weight ; this . filter = filter ; this . nDocs = nDocs ; this . hq = hq ; this . i = i ; this . starts = starts ; this . sort = sort ; } public void run ( ) { try { docs = ( sort == null ) ? searchable . search ( weight , filter , nDocs ) : searchable . search ( weight , filter , nDocs , sort ) ; } catch ( IOException ioe ) { this . ioe = ioe ; } if ( ioe == null ) { if ( sort != null ) { ( ( FieldDocSortedHitQueue ) hq ) . setFields ( ( ( TopFieldDocs ) docs ) . fields ) ; } ScoreDoc [ ] scoreDocs = docs . scoreDocs ; for ( int j = 0 ; j < scoreDocs . length ; j ++ ) { ScoreDoc scoreDoc = scoreDocs [ j ] ; scoreDoc . doc += starts [ i ] ; synchronized ( hq ) { if ( ! hq . insert ( scoreDoc ) ) break ; } } } } public int hits ( ) { return docs . totalHits ; } public float getMaxScore ( ) { return docs . getMaxScore ( ) ; } public IOException getIOException ( ) { return ioe ; } } 	0	['6', '3', '0', '16', '33', '3', '1', '16', '6', '0.4', '297', '1', '1', '0.87804878', '0.351851852', '2', '3', '48.16666667', '1', '0.8333', '0']
package org . apache . lucene . util ; public class SmallFloat { public static byte floatToByte ( float f , int numMantissaBits , int zeroExp ) { int fzero = ( 63 - zeroExp ) << numMantissaBits ; int bits = Float . floatToRawIntBits ( f ) ; int smallfloat = bits > > ( 24 - numMantissaBits ) ; if ( smallfloat < fzero ) { return ( bits <= 0 ) ? ( byte ) 0 : ( byte ) 1 ; } else if ( smallfloat >= fzero + 0x100 ) { return - 1 ; } else { return ( byte ) ( smallfloat - fzero ) ; } } public static float byteToFloat ( byte b , int numMantissaBits , int zeroExp ) { if ( b == 0 ) return 0.0f ; int bits = ( b & 0xff ) << ( 24 - numMantissaBits ) ; bits += ( 63 - zeroExp ) << 24 ; return Float . intBitsToFloat ( bits ) ; } public static byte floatToByte315 ( float f ) { int bits = Float . floatToRawIntBits ( f ) ; int smallfloat = bits > > ( 24 - 3 ) ; if ( smallfloat < ( 63 - 15 ) << 3 ) { return ( bits <= 0 ) ? ( byte ) 0 : ( byte ) 1 ; } if ( smallfloat >= ( ( 63 - 15 ) << 3 ) + 0x100 ) { return - 1 ; } return ( byte ) ( smallfloat - ( ( 63 - 15 ) << 3 ) ) ; } public static float byte315ToFloat ( byte b ) { if ( b == 0 ) return 0.0f ; int bits = ( b & 0xff ) << ( 24 - 3 ) ; bits += ( 63 - 15 ) << 24 ; return Float . intBitsToFloat ( bits ) ; } public static byte floatToByte52 ( float f ) { int bits = Float . floatToRawIntBits ( f ) ; int smallfloat = bits > > ( 24 - 5 ) ; if ( smallfloat < ( 63 - 2 ) << 5 ) { return ( bits <= 0 ) ? ( byte ) 0 : ( byte ) 1 ; } if ( smallfloat >= ( ( 63 - 2 ) << 5 ) + 0x100 ) { return - 1 ; } return ( byte ) ( smallfloat - ( ( 63 - 2 ) << 5 ) ) ; } public static float byte52ToFloat ( byte b ) { if ( b == 0 ) return 0.0f ; int bits = ( b & 0xff ) << ( 24 - 5 ) ; bits += ( 63 - 2 ) << 24 ; return Float . intBitsToFloat ( bits ) ; } } 	0	['7', '1', '0', '1', '10', '21', '1', '0', '7', '2', '155', '0', '0', '0', '0.321428571', '0', '0', '21.14285714', '4', '2.5714', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; import java . io . Reader ; public class KeywordTokenizer extends Tokenizer { private static final int DEFAULT_BUFFER_SIZE = 256 ; private boolean done ; private final char [ ] buffer ; public KeywordTokenizer ( Reader input ) { this ( input , DEFAULT_BUFFER_SIZE ) ; } public KeywordTokenizer ( Reader input , int bufferSize ) { super ( input ) ; this . buffer = new char [ bufferSize ] ; this . done = false ; } public Token next ( ) throws IOException { if ( ! done ) { done = true ; StringBuffer buffer = new StringBuffer ( ) ; int length ; while ( true ) { length = input . read ( this . buffer ) ; if ( length == - 1 ) break ; buffer . append ( this . buffer , 0 , length ) ; } String text = buffer . toString ( ) ; return new Token ( text , 0 , text . length ( ) ) ; } return null ; } } 	0	['3', '3', '0', '3', '10', '1', '1', '2', '3', '0.5', '63', '1', '0', '0.75', '0.666666667', '0', '0', '19', '1', '0.3333', '0']
package org . apache . lucene . index ; public interface TermFreqVector { public String getField ( ) ; public int size ( ) ; public String [ ] getTerms ( ) ; public int [ ] getTermFrequencies ( ) ; public int indexOf ( String term ) ; public int [ ] indexesOf ( String [ ] terms , int start , int len ) ; } 	0	['6', '1', '0', '11', '6', '15', '11', '0', '6', '2', '6', '0', '0', '0', '0.375', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search ; import org . apache . lucene . util . PriorityQueue ; public class TopDocCollector extends HitCollector { private int numHits ; private float minScore = 0.0f ; int totalHits ; PriorityQueue hq ; public TopDocCollector ( int numHits ) { this ( numHits , new HitQueue ( numHits ) ) ; } TopDocCollector ( int numHits , PriorityQueue hq ) { this . numHits = numHits ; this . hq = hq ; } public void collect ( int doc , float score ) { if ( score > 0.0f ) { totalHits ++ ; if ( hq . size ( ) < numHits || score >= minScore ) { hq . insert ( new ScoreDoc ( doc , score ) ) ; minScore = ( ( ScoreDoc ) hq . top ( ) ) . score ; } } } public int getTotalHits ( ) { return totalHits ; } public TopDocs topDocs ( ) { ScoreDoc [ ] scoreDocs = new ScoreDoc [ hq . size ( ) ] ; for ( int i = hq . size ( ) - 1 ; i >= 0 ; i -- ) scoreDocs [ i ] = ( ScoreDoc ) hq . pop ( ) ; float maxScore = ( totalHits == 0 ) ? Float . NEGATIVE_INFINITY : scoreDocs [ 0 ] . score ; return new TopDocs ( totalHits , scoreDocs , maxScore ) ; } } 	0	['5', '2', '1', '7', '13', '0', '2', '5', '4', '0.4375', '110', '0.5', '1', '0.25', '0.5', '0', '0', '20.2', '4', '1.6', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public class LetterTokenizer extends CharTokenizer { public LetterTokenizer ( Reader in ) { super ( in ) ; } protected boolean isTokenChar ( char c ) { return Character . isLetter ( c ) ; } } 	0	['2', '4', '1', '2', '4', '1', '1', '1', '1', '2', '9', '0', '0', '0.857142857', '0.666666667', '1', '1', '3.5', '1', '0.5', '0']
package org . apache . lucene . analysis . standard ; public class TokenMgrError extends Error { static final int LEXICAL_ERROR = 0 ; static final int STATIC_LEXER_ERROR = 1 ; static final int INVALID_LEXICAL_STATE = 2 ; static final int LOOP_DETECTED = 3 ; int errorCode ; protected static final String addEscapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( "\\b" ) ; continue ; case '\t' : retval . append ( "\\t" ) ; continue ; case '\n' : retval . append ( "\\n" ) ; continue ; case '\f' : retval . append ( "\\f" ) ; continue ; case '\r' : retval . append ( "\\r" ) ; continue ; case '\"' : retval . append ( "\\\"" ) ; continue ; case '\'' : retval . append ( "\\\'" ) ; continue ; case '\\' : retval . append ( "\\\\" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = "0000" + Integer . toString ( ch , 16 ) ; retval . append ( "\\u" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; } protected static String LexicalError ( boolean EOFSeen , int lexState , int errorLine , int errorColumn , String errorAfter , char curChar ) { return ( "Lexical error at line " + errorLine + ", column " + errorColumn + ".  Encountered: " + ( EOFSeen ? "<EOF> " : ( "\"" + addEscapes ( String . valueOf ( curChar ) ) + "\"" ) + " (" + ( int ) curChar + "), " ) + "after : \"" + addEscapes ( errorAfter ) + "\"" ) ; } public String getMessage ( ) { return super . getMessage ( ) ; } public TokenMgrError ( ) { } public TokenMgrError ( String message , int reason ) { super ( message ) ; errorCode = reason ; } public TokenMgrError ( boolean EOFSeen , int lexState , int errorLine , int errorColumn , String errorAfter , char curChar , int reason ) { this ( LexicalError ( EOFSeen , lexState , errorLine , errorColumn , errorAfter , curChar ) , reason ) ; } } 	0	['6', '3', '0', '1', '19', '15', '1', '0', '4', '1.12', '184', '0', '0', '0.8125', '0.5', '1', '1', '28.83333333', '14', '2.8333', '0']
package org . apache . lucene . search ; import java . util . BitSet ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; public abstract class Filter implements java . io . Serializable { public abstract BitSet bits ( IndexReader reader ) throws IOException ; } 	0	['2', '1', '3', '20', '3', '1', '19', '1', '2', '2', '5', '0', '0', '0', '0.75', '0', '0', '1.5', '1', '0.5', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import java . io . IOException ; public interface FieldCache { public static final int STRING_INDEX = - 1 ; public static class StringIndex { public final String [ ] lookup ; public final int [ ] order ; public StringIndex ( int [ ] values , String [ ] lookup ) { this . order = values ; this . lookup = lookup ; } } public interface IntParser { public int parseInt ( String string ) ; } public interface FloatParser { public float parseFloat ( String string ) ; } public static FieldCache DEFAULT = new FieldCacheImpl ( ) ; public int [ ] getInts ( IndexReader reader , String field ) throws IOException ; public int [ ] getInts ( IndexReader reader , String field , IntParser parser ) throws IOException ; public float [ ] getFloats ( IndexReader reader , String field ) throws IOException ; public float [ ] getFloats ( IndexReader reader , String field , FloatParser parser ) throws IOException ; public String [ ] getStrings ( IndexReader reader , String field ) throws IOException ; public StringIndex getStringIndex ( IndexReader reader , String field ) throws IOException ; public Object getAuto ( IndexReader reader , String field ) throws IOException ; public Comparable [ ] getCustom ( IndexReader reader , String field , SortComparator comparator ) throws IOException ; } 	0	['9', '1', '0', '7', '10', '36', '3', '6', '8', '1.0625', '16', '0', '1', '0', '0.5625', '0', '0', '0.555555556', '1', '0.8889', '0']
package org . apache . lucene . store ; import java . io . IOException ; public abstract class IndexInput implements Cloneable { private char [ ] chars ; public abstract byte readByte ( ) throws IOException ; public abstract void readBytes ( byte [ ] b , int offset , int len ) throws IOException ; public int readInt ( ) throws IOException { return ( ( readByte ( ) & 0xFF ) << 24 ) | ( ( readByte ( ) & 0xFF ) << 16 ) | ( ( readByte ( ) & 0xFF ) << 8 ) | ( readByte ( ) & 0xFF ) ; } public int readVInt ( ) throws IOException { byte b = readByte ( ) ; int i = b & 0x7F ; for ( int shift = 7 ; ( b & 0x80 ) != 0 ; shift += 7 ) { b = readByte ( ) ; i |= ( b & 0x7F ) << shift ; } return i ; } public long readLong ( ) throws IOException { return ( ( ( long ) readInt ( ) ) << 32 ) | ( readInt ( ) & 0xFFFFFFFFL ) ; } public long readVLong ( ) throws IOException { byte b = readByte ( ) ; long i = b & 0x7F ; for ( int shift = 7 ; ( b & 0x80 ) != 0 ; shift += 7 ) { b = readByte ( ) ; i |= ( b & 0x7FL ) << shift ; } return i ; } public String readString ( ) throws IOException { int length = readVInt ( ) ; if ( chars == null || length > chars . length ) chars = new char [ length ] ; readChars ( chars , 0 , length ) ; return new String ( chars , 0 , length ) ; } public void readChars ( char [ ] buffer , int start , int length ) throws IOException { final int end = start + length ; for ( int i = start ; i < end ; i ++ ) { byte b = readByte ( ) ; if ( ( b & 0x80 ) == 0 ) buffer [ i ] = ( char ) ( b & 0x7F ) ; else if ( ( b & 0xE0 ) != 0xE0 ) { buffer [ i ] = ( char ) ( ( ( b & 0x1F ) << 6 ) | ( readByte ( ) & 0x3F ) ) ; } else buffer [ i ] = ( char ) ( ( ( b & 0x0F ) << 12 ) | ( ( readByte ( ) & 0x3F ) << 6 ) | ( readByte ( ) & 0x3F ) ) ; } } public abstract void close ( ) throws IOException ; public abstract long getFilePointer ( ) ; public abstract void seek ( long pos ) throws IOException ; public abstract long length ( ) ; public Object clone ( ) { IndexInput clone = null ; try { clone = ( IndexInput ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { } clone . chars = null ; return clone ; } } 	0	['14', '1', '3', '24', '17', '89', '24', '0', '14', '0.923076923', '224', '1', '0', '0', '0.271428571', '0', '0', '14.92857143', '1', '0.9286', '0']
package org . apache . lucene . analysis . standard ; import java . io . * ; public final class FastCharStream implements CharStream { char [ ] buffer = null ; int bufferLength = 0 ; int bufferPosition = 0 ; int tokenStart = 0 ; int bufferStart = 0 ; Reader input ; public FastCharStream ( Reader r ) { input = r ; } public final char readChar ( ) throws IOException { if ( bufferPosition >= bufferLength ) refill ( ) ; return buffer [ bufferPosition ++ ] ; } private final void refill ( ) throws IOException { int newPosition = bufferLength - tokenStart ; if ( tokenStart == 0 ) { if ( buffer == null ) { buffer = new char [ 2048 ] ; } else if ( bufferLength == buffer . length ) { char [ ] newBuffer = new char [ buffer . length * 2 ] ; System . arraycopy ( buffer , 0 , newBuffer , 0 , bufferLength ) ; buffer = newBuffer ; } } else { System . arraycopy ( buffer , tokenStart , buffer , 0 , newPosition ) ; } bufferLength = newPosition ; bufferPosition = newPosition ; bufferStart += tokenStart ; tokenStart = 0 ; int charsRead = input . read ( buffer , newPosition , buffer . length - newPosition ) ; if ( charsRead == - 1 ) throw new IOException ( "read past eof" ) ; else bufferLength += charsRead ; } public final char BeginToken ( ) throws IOException { tokenStart = bufferPosition ; return readChar ( ) ; } public final void backup ( int amount ) { bufferPosition -= amount ; } public final String GetImage ( ) { return new String ( buffer , tokenStart , bufferPosition - tokenStart ) ; } public final char [ ] GetSuffix ( int len ) { char [ ] value = new char [ len ] ; System . arraycopy ( buffer , bufferPosition - len , value , 0 , len ) ; return value ; } public final void Done ( ) { try { input . close ( ) ; } catch ( IOException e ) { System . err . println ( "Caught: " + e + "; ignoring." ) ; } } public final int getColumn ( ) { return bufferStart + bufferPosition ; } public final int getLine ( ) { return 1 ; } public final int getEndColumn ( ) { return bufferStart + bufferPosition ; } public final int getEndLine ( ) { return 1 ; } public final int getBeginColumn ( ) { return bufferStart + tokenStart ; } public final int getBeginLine ( ) { return 1 ; } } 	0	['14', '1', '0', '2', '25', '3', '1', '1', '13', '0.602564103', '237', '0', '0', '0', '0.404761905', '0', '0', '15.5', '1', '0.9286', '0']
package org . apache . lucene . search ; import java . io . IOException ; public class ReqExclScorer extends Scorer { private Scorer reqScorer , exclScorer ; public ReqExclScorer ( Scorer reqScorer , Scorer exclScorer ) { super ( null ) ; this . reqScorer = reqScorer ; this . exclScorer = exclScorer ; } private boolean firstTime = true ; public boolean next ( ) throws IOException { if ( firstTime ) { if ( ! exclScorer . next ( ) ) { exclScorer = null ; } firstTime = false ; } if ( reqScorer == null ) { return false ; } if ( ! reqScorer . next ( ) ) { reqScorer = null ; return false ; } if ( exclScorer == null ) { return true ; } return toNonExcluded ( ) ; } private boolean toNonExcluded ( ) throws IOException { int exclDoc = exclScorer . doc ( ) ; do { int reqDoc = reqScorer . doc ( ) ; if ( reqDoc < exclDoc ) { return true ; } else if ( reqDoc > exclDoc ) { if ( ! exclScorer . skipTo ( reqDoc ) ) { exclScorer = null ; return true ; } exclDoc = exclScorer . doc ( ) ; if ( exclDoc > reqDoc ) { return true ; } } } while ( reqScorer . next ( ) ) ; reqScorer = null ; return false ; } public int doc ( ) { return reqScorer . doc ( ) ; } public float score ( ) throws IOException { return reqScorer . score ( ) ; } public boolean skipTo ( int target ) throws IOException { if ( firstTime ) { firstTime = false ; if ( ! exclScorer . skipTo ( target ) ) { exclScorer = null ; } } if ( reqScorer == null ) { return false ; } if ( exclScorer == null ) { return reqScorer . skipTo ( target ) ; } if ( ! reqScorer . skipTo ( target ) ) { reqScorer = null ; return false ; } return toNonExcluded ( ) ; } public Explanation explain ( int doc ) throws IOException { Explanation res = new Explanation ( ) ; if ( exclScorer . skipTo ( doc ) && ( exclScorer . doc ( ) == doc ) ) { res . setDescription ( "excluded" ) ; } else { res . setDescription ( "not excluded" ) ; res . addDetail ( reqScorer . explain ( doc ) ) ; } return res ; } } 	0	['7', '2', '0', '4', '16', '0', '1', '3', '6', '0.333333333', '179', '1', '2', '0.571428571', '0.476190476', '1', '3', '24.14285714', '1', '0.8571', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; public final class PorterStemFilter extends TokenFilter { private PorterStemmer stemmer ; public PorterStemFilter ( TokenStream in ) { super ( in ) ; stemmer = new PorterStemmer ( ) ; } public final Token next ( ) throws IOException { Token token = input . next ( ) ; if ( token == null ) return null ; else { String s = stemmer . stem ( token . termText ) ; if ( s != token . termText ) token . termText = s ; return token ; } } } 	0	['2', '3', '0', '4', '6', '0', '0', '4', '2', '0', '35', '1', '1', '0.75', '0.75', '0', '0', '16', '1', '0.5', '0']
package org . apache . lucene . analysis ; import java . io . File ; import java . io . FileReader ; import java . io . IOException ; import java . io . Reader ; import java . io . BufferedReader ; import java . util . HashSet ; import java . util . Hashtable ; import java . util . Iterator ; public class WordlistLoader { public static HashSet getWordSet ( File wordfile ) throws IOException { HashSet result = new HashSet ( ) ; FileReader reader = null ; try { reader = new FileReader ( wordfile ) ; result = getWordSet ( reader ) ; } finally { if ( reader != null ) reader . close ( ) ; } return result ; } public static HashSet getWordSet ( Reader reader ) throws IOException { HashSet result = new HashSet ( ) ; BufferedReader br = null ; try { if ( reader instanceof BufferedReader ) { br = ( BufferedReader ) reader ; } else { br = new BufferedReader ( reader ) ; } String word = null ; while ( ( word = br . readLine ( ) ) != null ) { result . add ( word . trim ( ) ) ; } } finally { if ( br != null ) br . close ( ) ; } return result ; } private static Hashtable makeWordTable ( HashSet wordSet ) { Hashtable table = new Hashtable ( ) ; for ( Iterator iter = wordSet . iterator ( ) ; iter . hasNext ( ) ; ) { String word = ( String ) iter . next ( ) ; table . put ( word , word ) ; } return table ; } } 	0	['4', '1', '0', '2', '18', '6', '2', '0', '3', '2', '102', '0', '0', '0', '0.25', '0', '0', '24.5', '2', '1', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; public final class LowerCaseFilter extends TokenFilter { public LowerCaseFilter ( TokenStream in ) { super ( in ) ; } public final Token next ( ) throws IOException { Token t = input . next ( ) ; if ( t == null ) return null ; t . termText = t . termText . toLowerCase ( ) ; return t ; } } 	0	['2', '3', '0', '4', '5', '1', '1', '3', '2', '2', '21', '0', '0', '0.75', '0.75', '0', '0', '9.5', '1', '0.5', '0']
package org . apache . lucene . queryParser ; public interface CharStream { char readChar ( ) throws java . io . IOException ; int getEndColumn ( ) ; int getEndLine ( ) ; int getBeginColumn ( ) ; int getBeginLine ( ) ; void backup ( int amount ) ; char BeginToken ( ) throws java . io . IOException ; String GetImage ( ) ; char [ ] GetSuffix ( int len ) ; void Done ( ) ; } 	0	['10', '1', '0', '3', '10', '45', '3', '0', '10', '2', '10', '0', '0', '0', '0.6', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import java . io . IOException ; public abstract class SortComparator implements SortComparatorSource { public ScoreDocComparator newComparator ( final IndexReader reader , final String fieldname ) throws IOException { final String field = fieldname . intern ( ) ; final Comparable [ ] cachedValues = FieldCache . DEFAULT . getCustom ( reader , field , SortComparator . this ) ; return new ScoreDocComparator ( ) { public int compare ( ScoreDoc i , ScoreDoc j ) { return cachedValues [ i . doc ] . compareTo ( cachedValues [ j . doc ] ) ; } public Comparable sortValue ( ScoreDoc i ) { return cachedValues [ i . doc ] ; } public int sortType ( ) { return SortField . CUSTOM ; } } ; } protected abstract Comparable getComparable ( String termtext ) ; } 	0	['3', '1', '0', '6', '7', '3', '3', '5', '2', '2', '21', '0', '0', '0', '0.666666667', '0', '0', '6', '1', '0.6667', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . TermDocs ; final class TermScorer extends Scorer { private Weight weight ; private TermDocs termDocs ; private byte [ ] norms ; private float weightValue ; private int doc ; private final int [ ] docs = new int [ 32 ] ; private final int [ ] freqs = new int [ 32 ] ; private int pointer ; private int pointerMax ; private static final int SCORE_CACHE_SIZE = 32 ; private float [ ] scoreCache = new float [ SCORE_CACHE_SIZE ] ; TermScorer ( Weight weight , TermDocs td , Similarity similarity , byte [ ] norms ) { super ( similarity ) ; this . weight = weight ; this . termDocs = td ; this . norms = norms ; this . weightValue = weight . getValue ( ) ; for ( int i = 0 ; i < SCORE_CACHE_SIZE ; i ++ ) scoreCache [ i ] = getSimilarity ( ) . tf ( i ) * weightValue ; } public void score ( HitCollector hc ) throws IOException { next ( ) ; score ( hc , Integer . MAX_VALUE ) ; } protected boolean score ( HitCollector c , int end ) throws IOException { Similarity similarity = getSimilarity ( ) ; float [ ] normDecoder = Similarity . getNormDecoder ( ) ; while ( doc < end ) { int f = freqs [ pointer ] ; float score = f < SCORE_CACHE_SIZE ? scoreCache [ f ] : similarity . tf ( f ) * weightValue ; score *= normDecoder [ norms [ doc ] & 0xFF ] ; c . collect ( doc , score ) ; if ( ++ pointer >= pointerMax ) { pointerMax = termDocs . read ( docs , freqs ) ; if ( pointerMax != 0 ) { pointer = 0 ; } else { termDocs . close ( ) ; doc = Integer . MAX_VALUE ; return false ; } } doc = docs [ pointer ] ; } return true ; } public int doc ( ) { return doc ; } public boolean next ( ) throws IOException { pointer ++ ; if ( pointer >= pointerMax ) { pointerMax = termDocs . read ( docs , freqs ) ; if ( pointerMax != 0 ) { pointer = 0 ; } else { termDocs . close ( ) ; doc = Integer . MAX_VALUE ; return false ; } } doc = docs [ pointer ] ; return true ; } public float score ( ) { int f = freqs [ pointer ] ; float raw = f < SCORE_CACHE_SIZE ? scoreCache [ f ] : getSimilarity ( ) . tf ( f ) * weightValue ; return raw * Similarity . decodeNorm ( norms [ doc ] ) ; } public boolean skipTo ( int target ) throws IOException { for ( pointer ++ ; pointer < pointerMax ; pointer ++ ) { if ( docs [ pointer ] >= target ) { doc = docs [ pointer ] ; return true ; } } boolean result = termDocs . skipTo ( target ) ; if ( result ) { pointerMax = 1 ; pointer = 0 ; docs [ pointer ] = doc = termDocs . doc ( ) ; freqs [ pointer ] = termDocs . freq ( ) ; } else { doc = Integer . MAX_VALUE ; } return result ; } public Explanation explain ( int doc ) throws IOException { TermQuery query = ( TermQuery ) weight . getQuery ( ) ; Explanation tfExplanation = new Explanation ( ) ; int tf = 0 ; while ( pointer < pointerMax ) { if ( docs [ pointer ] == doc ) tf = freqs [ pointer ] ; pointer ++ ; } if ( tf == 0 ) { while ( termDocs . next ( ) ) { if ( termDocs . doc ( ) == doc ) { tf = termDocs . freq ( ) ; } } } termDocs . close ( ) ; tfExplanation . setValue ( getSimilarity ( ) . tf ( tf ) ) ; tfExplanation . setDescription ( "tf(termFreq(" + query . getTerm ( ) + ")=" + tf + ")" ) ; return tfExplanation ; } public String toString ( ) { return "scorer(" + weight + ")" ; } } 	0	['9', '2', '0', '10', '32', '0', '1', '9', '7', '0.545454545', '409', '1', '2', '0.5', '0.285714286', '1', '3', '43.22222222', '2', '1', '0']
package org . apache . lucene . util ; public abstract class PriorityQueue { private Object [ ] heap ; private int size ; private int maxSize ; protected abstract boolean lessThan ( Object a , Object b ) ; protected final void initialize ( int maxSize ) { size = 0 ; int heapSize = maxSize + 1 ; heap = new Object [ heapSize ] ; this . maxSize = maxSize ; } public final void put ( Object element ) { size ++ ; heap [ size ] = element ; upHeap ( ) ; } public boolean insert ( Object element ) { if ( size < maxSize ) { put ( element ) ; return true ; } else if ( size > 0 && ! lessThan ( element , top ( ) ) ) { heap [ 1 ] = element ; adjustTop ( ) ; return true ; } else return false ; } public final Object top ( ) { if ( size > 0 ) return heap [ 1 ] ; else return null ; } public final Object pop ( ) { if ( size > 0 ) { Object result = heap [ 1 ] ; heap [ 1 ] = heap [ size ] ; heap [ size ] = null ; size -- ; downHeap ( ) ; return result ; } else return null ; } public final void adjustTop ( ) { downHeap ( ) ; } public final int size ( ) { return size ; } public final void clear ( ) { for ( int i = 0 ; i <= size ; i ++ ) heap [ i ] = null ; size = 0 ; } private final void upHeap ( ) { int i = size ; Object node = heap [ i ] ; int j = i > > > 1 ; while ( j > 0 && lessThan ( node , heap [ j ] ) ) { heap [ i ] = heap [ j ] ; i = j ; j = j > > > 1 ; } heap [ i ] = node ; } private final void downHeap ( ) { int i = 1 ; Object node = heap [ i ] ; int j = i << 1 ; int k = j + 1 ; if ( k <= size && lessThan ( heap [ k ] , heap [ j ] ) ) { j = k ; } while ( j <= size && lessThan ( heap [ j ] , node ) ) { heap [ i ] = heap [ j ] ; i = j ; j = i << 1 ; k = j + 1 ; if ( k <= size && lessThan ( heap [ k ] , heap [ j ] ) ) { j = k ; } } heap [ i ] = node ; } } 	0	['12', '1', '10', '13', '13', '0', '13', '0', '8', '0.454545455', '275', '1', '0', '0', '0.444444444', '0', '0', '21.66666667', '7', '2.0833', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; import java . io . IOException ; public final class FuzzyTermEnum extends FilteredTermEnum { private static final int TYPICAL_LONGEST_WORD_IN_INDEX = 19 ; private int [ ] [ ] d ; private float similarity ; private boolean endEnum = false ; private Term searchTerm = null ; private final String field ; private final String text ; private final String prefix ; private final float minimumSimilarity ; private final float scale_factor ; private final int [ ] maxDistances = new int [ TYPICAL_LONGEST_WORD_IN_INDEX ] ; public FuzzyTermEnum ( IndexReader reader , Term term ) throws IOException { this ( reader , term , FuzzyQuery . defaultMinSimilarity , FuzzyQuery . defaultPrefixLength ) ; } public FuzzyTermEnum ( IndexReader reader , Term term , float minSimilarity ) throws IOException { this ( reader , term , minSimilarity , FuzzyQuery . defaultPrefixLength ) ; } public FuzzyTermEnum ( IndexReader reader , Term term , final float minSimilarity , final int prefixLength ) throws IOException { super ( ) ; if ( minSimilarity >= 1.0f ) throw new IllegalArgumentException ( "minimumSimilarity cannot be greater than or equal to 1" ) ; else if ( minSimilarity < 0.0f ) throw new IllegalArgumentException ( "minimumSimilarity cannot be less than 0" ) ; if ( prefixLength < 0 ) throw new IllegalArgumentException ( "prefixLength cannot be less than 0" ) ; this . minimumSimilarity = minSimilarity ; this . scale_factor = 1.0f / ( 1.0f - minimumSimilarity ) ; this . searchTerm = term ; this . field = searchTerm . field ( ) ; final int fullSearchTermLength = searchTerm . text ( ) . length ( ) ; final int realPrefixLength = prefixLength > fullSearchTermLength ? fullSearchTermLength : prefixLength ; this . text = searchTerm . text ( ) . substring ( realPrefixLength ) ; this . prefix = searchTerm . text ( ) . substring ( 0 , realPrefixLength ) ; initializeMaxDistances ( ) ; this . d = initDistanceArray ( ) ; setEnum ( reader . terms ( new Term ( searchTerm . field ( ) , prefix ) ) ) ; } protected final boolean termCompare ( Term term ) { if ( field == term . field ( ) && term . text ( ) . startsWith ( prefix ) ) { final String target = term . text ( ) . substring ( prefix . length ( ) ) ; this . similarity = similarity ( target ) ; return ( similarity > minimumSimilarity ) ; } endEnum = true ; return false ; } public final float difference ( ) { return ( float ) ( ( similarity - minimumSimilarity ) * scale_factor ) ; } public final boolean endEnum ( ) { return endEnum ; } private static final int min ( int a , int b , int c ) { final int t = ( a < b ) ? a : b ; return ( t < c ) ? t : c ; } private final int [ ] [ ] initDistanceArray ( ) { return new int [ this . text . length ( ) + 1 ] [ TYPICAL_LONGEST_WORD_IN_INDEX ] ; } private synchronized final float similarity ( final String target ) { final int m = target . length ( ) ; final int n = text . length ( ) ; if ( n == 0 ) { return prefix . length ( ) == 0 ? 0.0f : 1.0f - ( ( float ) m / prefix . length ( ) ) ; } if ( m == 0 ) { return prefix . length ( ) == 0 ? 0.0f : 1.0f - ( ( float ) n / prefix . length ( ) ) ; } final int maxDistance = getMaxDistance ( m ) ; if ( maxDistance < Math . abs ( m - n ) ) { return 0.0f ; } if ( d [ 0 ] . length <= m ) { growDistanceArray ( m ) ; } for ( int i = 0 ; i <= n ; i ++ ) d [ i ] [ 0 ] = i ; for ( int j = 0 ; j <= m ; j ++ ) d [ 0 ] [ j ] = j ; for ( int i = 1 ; i <= n ; i ++ ) { int bestPossibleEditDistance = m ; final char s_i = text . charAt ( i - 1 ) ; for ( int j = 1 ; j <= m ; j ++ ) { if ( s_i != target . charAt ( j - 1 ) ) { d [ i ] [ j ] = min ( d [ i - 1 ] [ j ] , d [ i ] [ j - 1 ] , d [ i - 1 ] [ j - 1 ] ) + 1 ; } else { d [ i ] [ j ] = min ( d [ i - 1 ] [ j ] + 1 , d [ i ] [ j - 1 ] + 1 , d [ i - 1 ] [ j - 1 ] ) ; } bestPossibleEditDistance = Math . min ( bestPossibleEditDistance , d [ i ] [ j ] ) ; } if ( i > maxDistance && bestPossibleEditDistance > maxDistance ) { return 0.0f ; } } return 1.0f - ( ( float ) d [ n ] [ m ] / ( float ) ( prefix . length ( ) + Math . min ( n , m ) ) ) ; } private void growDistanceArray ( int m ) { for ( int i = 0 ; i < d . length ; i ++ ) { d [ i ] = new int [ m + 1 ] ; } } private final int getMaxDistance ( int m ) { return ( m < maxDistances . length ) ? maxDistances [ m ] : calculateMaxDistance ( m ) ; } private void initializeMaxDistances ( ) { for ( int i = 0 ; i < maxDistances . length ; i ++ ) { maxDistances [ i ] = calculateMaxDistance ( i ) ; } } private int calculateMaxDistance ( int m ) { return ( int ) ( ( 1 - minimumSimilarity ) * ( Math . min ( text . length ( ) , m ) + prefix . length ( ) ) ) ; } public void close ( ) throws IOException { super . close ( ) ; } } 	0	['14', '3', '0', '5', '29', '53', '1', '4', '6', '0.692307692', '514', '1', '1', '0.541666667', '0.333333333', '1', '4', '34.92857143', '14', '2.2857', '0']
package org . apache . lucene . search . spans ; import java . io . IOException ; import java . util . Collection ; import java . util . Set ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . search . Query ; import org . apache . lucene . util . ToStringUtils ; public class SpanFirstQuery extends SpanQuery { private SpanQuery match ; private int end ; public SpanFirstQuery ( SpanQuery match , int end ) { this . match = match ; this . end = end ; } public SpanQuery getMatch ( ) { return match ; } public int getEnd ( ) { return end ; } public String getField ( ) { return match . getField ( ) ; } public Collection getTerms ( ) { return match . getTerms ( ) ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( "spanFirst(" ) ; buffer . append ( match . toString ( field ) ) ; buffer . append ( ", " ) ; buffer . append ( end ) ; buffer . append ( ")" ) ; buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public void extractTerms ( Set terms ) { match . extractTerms ( terms ) ; } public Spans getSpans ( final IndexReader reader ) throws IOException { return new Spans ( ) { private Spans spans = match . getSpans ( reader ) ; public boolean next ( ) throws IOException { while ( spans . next ( ) ) { if ( end ( ) <= end ) return true ; } return false ; } public boolean skipTo ( int target ) throws IOException { if ( ! spans . skipTo ( target ) ) return false ; if ( spans . end ( ) <= end ) return true ; return next ( ) ; } public int doc ( ) { return spans . doc ( ) ; } public int start ( ) { return spans . start ( ) ; } public int end ( ) { return spans . end ( ) ; } public String toString ( ) { return "spans(" + SpanFirstQuery . this . toString ( ) + ")" ; } } ; } public Query rewrite ( IndexReader reader ) throws IOException { SpanFirstQuery clone = null ; SpanQuery rewritten = ( SpanQuery ) match . rewrite ( reader ) ; if ( rewritten != match ) { clone = ( SpanFirstQuery ) this . clone ( ) ; clone . match = rewritten ; } if ( clone != null ) { return clone ; } else { return this ; } } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof SpanFirstQuery ) ) return false ; SpanFirstQuery other = ( SpanFirstQuery ) o ; return this . end == other . end && this . match . equals ( other . match ) && this . getBoost ( ) == other . getBoost ( ) ; } public int hashCode ( ) { int h = match . hashCode ( ) ; h ^= ( h << 8 ) | ( h > > > 25 ) ; h ^= Float . floatToRawIntBits ( getBoost ( ) ) ^ end ; return h ; } } 	0	['13', '3', '0', '6', '30', '0', '1', '6', '11', '0.416666667', '176', '1', '1', '0.571428571', '0.192307692', '2', '2', '12.38461538', '6', '1.3077', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; public class TopFieldDocCollector extends TopDocCollector { public TopFieldDocCollector ( IndexReader reader , Sort sort , int numHits ) throws IOException { super ( numHits , new FieldSortedHitQueue ( reader , sort . fields , numHits ) ) ; } public void collect ( int doc , float score ) { if ( score > 0.0f ) { totalHits ++ ; hq . insert ( new FieldDoc ( doc , score ) ) ; } } public TopDocs topDocs ( ) { FieldSortedHitQueue fshq = ( FieldSortedHitQueue ) hq ; ScoreDoc [ ] scoreDocs = new ScoreDoc [ fshq . size ( ) ] ; for ( int i = fshq . size ( ) - 1 ; i >= 0 ; i -- ) scoreDocs [ i ] = fshq . fillFields ( ( FieldDoc ) fshq . pop ( ) ) ; return new TopFieldDocs ( totalHits , scoreDocs , fshq . getFields ( ) , fshq . getMaxScore ( ) ) ; } } 	0	['3', '3', '0', '11', '13', '1', '1', '10', '3', '2', '70', '0', '0', '0.666666667', '0.533333333', '1', '3', '22.33333333', '2', '1.3333', '0']
package org . apache . lucene . index ; import java . io . File ; import java . io . FilenameFilter ; public class IndexFileNameFilter implements FilenameFilter { public boolean accept ( File dir , String name ) { for ( int i = 0 ; i < IndexFileNames . INDEX_EXTENSIONS . length ; i ++ ) { if ( name . endsWith ( "." + IndexFileNames . INDEX_EXTENSIONS [ i ] ) ) return true ; } if ( name . equals ( IndexFileNames . DELETABLE ) ) return true ; else if ( name . equals ( IndexFileNames . SEGMENTS ) ) return true ; else if ( name . matches ( ".+\\.f\\d+" ) ) return true ; return false ; } } 	0	['2', '1', '0', '2', '9', '1', '1', '1', '2', '2', '48', '0', '0', '0', '0.666666667', '0', '0', '23', '6', '3', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public final class LowerCaseTokenizer extends LetterTokenizer { public LowerCaseTokenizer ( Reader in ) { super ( in ) ; } protected char normalize ( char c ) { return Character . toLowerCase ( c ) ; } } 	0	['2', '5', '0', '3', '4', '1', '2', '1', '1', '2', '9', '0', '0', '0.875', '0.666666667', '1', '1', '3.5', '1', '0.5', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermEnum ; public abstract class FilteredTermEnum extends TermEnum { private Term currentTerm = null ; private TermEnum actualEnum = null ; public FilteredTermEnum ( ) { } protected abstract boolean termCompare ( Term term ) ; public abstract float difference ( ) ; protected abstract boolean endEnum ( ) ; protected void setEnum ( TermEnum actualEnum ) throws IOException { this . actualEnum = actualEnum ; Term term = actualEnum . term ( ) ; if ( term != null && termCompare ( term ) ) currentTerm = term ; else next ( ) ; } public int docFreq ( ) { if ( actualEnum == null ) return - 1 ; return actualEnum . docFreq ( ) ; } public boolean next ( ) throws IOException { if ( actualEnum == null ) return false ; currentTerm = null ; while ( currentTerm == null ) { if ( endEnum ( ) ) return false ; if ( actualEnum . next ( ) ) { Term term = actualEnum . term ( ) ; if ( termCompare ( term ) ) { currentTerm = term ; return true ; } } else return false ; } currentTerm = null ; return false ; } public Term term ( ) { return currentTerm ; } public void close ( ) throws IOException { actualEnum . close ( ) ; currentTerm = null ; actualEnum = null ; } } 	0	['9', '2', '2', '7', '14', '8', '5', '2', '6', '0.5', '103', '1', '2', '0.384615385', '0.407407407', '1', '2', '10.22222222', '2', '1', '0']
package org . apache . lucene . index ; import java . io . IOException ; public interface TermDocs { void seek ( Term term ) throws IOException ; void seek ( TermEnum termEnum ) throws IOException ; int doc ( ) ; int freq ( ) ; boolean next ( ) throws IOException ; int read ( int [ ] docs , int [ ] freqs ) throws IOException ; boolean skipTo ( int target ) throws IOException ; void close ( ) throws IOException ; } 	0	['8', '1', '0', '19', '8', '28', '17', '2', '8', '2', '8', '0', '0', '0', '0.3', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . index ; final class TermInfo { int docFreq = 0 ; long freqPointer = 0 ; long proxPointer = 0 ; int skipOffset ; TermInfo ( ) { } TermInfo ( int df , long fp , long pp ) { docFreq = df ; freqPointer = fp ; proxPointer = pp ; } TermInfo ( TermInfo ti ) { docFreq = ti . docFreq ; freqPointer = ti . freqPointer ; proxPointer = ti . proxPointer ; skipOffset = ti . skipOffset ; } final void set ( int docFreq , long freqPointer , long proxPointer , int skipOffset ) { this . docFreq = docFreq ; this . freqPointer = freqPointer ; this . proxPointer = proxPointer ; this . skipOffset = skipOffset ; } final void set ( TermInfo ti ) { docFreq = ti . docFreq ; freqPointer = ti . freqPointer ; proxPointer = ti . proxPointer ; skipOffset = ti . skipOffset ; } } 	0	['5', '1', '0', '8', '6', '0', '8', '0', '0', '0.125', '100', '0', '0', '0', '0.55', '0', '0', '18.2', '1', '0.4', '0']
package org . apache . lucene . index ; import java . io . IOException ; import org . apache . lucene . util . PriorityQueue ; final class SegmentMergeQueue extends PriorityQueue { SegmentMergeQueue ( int size ) { initialize ( size ) ; } protected final boolean lessThan ( Object a , Object b ) { SegmentMergeInfo stiA = ( SegmentMergeInfo ) a ; SegmentMergeInfo stiB = ( SegmentMergeInfo ) b ; int comparison = stiA . term . compareTo ( stiB . term ) ; if ( comparison == 0 ) return stiA . base < stiB . base ; else return comparison < 0 ; } final void close ( ) throws IOException { while ( top ( ) != null ) ( ( SegmentMergeInfo ) pop ( ) ) . close ( ) ; } } 	0	['3', '2', '0', '5', '9', '3', '2', '3', '0', '2', '47', '0', '0', '0.846153846', '0.555555556', '1', '3', '14.66666667', '4', '1.6667', '0']
package org . apache . lucene . util ; public class ToStringUtils { public static String boost ( float boost ) { if ( boost != 1.0f ) { return "^" + Float . toString ( boost ) ; } else return "" ; } } 	0	['2', '1', '0', '15', '7', '1', '15', '0', '2', '2', '21', '0', '0', '0', '0.5', '0', '0', '9.5', '2', '1', '0']
package org . apache . lucene . search ; public class ScoreDoc implements java . io . Serializable { public float score ; public int doc ; public ScoreDoc ( int doc , float score ) { this . doc = doc ; this . score = score ; } } 	0	['1', '1', '1', '19', '2', '0', '19', '0', '1', '2', '12', '0', '0', '0', '1', '0', '0', '9', '0', '0', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; public final class LengthFilter extends TokenFilter { final int min ; final int max ; public LengthFilter ( TokenStream in , int min , int max ) { super ( in ) ; this . min = min ; this . max = max ; } public final Token next ( ) throws IOException { for ( Token token = input . next ( ) ; token != null ; token = input . next ( ) ) { int len = token . termText ( ) . length ( ) ; if ( len >= min && len <= max ) { return token ; } } return null ; } } 	0	['2', '3', '0', '3', '6', '0', '0', '3', '2', '0', '41', '0', '0', '0.75', '0.666666667', '0', '0', '18.5', '1', '0.5', '0']
package org . apache . lucene . queryParser ; public class ParseException extends Exception { public ParseException ( Token currentTokenVal , int [ ] [ ] expectedTokenSequencesVal , String [ ] tokenImageVal ) { super ( "" ) ; specialConstructor = true ; currentToken = currentTokenVal ; expectedTokenSequences = expectedTokenSequencesVal ; tokenImage = tokenImageVal ; } public ParseException ( ) { super ( ) ; specialConstructor = false ; } public ParseException ( String message ) { super ( message ) ; specialConstructor = false ; } protected boolean specialConstructor ; public Token currentToken ; public int [ ] [ ] expectedTokenSequences ; public String [ ] tokenImage ; public String getMessage ( ) { if ( ! specialConstructor ) { return super . getMessage ( ) ; } String expected = "" ; int maxSize = 0 ; for ( int i = 0 ; i < expectedTokenSequences . length ; i ++ ) { if ( maxSize < expectedTokenSequences [ i ] . length ) { maxSize = expectedTokenSequences [ i ] . length ; } for ( int j = 0 ; j < expectedTokenSequences [ i ] . length ; j ++ ) { expected += tokenImage [ expectedTokenSequences [ i ] [ j ] ] + " " ; } if ( expectedTokenSequences [ i ] [ expectedTokenSequences [ i ] . length - 1 ] != 0 ) { expected += "..." ; } expected += eol + "    " ; } String retval = "Encountered \"" ; Token tok = currentToken . next ; for ( int i = 0 ; i < maxSize ; i ++ ) { if ( i != 0 ) retval += " " ; if ( tok . kind == 0 ) { retval += tokenImage [ 0 ] ; break ; } retval += add_escapes ( tok . image ) ; tok = tok . next ; } retval += "\" at line " + currentToken . next . beginLine + ", column " + currentToken . next . beginColumn ; retval += "." + eol ; if ( expectedTokenSequences . length == 1 ) { retval += "Was expecting:" + eol + "    " ; } else { retval += "Was expecting one of:" + eol + "    " ; } retval += expected ; return retval ; } protected String eol = System . getProperty ( "line.separator" , "\n" ) ; protected String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( "\\b" ) ; continue ; case '\t' : retval . append ( "\\t" ) ; continue ; case '\n' : retval . append ( "\\n" ) ; continue ; case '\f' : retval . append ( "\\f" ) ; continue ; case '\r' : retval . append ( "\\r" ) ; continue ; case '\"' : retval . append ( "\\\"" ) ; continue ; case '\'' : retval . append ( "\\\'" ) ; continue ; case '\\' : retval . append ( "\\\\" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = "0000" + Integer . toString ( ch , 16 ) ; retval . append ( "\\u" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; } } 	0	['5', '3', '0', '3', '18', '0', '2', '1', '4', '0.55', '387', '0.4', '1', '0.866666667', '0.4', '1', '1', '75.4', '14', '4.8', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; public interface Weight extends java . io . Serializable { Query getQuery ( ) ; float getValue ( ) ; float sumOfSquaredWeights ( ) throws IOException ; void normalize ( float norm ) ; Scorer scorer ( IndexReader reader ) throws IOException ; Explanation explain ( IndexReader reader , int doc ) throws IOException ; } 	0	['6', '1', '0', '40', '6', '15', '37', '4', '6', '2', '6', '0', '0', '0', '0.416666667', '0', '0', '0', '1', '1', '0']
package org . apache . lucene . search ; import java . io . IOException ; public abstract class Scorer { private Similarity similarity ; protected Scorer ( Similarity similarity ) { this . similarity = similarity ; } public Similarity getSimilarity ( ) { return this . similarity ; } public void score ( HitCollector hc ) throws IOException { while ( next ( ) ) { hc . collect ( doc ( ) , score ( ) ) ; } } protected boolean score ( HitCollector hc , int max ) throws IOException { while ( doc ( ) < max ) { hc . collect ( doc ( ) , score ( ) ) ; if ( ! next ( ) ) return false ; } return true ; } public abstract boolean next ( ) throws IOException ; public abstract int doc ( ) ; public abstract float score ( ) throws IOException ; public abstract boolean skipTo ( int target ) throws IOException ; public abstract Explanation explain ( int doc ) throws IOException ; } 	0	['9', '1', '15', '33', '11', '34', '30', '3', '7', '0.875', '47', '1', '1', '0', '0.416666667', '0', '0', '4.111111111', '1', '0.8889', '0']
package org . apache . lucene . analysis ; import java . io . File ; import java . io . IOException ; import java . io . Reader ; import java . util . Set ; public final class StopAnalyzer extends Analyzer { private Set stopWords ; public static final String [ ] ENGLISH_STOP_WORDS = { "a" , "an" , "and" , "are" , "as" , "at" , "be" , "but" , "by" , "for" , "if" , "in" , "into" , "is" , "it" , "no" , "not" , "of" , "on" , "or" , "s" , "such" , "t" , "that" , "the" , "their" , "then" , "there" , "these" , "they" , "this" , "to" , "was" , "will" , "with" } ; public StopAnalyzer ( ) { stopWords = StopFilter . makeStopSet ( ENGLISH_STOP_WORDS ) ; } public StopAnalyzer ( Set stopWords ) { this . stopWords = stopWords ; } public StopAnalyzer ( String [ ] stopWords ) { this . stopWords = StopFilter . makeStopSet ( stopWords ) ; } public StopAnalyzer ( File stopwordsFile ) throws IOException { stopWords = WordlistLoader . getWordSet ( stopwordsFile ) ; } public StopAnalyzer ( Reader stopwords ) throws IOException { stopWords = WordlistLoader . getWordSet ( stopwords ) ; } public TokenStream tokenStream ( String fieldName , Reader reader ) { return new StopFilter ( new LowerCaseTokenizer ( reader ) , stopWords ) ; } } 	0	['7', '2', '0', '6', '13', '0', '1', '5', '6', '0.5', '197', '0.5', '0', '0.666666667', '0.333333333', '0', '0', '26.85714286', '1', '0.1429', '0']
package org . apache . lucene . search ; import java . io . Serializable ; import java . util . Locale ; public class SortField implements Serializable { public static final int SCORE = 0 ; public static final int DOC = 1 ; public static final int AUTO = 2 ; public static final int STRING = 3 ; public static final int INT = 4 ; public static final int FLOAT = 5 ; public static final int CUSTOM = 9 ; public static final SortField FIELD_SCORE = new SortField ( null , SCORE ) ; public static final SortField FIELD_DOC = new SortField ( null , DOC ) ; private String field ; private int type = AUTO ; private Locale locale ; boolean reverse = false ; private SortComparatorSource factory ; public SortField ( String field ) { this . field = field . intern ( ) ; } public SortField ( String field , boolean reverse ) { this . field = field . intern ( ) ; this . reverse = reverse ; } public SortField ( String field , int type ) { this . field = ( field != null ) ? field . intern ( ) : field ; this . type = type ; } public SortField ( String field , int type , boolean reverse ) { this . field = ( field != null ) ? field . intern ( ) : field ; this . type = type ; this . reverse = reverse ; } public SortField ( String field , Locale locale ) { this . field = field . intern ( ) ; this . type = STRING ; this . locale = locale ; } public SortField ( String field , Locale locale , boolean reverse ) { this . field = field . intern ( ) ; this . type = STRING ; this . locale = locale ; this . reverse = reverse ; } public SortField ( String field , SortComparatorSource comparator ) { this . field = ( field != null ) ? field . intern ( ) : field ; this . type = CUSTOM ; this . factory = comparator ; } public SortField ( String field , SortComparatorSource comparator , boolean reverse ) { this . field = ( field != null ) ? field . intern ( ) : field ; this . type = CUSTOM ; this . reverse = reverse ; this . factory = comparator ; } public String getField ( ) { return field ; } public int getType ( ) { return type ; } public Locale getLocale ( ) { return locale ; } public boolean getReverse ( ) { return reverse ; } public SortComparatorSource getFactory ( ) { return factory ; } public String toString ( ) { StringBuffer buffer = new StringBuffer ( ) ; switch ( type ) { case SCORE : buffer . append ( "<score>" ) ; break ; case DOC : buffer . append ( "<doc>" ) ; break ; case CUSTOM : buffer . append ( "<custom:\"" + field + "\": " + factory + ">" ) ; break ; default : buffer . append ( "\"" + field + "\"" ) ; break ; } if ( locale != null ) buffer . append ( "(" + locale + ")" ) ; if ( reverse ) buffer . append ( '!' ) ; return buffer . toString ( ) ; } } 	0	['15', '1', '0', '9', '22', '0', '8', '1', '14', '0.852040816', '297', '0.285714286', '3', '0', '0.380952381', '0', '0', '17.86666667', '7', '0.8', '0']
package org . apache . lucene . queryParser ; import java . io . * ; public final class FastCharStream implements CharStream { char [ ] buffer = null ; int bufferLength = 0 ; int bufferPosition = 0 ; int tokenStart = 0 ; int bufferStart = 0 ; Reader input ; public FastCharStream ( Reader r ) { input = r ; } public final char readChar ( ) throws IOException { if ( bufferPosition >= bufferLength ) refill ( ) ; return buffer [ bufferPosition ++ ] ; } private final void refill ( ) throws IOException { int newPosition = bufferLength - tokenStart ; if ( tokenStart == 0 ) { if ( buffer == null ) { buffer = new char [ 2048 ] ; } else if ( bufferLength == buffer . length ) { char [ ] newBuffer = new char [ buffer . length * 2 ] ; System . arraycopy ( buffer , 0 , newBuffer , 0 , bufferLength ) ; buffer = newBuffer ; } } else { System . arraycopy ( buffer , tokenStart , buffer , 0 , newPosition ) ; } bufferLength = newPosition ; bufferPosition = newPosition ; bufferStart += tokenStart ; tokenStart = 0 ; int charsRead = input . read ( buffer , newPosition , buffer . length - newPosition ) ; if ( charsRead == - 1 ) throw new IOException ( "read past eof" ) ; else bufferLength += charsRead ; } public final char BeginToken ( ) throws IOException { tokenStart = bufferPosition ; return readChar ( ) ; } public final void backup ( int amount ) { bufferPosition -= amount ; } public final String GetImage ( ) { return new String ( buffer , tokenStart , bufferPosition - tokenStart ) ; } public final char [ ] GetSuffix ( int len ) { char [ ] value = new char [ len ] ; System . arraycopy ( buffer , bufferPosition - len , value , 0 , len ) ; return value ; } public final void Done ( ) { try { input . close ( ) ; } catch ( IOException e ) { System . err . println ( "Caught: " + e + "; ignoring." ) ; } } public final int getColumn ( ) { return bufferStart + bufferPosition ; } public final int getLine ( ) { return 1 ; } public final int getEndColumn ( ) { return bufferStart + bufferPosition ; } public final int getEndLine ( ) { return 1 ; } public final int getBeginColumn ( ) { return bufferStart + tokenStart ; } public final int getBeginLine ( ) { return 1 ; } } 	0	['14', '1', '0', '2', '25', '3', '1', '1', '13', '0.602564103', '237', '0', '0', '0', '0.404761905', '0', '0', '15.5', '1', '0.9286', '0']
package org . apache . lucene . search ; import java . io . IOException ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . index . Term ; public class WildcardTermEnum extends FilteredTermEnum { Term searchTerm ; String field = "" ; String text = "" ; String pre = "" ; int preLen = 0 ; boolean endEnum = false ; public WildcardTermEnum ( IndexReader reader , Term term ) throws IOException { super ( ) ; searchTerm = term ; field = searchTerm . field ( ) ; text = searchTerm . text ( ) ; int sidx = text . indexOf ( WILDCARD_STRING ) ; int cidx = text . indexOf ( WILDCARD_CHAR ) ; int idx = sidx ; if ( idx == - 1 ) { idx = cidx ; } else if ( cidx >= 0 ) { idx = Math . min ( idx , cidx ) ; } pre = searchTerm . text ( ) . substring ( 0 , idx ) ; preLen = pre . length ( ) ; text = text . substring ( preLen ) ; setEnum ( reader . terms ( new Term ( searchTerm . field ( ) , pre ) ) ) ; } protected final boolean termCompare ( Term term ) { if ( field == term . field ( ) ) { String searchText = term . text ( ) ; if ( searchText . startsWith ( pre ) ) { return wildcardEquals ( text , 0 , searchText , preLen ) ; } } endEnum = true ; return false ; } public final float difference ( ) { return 1.0f ; } public final boolean endEnum ( ) { return endEnum ; } public static final char WILDCARD_STRING = '*' ; public static final char WILDCARD_CHAR = '?' ; public static final boolean wildcardEquals ( String pattern , int patternIdx , String string , int stringIdx ) { int p = patternIdx ; for ( int s = stringIdx ; ; ++ p , ++ s ) { boolean sEnd = ( s >= string . length ( ) ) ; boolean pEnd = ( p >= pattern . length ( ) ) ; if ( sEnd ) { boolean justWildcardsLeft = true ; int wildcardSearchPos = p ; while ( wildcardSearchPos < pattern . length ( ) && justWildcardsLeft ) { char wildchar = pattern . charAt ( wildcardSearchPos ) ; if ( wildchar != WILDCARD_CHAR && wildchar != WILDCARD_STRING ) { justWildcardsLeft = false ; } else { if ( wildchar == WILDCARD_CHAR ) { return false ; } wildcardSearchPos ++ ; } } if ( justWildcardsLeft ) { return true ; } } if ( sEnd || pEnd ) { break ; } if ( pattern . charAt ( p ) == WILDCARD_CHAR ) { continue ; } if ( pattern . charAt ( p ) == WILDCARD_STRING ) { ++ p ; for ( int i = string . length ( ) ; i >= s ; -- i ) { if ( wildcardEquals ( pattern , p , string , i ) ) { return true ; } } break ; } if ( pattern . charAt ( p ) != string . charAt ( s ) ) { break ; } } return false ; } public void close ( ) throws IOException { super . close ( ) ; searchTerm = null ; field = null ; text = null ; } } 	0	['6', '3', '0', '5', '20', '5', '1', '4', '5', '0.825', '247', '0', '1', '0.722222222', '0.333333333', '1', '4', '38.83333333', '16', '3.6667', '0']
package org . apache . lucene . search ; import java . io . Serializable ; public class Sort implements Serializable { public static final Sort RELEVANCE = new Sort ( ) ; public static final Sort INDEXORDER = new Sort ( SortField . FIELD_DOC ) ; SortField [ ] fields ; public Sort ( ) { this ( new SortField [ ] { SortField . FIELD_SCORE , SortField . FIELD_DOC } ) ; } public Sort ( String field ) { setSort ( field , false ) ; } public Sort ( String field , boolean reverse ) { setSort ( field , reverse ) ; } public Sort ( String [ ] fields ) { setSort ( fields ) ; } public Sort ( SortField field ) { setSort ( field ) ; } public Sort ( SortField [ ] fields ) { setSort ( fields ) ; } public final void setSort ( String field ) { setSort ( field , false ) ; } public void setSort ( String field , boolean reverse ) { SortField [ ] nfields = new SortField [ ] { new SortField ( field , SortField . AUTO , reverse ) , SortField . FIELD_DOC } ; fields = nfields ; } public void setSort ( String [ ] fieldnames ) { final int n = fieldnames . length ; SortField [ ] nfields = new SortField [ n ] ; for ( int i = 0 ; i < n ; ++ i ) { nfields [ i ] = new SortField ( fieldnames [ i ] , SortField . AUTO ) ; } fields = nfields ; } public void setSort ( SortField field ) { this . fields = new SortField [ ] { field } ; } public void setSort ( SortField [ ] fields ) { this . fields = fields ; } public SortField [ ] getSort ( ) { return fields ; } public String toString ( ) { StringBuffer buffer = new StringBuffer ( ) ; for ( int i = 0 ; i < fields . length ; i ++ ) { buffer . append ( fields [ i ] . toString ( ) ) ; if ( ( i + 1 ) < fields . length ) buffer . append ( ',' ) ; } return buffer . toString ( ) ; } } 	0	['14', '1', '0', '12', '22', '61', '11', '1', '13', '0.692307692', '175', '0', '3', '0', '0.320512821', '0', '0', '11.28571429', '3', '0.7143', '0']
package org . apache . lucene . search ; public class DefaultSimilarity extends Similarity { public float lengthNorm ( String fieldName , int numTerms ) { return ( float ) ( 1.0 / Math . sqrt ( numTerms ) ) ; } public float queryNorm ( float sumOfSquaredWeights ) { return ( float ) ( 1.0 / Math . sqrt ( sumOfSquaredWeights ) ) ; } public float tf ( float freq ) { return ( float ) Math . sqrt ( freq ) ; } public float sloppyFreq ( int distance ) { return 1.0f / ( distance + 1 ) ; } public float idf ( int docFreq , int numDocs ) { return ( float ) ( Math . log ( numDocs / ( double ) ( docFreq + 1 ) ) + 1.0 ) ; } public float coord ( int overlap , int maxOverlap ) { return overlap / ( float ) maxOverlap ; } } 	0	['7', '2', '0', '3', '10', '21', '3', '1', '7', '2', '54', '0', '0', '0.7', '0.5', '1', '2', '6.714285714', '1', '0.8571', '0']
package org . apache . lucene . search ; import org . apache . lucene . index . IndexReader ; import java . io . IOException ; public class ConstantScoreRangeQuery extends Query { private final String fieldName ; private final String lowerVal ; private final String upperVal ; private final boolean includeLower ; private final boolean includeUpper ; public ConstantScoreRangeQuery ( String fieldName , String lowerVal , String upperVal , boolean includeLower , boolean includeUpper ) { if ( lowerVal == null ) { includeLower = true ; } else if ( includeLower && lowerVal . equals ( "" ) ) { lowerVal = null ; } if ( upperVal == null ) { includeUpper = true ; } this . fieldName = fieldName . intern ( ) ; this . lowerVal = lowerVal ; this . upperVal = upperVal ; this . includeLower = includeLower ; this . includeUpper = includeUpper ; } public String getField ( ) { return fieldName ; } public String getLowerVal ( ) { return lowerVal ; } public String getUpperVal ( ) { return upperVal ; } public boolean includesLower ( ) { return includeLower ; } public boolean includesUpper ( ) { return includeUpper ; } public Query rewrite ( IndexReader reader ) throws IOException { RangeFilter rangeFilt = new RangeFilter ( fieldName , lowerVal != null ? lowerVal : "" , upperVal , lowerVal == "" ? false : includeLower , upperVal == null ? false : includeUpper ) ; Query q = new ConstantScoreQuery ( rangeFilt ) ; q . setBoost ( getBoost ( ) ) ; return q ; } public String toString ( String field ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! getField ( ) . equals ( field ) ) { buffer . append ( getField ( ) ) ; buffer . append ( ":" ) ; } buffer . append ( includeLower ? '[' : '{' ) ; buffer . append ( lowerVal != null ? lowerVal : "*" ) ; buffer . append ( " TO " ) ; buffer . append ( upperVal != null ? upperVal : "*" ) ; buffer . append ( includeUpper ? ']' : '}' ) ; if ( getBoost ( ) != 1.0f ) { buffer . append ( "^" ) ; buffer . append ( Float . toString ( getBoost ( ) ) ) ; } return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof ConstantScoreRangeQuery ) ) return false ; ConstantScoreRangeQuery other = ( ConstantScoreRangeQuery ) o ; if ( this . fieldName != other . fieldName || this . includeLower != other . includeLower || this . includeUpper != other . includeUpper ) { return false ; } if ( this . lowerVal != null ? ! this . lowerVal . equals ( other . lowerVal ) : other . lowerVal != null ) return false ; if ( this . upperVal != null ? ! this . upperVal . equals ( other . upperVal ) : other . upperVal != null ) return false ; return this . getBoost ( ) == other . getBoost ( ) ; } public int hashCode ( ) { int h = Float . floatToIntBits ( getBoost ( ) ) ^ fieldName . hashCode ( ) ; h ^= lowerVal != null ? lowerVal . hashCode ( ) : 0x965a965a ; h ^= ( h << 17 ) | ( h > > > 16 ) ; h ^= ( upperVal != null ? ( upperVal . hashCode ( ) ) : 0x5a695a69 ) ; h ^= ( includeLower ? 0x665599aa : 0 ) ^ ( includeUpper ? 0x99aa5566 : 0 ) ; return h ; } } 	0	['10', '2', '0', '5', '24', '0', '0', '5', '10', '0.444444444', '313', '1', '0', '0.571428571', '0.3', '2', '3', '29.8', '13', '3.1', '0']
package org . apache . lucene . analysis ; import java . io . IOException ; public abstract class TokenFilter extends TokenStream { protected TokenStream input ; protected TokenFilter ( TokenStream input ) { this . input = input ; } public void close ( ) throws IOException { input . close ( ) ; } } 	0	['2', '2', '6', '7', '4', '0', '6', '1', '1', '0', '13', '1', '1', '0.666666667', '0.75', '0', '0', '5', '1', '0.5', '0']
package org . apache . lucene . store ; import java . io . IOException ; import java . io . File ; import java . io . RandomAccessFile ; import java . nio . ByteBuffer ; import java . nio . channels . FileChannel ; import java . nio . channels . FileChannel . MapMode ; public class MMapDirectory extends FSDirectory { private static class MMapIndexInput extends IndexInput { private ByteBuffer buffer ; private final long length ; private MMapIndexInput ( RandomAccessFile raf ) throws IOException { this . length = raf . length ( ) ; this . buffer = raf . getChannel ( ) . map ( MapMode . READ_ONLY , 0 , length ) ; } public byte readByte ( ) throws IOException { return buffer . get ( ) ; } public void readBytes ( byte [ ] b , int offset , int len ) throws IOException { buffer . get ( b , offset , len ) ; } public long getFilePointer ( ) { return buffer . position ( ) ; } public void seek ( long pos ) throws IOException { buffer . position ( ( int ) pos ) ; } public long length ( ) { return length ; } public Object clone ( ) { MMapIndexInput clone = ( MMapIndexInput ) super . clone ( ) ; clone . buffer = buffer . duplicate ( ) ; return clone ; } public void close ( ) throws IOException { } } private static class MultiMMapIndexInput extends IndexInput { private ByteBuffer [ ] buffers ; private int [ ] bufSizes ; private final long length ; private int curBufIndex ; private final int maxBufSize ; private ByteBuffer curBuf ; private int curAvail ; public MultiMMapIndexInput ( RandomAccessFile raf , int maxBufSize ) throws IOException { this . length = raf . length ( ) ; this . maxBufSize = maxBufSize ; if ( maxBufSize <= 0 ) throw new IllegalArgumentException ( "Non positive maxBufSize: " + maxBufSize ) ; if ( ( length / maxBufSize ) > Integer . MAX_VALUE ) throw new IllegalArgumentException ( "RandomAccessFile too big for maximum buffer size: " + raf . toString ( ) ) ; int nrBuffers = ( int ) ( length / maxBufSize ) ; if ( ( nrBuffers * maxBufSize ) < length ) nrBuffers ++ ; this . buffers = new ByteBuffer [ nrBuffers ] ; this . bufSizes = new int [ nrBuffers ] ; long bufferStart = 0 ; FileChannel rafc = raf . getChannel ( ) ; for ( int bufNr = 0 ; bufNr < nrBuffers ; bufNr ++ ) { int bufSize = ( length > ( bufferStart + maxBufSize ) ) ? maxBufSize : ( int ) ( length - bufferStart ) ; this . buffers [ bufNr ] = rafc . map ( MapMode . READ_ONLY , bufferStart , bufSize ) ; this . bufSizes [ bufNr ] = bufSize ; bufferStart += bufSize ; } seek ( 0L ) ; } public byte readByte ( ) throws IOException { if ( curAvail == 0 ) { curBufIndex ++ ; curBuf = buffers [ curBufIndex ] ; curBuf . position ( 0 ) ; curAvail = bufSizes [ curBufIndex ] ; } curAvail -- ; return curBuf . get ( ) ; } public void readBytes ( byte [ ] b , int offset , int len ) throws IOException { while ( len > curAvail ) { curBuf . get ( b , offset , curAvail ) ; len -= curAvail ; offset += curAvail ; curBufIndex ++ ; curBuf = buffers [ curBufIndex ] ; curBuf . position ( 0 ) ; curAvail = bufSizes [ curBufIndex ] ; } curBuf . get ( b , offset , len ) ; curAvail -= len ; } public long getFilePointer ( ) { return ( curBufIndex * ( long ) maxBufSize ) + curBuf . position ( ) ; } public void seek ( long pos ) throws IOException { curBufIndex = ( int ) ( pos / maxBufSize ) ; curBuf = buffers [ curBufIndex ] ; int bufOffset = ( int ) ( pos - ( curBufIndex * maxBufSize ) ) ; curBuf . position ( bufOffset ) ; curAvail = bufSizes [ curBufIndex ] - bufOffset ; } public long length ( ) { return length ; } public Object clone ( ) { MultiMMapIndexInput clone = ( MultiMMapIndexInput ) super . clone ( ) ; clone . buffers = new ByteBuffer [ buffers . length ] ; for ( int bufNr = 0 ; bufNr < buffers . length ; bufNr ++ ) { clone . buffers [ bufNr ] = buffers [ bufNr ] . duplicate ( ) ; } try { clone . seek ( getFilePointer ( ) ) ; } catch ( IOException ioe ) { RuntimeException newException = new RuntimeException ( ioe ) ; newException . initCause ( ioe ) ; throw newException ; } ; return clone ; } public void close ( ) throws IOException { } } private final int MAX_BBUF = Integer . MAX_VALUE ; public IndexInput openInput ( String name ) throws IOException { File f = new File ( getFile ( ) , name ) ; RandomAccessFile raf = new RandomAccessFile ( f , "r" ) ; try { return ( raf . length ( ) <= MAX_BBUF ) ? ( IndexInput ) new MMapIndexInput ( raf ) : ( IndexInput ) new MultiMMapIndexInput ( raf , MAX_BBUF ) ; } finally { raf . close ( ) ; } } } 	0	['2', '3', '0', '5', '10', '1', '0', '5', '2', '1', '48', '1', '0', '0.972222222', '0.75', '0', '0', '22.5', '1', '0.5', '0']
package org . apache . lucene . index ; import java . io . IOException ; final class SegmentMergeInfo { Term term ; int base ; TermEnum termEnum ; IndexReader reader ; private TermPositions postings ; private int [ ] docMap ; SegmentMergeInfo ( int b , TermEnum te , IndexReader r ) throws IOException { base = b ; reader = r ; termEnum = te ; term = te . term ( ) ; } int [ ] getDocMap ( ) { if ( docMap == null ) { if ( reader . hasDeletions ( ) ) { int maxDoc = reader . maxDoc ( ) ; docMap = new int [ maxDoc ] ; int j = 0 ; for ( int i = 0 ; i < maxDoc ; i ++ ) { if ( reader . isDeleted ( i ) ) docMap [ i ] = - 1 ; else docMap [ i ] = j ++ ; } } } return docMap ; } TermPositions getPositions ( ) throws IOException { if ( postings == null ) { postings = reader . termPositions ( ) ; } return postings ; } final boolean next ( ) throws IOException { if ( termEnum . next ( ) ) { term = termEnum . term ( ) ; return true ; } else { term = null ; return false ; } } final void close ( ) throws IOException { termEnum . close ( ) ; if ( postings != null ) { postings . close ( ) ; } } } 	0	['5', '1', '0', '7', '14', '0', '3', '4', '0', '0.75', '108', '0.333333333', '4', '0', '0.4', '0', '0', '19.4', '5', '1.6', '0']
package org . apache . lucene . search ; import java . io . IOException ; import java . util . Set ; import java . util . Vector ; import org . apache . lucene . index . Term ; import org . apache . lucene . index . TermPositions ; import org . apache . lucene . index . IndexReader ; import org . apache . lucene . util . ToStringUtils ; public class PhraseQuery extends Query { private String field ; private Vector terms = new Vector ( ) ; private Vector positions = new Vector ( ) ; private int slop = 0 ; public PhraseQuery ( ) { } public void setSlop ( int s ) { slop = s ; } public int getSlop ( ) { return slop ; } public void add ( Term term ) { int position = 0 ; if ( positions . size ( ) > 0 ) position = ( ( Integer ) positions . lastElement ( ) ) . intValue ( ) + 1 ; add ( term , position ) ; } public void add ( Term term , int position ) { if ( terms . size ( ) == 0 ) field = term . field ( ) ; else if ( term . field ( ) != field ) throw new IllegalArgumentException ( "All phrase terms must be in the same field: " + term ) ; terms . addElement ( term ) ; positions . addElement ( new Integer ( position ) ) ; } public Term [ ] getTerms ( ) { return ( Term [ ] ) terms . toArray ( new Term [ 0 ] ) ; } public int [ ] getPositions ( ) { int [ ] result = new int [ positions . size ( ) ] ; for ( int i = 0 ; i < positions . size ( ) ; i ++ ) result [ i ] = ( ( Integer ) positions . elementAt ( i ) ) . intValue ( ) ; return result ; } private class PhraseWeight implements Weight { private Similarity similarity ; private float value ; private float idf ; private float queryNorm ; private float queryWeight ; public PhraseWeight ( Searcher searcher ) throws IOException { this . similarity = getSimilarity ( searcher ) ; idf = similarity . idf ( terms , searcher ) ; } public String toString ( ) { return "weight(" + PhraseQuery . this + ")" ; } public Query getQuery ( ) { return PhraseQuery . this ; } public float getValue ( ) { return value ; } public float sumOfSquaredWeights ( ) { queryWeight = idf * getBoost ( ) ; return queryWeight * queryWeight ; } public void normalize ( float queryNorm ) { this . queryNorm = queryNorm ; queryWeight *= queryNorm ; value = queryWeight * idf ; } public Scorer scorer ( IndexReader reader ) throws IOException { if ( terms . size ( ) == 0 ) return null ; TermPositions [ ] tps = new TermPositions [ terms . size ( ) ] ; for ( int i = 0 ; i < terms . size ( ) ; i ++ ) { TermPositions p = reader . termPositions ( ( Term ) terms . elementAt ( i ) ) ; if ( p == null ) return null ; tps [ i ] = p ; } if ( slop == 0 ) return new ExactPhraseScorer ( this , tps , getPositions ( ) , similarity , reader . norms ( field ) ) ; else return new SloppyPhraseScorer ( this , tps , getPositions ( ) , similarity , slop , reader . norms ( field ) ) ; } public Explanation explain ( IndexReader reader , int doc ) throws IOException { Explanation result = new Explanation ( ) ; result . setDescription ( "weight(" + getQuery ( ) + " in " + doc + "), product of:" ) ; StringBuffer docFreqs = new StringBuffer ( ) ; StringBuffer query = new StringBuffer ( ) ; query . append ( '\"' ) ; for ( int i = 0 ; i < terms . size ( ) ; i ++ ) { if ( i != 0 ) { docFreqs . append ( " " ) ; query . append ( " " ) ; } Term term = ( Term ) terms . elementAt ( i ) ; docFreqs . append ( term . text ( ) ) ; docFreqs . append ( "=" ) ; docFreqs . append ( reader . docFreq ( term ) ) ; query . append ( term . text ( ) ) ; } query . append ( '\"' ) ; Explanation idfExpl = new Explanation ( idf , "idf(" + field + ": " + docFreqs + ")" ) ; Explanation queryExpl = new Explanation ( ) ; queryExpl . setDescription ( "queryWeight(" + getQuery ( ) + "), product of:" ) ; Explanation boostExpl = new Explanation ( getBoost ( ) , "boost" ) ; if ( getBoost ( ) != 1.0f ) queryExpl . addDetail ( boostExpl ) ; queryExpl . addDetail ( idfExpl ) ; Explanation queryNormExpl = new Explanation ( queryNorm , "queryNorm" ) ; queryExpl . addDetail ( queryNormExpl ) ; queryExpl . setValue ( boostExpl . getValue ( ) * idfExpl . getValue ( ) * queryNormExpl . getValue ( ) ) ; result . addDetail ( queryExpl ) ; Explanation fieldExpl = new Explanation ( ) ; fieldExpl . setDescription ( "fieldWeight(" + field + ":" + query + " in " + doc + "), product of:" ) ; Explanation tfExpl = scorer ( reader ) . explain ( doc ) ; fieldExpl . addDetail ( tfExpl ) ; fieldExpl . addDetail ( idfExpl ) ; Explanation fieldNormExpl = new Explanation ( ) ; byte [ ] fieldNorms = reader . norms ( field ) ; float fieldNorm = fieldNorms != null ? Similarity . decodeNorm ( fieldNorms [ doc ] ) : 0.0f ; fieldNormExpl . setValue ( fieldNorm ) ; fieldNormExpl . setDescription ( "fieldNorm(field=" + field + ", doc=" + doc + ")" ) ; fieldExpl . addDetail ( fieldNormExpl ) ; fieldExpl . setValue ( tfExpl . getValue ( ) * idfExpl . getValue ( ) * fieldNormExpl . getValue ( ) ) ; result . addDetail ( fieldExpl ) ; result . setValue ( queryExpl . getValue ( ) * fieldExpl . getValue ( ) ) ; if ( queryExpl . getValue ( ) == 1.0f ) return fieldExpl ; return result ; } } protected Weight createWeight ( Searcher searcher ) throws IOException { if ( terms . size ( ) == 1 ) { Term term = ( Term ) terms . elementAt ( 0 ) ; Query termQuery = new TermQuery ( term ) ; termQuery . setBoost ( getBoost ( ) ) ; return termQuery . createWeight ( searcher ) ; } return new PhraseWeight ( searcher ) ; } public void extractTerms ( Set queryTerms ) { queryTerms . addAll ( terms ) ; } public String toString ( String f ) { StringBuffer buffer = new StringBuffer ( ) ; if ( ! field . equals ( f ) ) { buffer . append ( field ) ; buffer . append ( ":" ) ; } buffer . append ( "\"" ) ; for ( int i = 0 ; i < terms . size ( ) ; i ++ ) { buffer . append ( ( ( Term ) terms . elementAt ( i ) ) . text ( ) ) ; if ( i != terms . size ( ) - 1 ) buffer . append ( " " ) ; } buffer . append ( "\"" ) ; if ( slop != 0 ) { buffer . append ( "~" ) ; buffer . append ( slop ) ; } buffer . append ( ToStringUtils . boost ( getBoost ( ) ) ) ; return buffer . toString ( ) ; } public boolean equals ( Object o ) { if ( ! ( o instanceof PhraseQuery ) ) return false ; PhraseQuery other = ( PhraseQuery ) o ; return ( this . getBoost ( ) == other . getBoost ( ) ) && ( this . slop == other . slop ) && this . terms . equals ( other . terms ) && this . positions . equals ( other . positions ) ; } public int hashCode ( ) { return Float . floatToIntBits ( getBoost ( ) ) ^ slop ^ terms . hashCode ( ) ^ positions . hashCode ( ) ; } } 	0	['15', '2', '0', '9', '43', '0', '3', '7', '11', '0.589285714', '302', '1', '0', '0.461538462', '0.191666667', '2', '3', '18.86666667', '6', '1.8', '0']
package org . apache . lucene . queryParser ; public class Token { public int kind ; public int beginLine , beginColumn , endLine , endColumn ; public String image ; public Token next ; public Token specialToken ; public String toString ( ) { return image ; } public static final Token newToken ( int ofKind ) { switch ( ofKind ) { default : return new Token ( ) ; } } } 	0	['3', '1', '0', '4', '4', '3', '4', '0', '3', '1.4375', '23', '0', '2', '0', '0.5', '0', '0', '4', '2', '1', '0']
package org . apache . lucene . util ; public abstract class StringHelper { public static final int stringDifference ( String s1 , String s2 ) { int len1 = s1 . length ( ) ; int len2 = s2 . length ( ) ; int len = len1 < len2 ? len1 : len2 ; for ( int i = 0 ; i < len ; i ++ ) { if ( s1 . charAt ( i ) != s2 . charAt ( i ) ) { return i ; } } return len ; } private StringHelper ( ) { } } 	0	['2', '1', '0', '2', '5', '1', '2', '0', '1', '2', '36', '0', '0', '0', '0.5', '0', '0', '17', '4', '2', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public abstract class Analyzer { public abstract TokenStream tokenStream ( String fieldName , Reader reader ) ; public int getPositionIncrementGap ( String fieldName ) { return 0 ; } } 	0	['3', '1', '6', '13', '4', '3', '12', '1', '3', '2', '8', '0', '0', '0', '0.666666667', '0', '0', '1.666666667', '1', '0.6667', '0']
package org . apache . lucene . index ; import java . io . IOException ; import org . apache . lucene . store . IndexInput ; final class TermBuffer implements Cloneable { private static final char [ ] NO_CHARS = new char [ 0 ] ; private String field ; private char [ ] text = NO_CHARS ; private int textLength ; private Term term ; public final int compareTo ( TermBuffer other ) { if ( field == other . field ) return compareChars ( text , textLength , other . text , other . textLength ) ; else return field . compareTo ( other . field ) ; } private static final int compareChars ( char [ ] v1 , int len1 , char [ ] v2 , int len2 ) { int end = Math . min ( len1 , len2 ) ; for ( int k = 0 ; k < end ; k ++ ) { char c1 = v1 [ k ] ; char c2 = v2 [ k ] ; if ( c1 != c2 ) { return c1 - c2 ; } } return len1 - len2 ; } private final void setTextLength ( int newLength ) { if ( text . length < newLength ) { char [ ] newText = new char [ newLength ] ; System . arraycopy ( text , 0 , newText , 0 , textLength ) ; text = newText ; } textLength = newLength ; } public final void read ( IndexInput input , FieldInfos fieldInfos ) throws IOException { this . term = null ; int start = input . readVInt ( ) ; int length = input . readVInt ( ) ; int totalLength = start + length ; setTextLength ( totalLength ) ; input . readChars ( this . text , start , length ) ; this . field = fieldInfos . fieldName ( input . readVInt ( ) ) ; } public final void set ( Term term ) { if ( term == null ) { reset ( ) ; return ; } setTextLength ( term . text ( ) . length ( ) ) ; term . text ( ) . getChars ( 0 , term . text ( ) . length ( ) , text , 0 ) ; this . field = term . field ( ) ; this . term = term ; } public final void set ( TermBuffer other ) { setTextLength ( other . textLength ) ; System . arraycopy ( other . text , 0 , text , 0 , textLength ) ; this . field = other . field ; this . term = other . term ; } public void reset ( ) { this . field = null ; this . textLength = 0 ; this . term = null ; } public Term toTerm ( ) { if ( field == null ) return null ; if ( term == null ) term = new Term ( field , new String ( text , 0 , textLength ) , false ) ; return term ; } protected Object clone ( ) { TermBuffer clone = null ; try { clone = ( TermBuffer ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { } clone . text = new char [ text . length ] ; System . arraycopy ( text , 0 , clone . text , 0 , textLength ) ; return clone ; } } 	0	['11', '1', '0', '4', '25', '0', '1', '3', '6', '0.52', '241', '1', '1', '0', '0.242857143', '0', '0', '20.45454545', '3', '1.4545', '0']
package org . apache . lucene . index ; public class TermVectorOffsetInfo { public static final TermVectorOffsetInfo [ ] EMPTY_OFFSET_INFO = new TermVectorOffsetInfo [ 0 ] ; private int startOffset ; private int endOffset ; public TermVectorOffsetInfo ( ) { } public TermVectorOffsetInfo ( int startOffset , int endOffset ) { this . endOffset = endOffset ; this . startOffset = startOffset ; } public int getEndOffset ( ) { return endOffset ; } public void setEndOffset ( int endOffset ) { this . endOffset = endOffset ; } public int getStartOffset ( ) { return startOffset ; } public void setStartOffset ( int startOffset ) { this . startOffset = startOffset ; } public boolean equals ( Object o ) { if ( this == o ) return true ; if ( ! ( o instanceof TermVectorOffsetInfo ) ) return false ; final TermVectorOffsetInfo termVectorOffsetInfo = ( TermVectorOffsetInfo ) o ; if ( endOffset != termVectorOffsetInfo . endOffset ) return false ; if ( startOffset != termVectorOffsetInfo . startOffset ) return false ; return true ; } public int hashCode ( ) { int result ; result = startOffset ; result = 29 * result + endOffset ; return result ; } } 	0	['9', '1', '0', '7', '10', '2', '7', '0', '8', '0.666666667', '83', '0.666666667', '1', '0', '0.5', '1', '1', '7.888888889', '5', '1.1111', '0']
package org . apache . lucene . analysis ; import java . io . Reader ; public class KeywordAnalyzer extends Analyzer { public TokenStream tokenStream ( String fieldName , final Reader reader ) { return new KeywordTokenizer ( reader ) ; } } 	0	['2', '2', '0', '3', '4', '1', '0', '3', '2', '2', '10', '0', '0', '0.666666667', '0.666666667', '0', '0', '4', '1', '0.5', '0']
